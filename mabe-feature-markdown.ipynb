{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Khởi tạo môi trường, import thư viện cần thiết, và cấu hình tham số cho pipeline học máy (LightGBM/XGBoost/CatBoost)\n",
    "* pandas, numpy: xử lý dữ liệu dạng bảng và tính toán số.\n",
    "* tqdm: tạo thanh progress bar hữu ích khi chạy vòng lặp.\n",
    "* import warnings, json, os, random, gc, re, math: hỗ trợ thao tác hệ thống, cảnh báo, dọn bộ nhớ, regex, toán học.\n",
    "* Ba thuật toán boosting phổ biến: LightGBM, XGBoost, CatBoost.\n",
    "* Công cụ đánh giá – cross validation – pipeline: from sklearn.model_selection import, from sklearn.metrics import f1_score, from sklearn.pipeline import make_pipeline: Phục vụ xây dựng pipeline, chia Fold, đánh giá mô hình bằng F1-score.\n",
    "* Polars là giải pháp thay thế Pandas với tốc độ nhanh hơn (Rust-based).\n",
    "* from scipy import signal, stats: Phục vụ tiền xử lý dữ liệu phức tạp (lọc tín hiệu, thống kê…).\n",
    "* Phát hiện GPU trong môi trường Kaggle để bật tăng tốc cho LightGBM/XGBoost/CatBoost.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-10T18:58:01.249262Z",
     "iopub.status.busy": "2025-12-10T18:58:01.248972Z",
     "iopub.status.idle": "2025-12-10T18:58:07.777869Z",
     "shell.execute_reply": "2025-12-10T18:58:07.777090Z",
     "shell.execute_reply.started": "2025-12-10T18:58:01.249242Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using GPU? True\n"
     ]
    }
   ],
   "source": [
    "verbose = True\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import itertools\n",
    "import warnings\n",
    "import json\n",
    "import os, random\n",
    "import gc, re, math\n",
    "import lightgbm\n",
    "from collections import defaultdict\n",
    "import polars as pl\n",
    "from scipy import signal, stats\n",
    "from typing import Dict, Optional, Tuple\n",
    "from time import perf_counter \n",
    "from sklearn.base import ClassifierMixin, BaseEstimator, clone\n",
    "from sklearn.model_selection import cross_val_predict, GroupKFold, StratifiedKFold\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "from sklearn.metrics import f1_score\n",
    "from xgboost import XGBClassifier\n",
    "from catboost import CatBoostClassifier\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "USE_GPU = (\"KAGGLE_KERNEL_RUN_TYPE\" in __import__(\"os\").environ) and (__import__(\"shutil\").which(\"nvidia-smi\") is not None)\n",
    "print(f'Using GPU? {USE_GPU}')\n",
    " \n",
    "SEED = 1234"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Trong các bài toán học máy, rất nhiều thao tác bên trong mô hình là ngẫu nhiên, ví dụ:\n",
    "\n",
    "    Chọn mẫu trong quá trình chia train/validation\n",
    "    \n",
    "    Khởi tạo trọng số ban đầu của mô hình\n",
    "    \n",
    "    Lấy mẫu ngẫu nhiên (shuffle) dữ liệu\n",
    "    \n",
    "    Các thuật toán boosting như LightGBM/XGBoost có nhiều bước random trong việc chọn feature, chọn split\n",
    "    \n",
    "    Stratified K-Fold, StratifiedShuffleSplit dùng RNG (random number generator)\n",
    "\n",
    "Nếu không cố định Seed, mỗi lần chạy cùng một đoạn code, mô hình có thể cho kết quả khác nhau, do sự thay đổi trong các bước ngẫu nhiên. Khi đặt: SEED và truyền seed này vào tất cả module có tính ngẫu nhiên, đảm bảo rằng:\n",
    "\n",
    "    Mọi thao tác ngẫu nhiên được định trước.\n",
    "    \n",
    "    Mô hình huấn luyện lại vẫn ra cùng kết quả.\n",
    "    \n",
    "    Có thể kiểm chứng, debug và so sánh mô hình chính xác hơn.\n",
    "\n",
    "Ví dụ khi chạy cùng pipeline:\n",
    "\n",
    "    Fold chia giống nhau 100%.\n",
    "    \n",
    "    LightGBM chọn split giống nhau.\n",
    "    \n",
    "    Dữ liệu được shuffle giống nhau.\n",
    "    \n",
    "    Trọng số mô hình khởi tạo giống nhau."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-10T18:58:07.779820Z",
     "iopub.status.busy": "2025-12-10T18:58:07.779234Z",
     "iopub.status.idle": "2025-12-10T18:58:07.785843Z",
     "shell.execute_reply": "2025-12-10T18:58:07.785097Z",
     "shell.execute_reply.started": "2025-12-10T18:58:07.779799Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# SEED \n",
    "os.environ[\"PYTHONHASHSEED\"] = str(SEED) \n",
    "\n",
    "rnd = np.random.RandomState(SEED)\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "\n",
    "def _make_lgbm(**kw):\n",
    "    kw.setdefault(\"random_state\", SEED)\n",
    "    # kw.setdefault(\"deterministic\", True)\n",
    "    # kw.setdefault(\"force_row_wise\", True) \n",
    "    kw.setdefault(\"feature_fraction_seed\", SEED)\n",
    "    kw.setdefault(\"data_random_seed\", SEED)\n",
    "    kw.setdefault(\"device\", 'gpu' if USE_GPU else 'cpu')\n",
    "    return lightgbm.LGBMClassifier(**kw)\n",
    "\n",
    "def _make_xgb(**kw):\n",
    "    kw.setdefault(\"random_state\", SEED)\n",
    "    kw.setdefault(\"tree_method\", \"gpu_hist\" if USE_GPU else \"hist\")\n",
    "    # kw.setdefault(\"deterministic_histogram\", True)\n",
    "    return XGBClassifier(**kw)\n",
    "\n",
    "def _make_cb(**kw):\n",
    "    kw.setdefault(\"random_seed\", SEED)\n",
    "    if USE_GPU:\n",
    "        kw.setdefault(\"task_type\", \"GPU\")\n",
    "        kw.setdefault(\"devices\", \"0\")\n",
    "    else:\n",
    "        kw.setdefault(\"task_type\", \"CPU\")\n",
    "\n",
    "    return CatBoostClassifier(**kw)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cố định thuật toán hash ngầm của Python bằng os.environ[\"PYTHONHASHSEED\"] = str(SEED).\n",
    "Python sử dụng hashing cho dictionary, keysset operations, sắp xếp và internal hashing\n",
    "Nếu không cố định hash, mỗi lần chạy Python sẽ tạo một hàm hash khác, làm thay đổi thứ tự duyệt dictionary, ảnh hưởng đến random nội bộ của nhiều thư viện.\n",
    "PYTHONHASHSEED cố định hành vi hash của Python; random.seed() và np.random.seed() khóa mọi thao tác ngẫu nhiên trong Python và NumPy; LightGBM, XGBoost và CatBoost được truyền cùng một Seed để kiểm soát các bước ngẫu nhiên nội bộ như sampling, bagging và chọn split."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-10T18:58:07.787899Z",
     "iopub.status.busy": "2025-12-10T18:58:07.787632Z",
     "iopub.status.idle": "2025-12-10T18:58:07.812760Z",
     "shell.execute_reply": "2025-12-10T18:58:07.811967Z",
     "shell.execute_reply.started": "2025-12-10T18:58:07.787879Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# ================= StratifiedSubsetClassifier =================\n",
    "class StratifiedSubsetClassifierWEval(ClassifierMixin, BaseEstimator):\n",
    "    def __init__(self,\n",
    "                 estimator,\n",
    "                 n_samples=None,\n",
    "                 random_state: int = 42,\n",
    "                 valid_size: float = 0.10,\n",
    "                 val_cap_ratio: float = 0.25,\n",
    "                 es_rounds: \"int|str\" = \"auto\",\n",
    "                 es_metric: str = \"auto\"):\n",
    "        self.estimator = estimator\n",
    "        self.n_samples = (int(n_samples) if (n_samples is not None) else None)\n",
    "        self.random_state = random_state\n",
    "        self.valid_size = float(valid_size)\n",
    "        self.val_cap_ratio = float(val_cap_ratio)\n",
    "        self.es_rounds = es_rounds\n",
    "        self.es_metric = es_metric\n",
    " \n",
    "    # -------------------------- API --------------------------\n",
    "    def fit(self, X: pd.DataFrame, y):\n",
    "        y = np.asarray(y)\n",
    "        n_total = len(y); assert n_total == len(X)\n",
    "\n",
    "        tr_idx, va_idx = self._compute_train_val_indices(y, n_total)\n",
    "        Xtr = X.iloc[tr_idx]; ytr = y[tr_idx]\n",
    "\n",
    "        Xtr = Xtr.to_numpy(np.float32, copy=False)\n",
    "\n",
    "        Xva = yva = None\n",
    "        if va_idx is not None and len(va_idx) > 0:\n",
    "            Xva = X.iloc[va_idx].to_numpy(np.float32, copy=False); yva = y[va_idx]\n",
    "\n",
    "        # Compute pos_rate on VALIDATION (what ES monitors)\n",
    "        pos_rate = None\n",
    "        if yva is not None and len(yva) > 0:\n",
    "            pos_rate = float(np.mean(yva == 1))\n",
    "\n",
    "        # Decide metric & patience\n",
    "        metric = self._choose_metric(pos_rate)\n",
    "        patience = self._choose_patience(pos_rate)\n",
    "\n",
    "        # Apply imbalance knobs per library\n",
    "        if self._is_xgb(self.estimator):\n",
    "            # scale_pos_weight = n_neg / n_pos on TRAIN\n",
    "            n_pos = max(1, int((ytr == 1).sum()))\n",
    "            n_neg = max(1, len(ytr) - n_pos)\n",
    "            self.estimator.set_params(scale_pos_weight=(n_neg / n_pos))\n",
    "            self.estimator.set_params(eval_metric=metric)\n",
    "\n",
    "        elif self._is_catboost(self.estimator):\n",
    "            # GPU-safe auto balancing\n",
    "            try: self.estimator.set_params(auto_class_weights=\"Balanced\")\n",
    "            except Exception: pass\n",
    "            try: self.estimator.set_params(eval_metric=metric)\n",
    "            except Exception: pass\n",
    "\n",
    "        # Fit with ES if we have any validation (single-class OK with Logloss)\n",
    "        has_valid = (Xva is not None and len(yva) > 0)\n",
    "        if has_valid and self._is_xgb(self.estimator):\n",
    "            import xgboost as xgb\n",
    "            self.estimator.fit(\n",
    "                Xtr, ytr,\n",
    "                eval_set=[(Xva, yva)],\n",
    "                verbose=False,\n",
    "                callbacks=[xgb.callback.EarlyStopping(\n",
    "                    rounds=int(patience),\n",
    "                    metric_name=metric,\n",
    "                    data_name=\"validation_0\",\n",
    "                    save_best=True\n",
    "                )]\n",
    "            )\n",
    "        elif has_valid and self._is_catboost(self.estimator):\n",
    "            from catboost import Pool\n",
    "            self.estimator.set_params(\n",
    "                use_best_model=True,\n",
    "                od_type=\"Iter\",\n",
    "                od_wait=int(patience),\n",
    "                custom_metric=[\"PRAUC:type=Classic;hints=skip_train~true\"],\n",
    "            )\n",
    "            self.estimator.fit(\n",
    "                Xtr, ytr,\n",
    "                eval_set=Pool(Xva, yva),\n",
    "                verbose=False,\n",
    "                metric_period=50\n",
    "            )\n",
    "        else:\n",
    "            # Fall back: train on train split without ES\n",
    "            self.estimator.fit(Xtr, ytr)\n",
    "\n",
    "        self.classes_ = getattr(self.estimator, \"classes_\", np.array([0, 1]))\n",
    "        self._tr_idx_ = tr_idx; self._va_idx_ = va_idx; self._pos_rate_ = pos_rate\n",
    "        return self\n",
    "\n",
    "    def predict_proba(self, X: pd.DataFrame):\n",
    "        return self.estimator.predict_proba(X)\n",
    "\n",
    "    def predict(self, X: pd.DataFrame):\n",
    "        return self.estimator.predict(X)\n",
    "\n",
    "    # -------------------------- helpers --------------------------\n",
    "    def _compute_train_val_indices(self, y: np.ndarray, n_total: int):\n",
    "        rng = np.random.default_rng(self.random_state)\n",
    "        n_classes = np.unique(y).size\n",
    "\n",
    "        def full_data_split():\n",
    "            if self.valid_size <= 0 or n_classes < 2:\n",
    "                idx = rng.permutation(n_total); return idx, None\n",
    "            sss = StratifiedShuffleSplit(n_splits=1, test_size=self.valid_size, random_state=self.random_state)\n",
    "            tr, va = next(sss.split(np.zeros(n_total, dtype=np.int8), y))\n",
    "            return tr, va\n",
    "\n",
    "        if self.n_samples is None or self.n_samples >= n_total:\n",
    "            return full_data_split()\n",
    "\n",
    "        # Use n_samples for train; build val from remainder (capped)\n",
    "        sss_tr = StratifiedShuffleSplit(n_splits=1, train_size=self.n_samples, random_state=self.random_state)\n",
    "        tr_idx, rest_idx = next(sss_tr.split(np.zeros(n_total, dtype=np.int8), y))\n",
    "        remaining = len(rest_idx)\n",
    "\n",
    "        min_val_needed = int(np.ceil(self.n_samples * max(self.valid_size, 0.0)))\n",
    "        val_cap = max(min_val_needed, int(round(self.val_cap_ratio * self.n_samples)))\n",
    "        want_val = min(remaining, val_cap)\n",
    "\n",
    "        y_rest = y[rest_idx]\n",
    "        if remaining < min_val_needed or np.unique(y_rest).size < 2 or self.valid_size <= 0:\n",
    "            return full_data_split()\n",
    "\n",
    "        sss_val = StratifiedShuffleSplit(n_splits=1, train_size=want_val, random_state=self.random_state)\n",
    "        try:\n",
    "            va_sel, _ = next(sss_val.split(np.zeros(remaining, dtype=np.int8), y_rest))\n",
    "        except ValueError:\n",
    "            return full_data_split()\n",
    "\n",
    "        va_idx = rest_idx[va_sel]\n",
    "        return tr_idx, va_idx\n",
    "\n",
    "    def _choose_metric(self, pos_rate=0.01) -> str:\n",
    "        if self.es_metric != \"auto\":\n",
    "            return self.es_metric\n",
    "        if pos_rate is None or pos_rate == 0.0 or pos_rate == 1.0:\n",
    "            return \"logloss\" if self._is_xgb(self.estimator) else \"Logloss\"\n",
    "        return \"aucpr\" if self._is_xgb(self.estimator) else \"PRAUC:type=Classic\"\n",
    "\n",
    "    def _choose_patience(self, pos_rate: Optional[float]) -> int:\n",
    "        if isinstance(self.es_rounds, int):\n",
    "            return self.es_rounds\n",
    "        try:\n",
    "            n_estimators = (int(self.estimator.get_params().get(\"n_estimators\", 200))\n",
    "                            if self._is_xgb(self.estimator)\n",
    "                            else int(self.estimator.get_params().get(\"iterations\", 500)))\n",
    "        except Exception:\n",
    "            n_estimators = 200\n",
    "        base = max(30, int(round(0.20 * (n_estimators or 200))))\n",
    "        if pos_rate is None:\n",
    "            return base\n",
    "        if pos_rate < 0.005:   # <0.5%\n",
    "            return int(round(base * 1.75))\n",
    "        if pos_rate < 0.02:    # <2%\n",
    "            return int(round(base * 1.40))\n",
    "        return base\n",
    "\n",
    "    @staticmethod\n",
    "    def _is_xgb(est):\n",
    "        name = est.__class__.__name__.lower(); mod = getattr(est, \"__module__\", \"\")\n",
    "        return \"xgb\" in name or \"xgboost\" in mod or hasattr(est, \"get_xgb_params\")\n",
    "\n",
    "    @staticmethod\n",
    "    def _is_catboost(est):\n",
    "        name = est.__class__.__name__.lower(); mod = getattr(est, \"__module__\", \"\")\n",
    "        return \"catboost\" in name or \"catboost\" in mod or hasattr(est, \"get_all_params\")\n",
    "\n",
    "\n",
    "class StratifiedSubsetClassifier(ClassifierMixin, BaseEstimator):\n",
    "    def __init__(self, estimator, n_samples, random_state=SEED):\n",
    "        self.estimator = estimator\n",
    "        self.n_samples = n_samples and int(n_samples)\n",
    "        self.random_state = random_state\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        y = np.asarray(y)\n",
    "        n_total = len(y)\n",
    "\n",
    "        if self.n_samples is None or self.n_samples >= n_total:\n",
    "            rng = np.random.default_rng(self.random_state)\n",
    "            idx = rng.permutation(n_total)\n",
    "        else:\n",
    "            sss = StratifiedShuffleSplit(\n",
    "                n_splits=1, train_size=self.n_samples, random_state=self.random_state\n",
    "            )\n",
    "            idx, _ = next(sss.split(np.zeros(n_total, dtype=np.int8), y))\n",
    "\n",
    "        Xn = X.iloc[idx]\n",
    "        Xn = Xn.to_numpy(np.float32, copy=False)\n",
    "        yn = y[idx]\n",
    "\n",
    "        self.estimator.fit(Xn, yn)\n",
    "        self.classes_ = getattr(self.estimator, \"classes_\", np.array([0, 1]))\n",
    "        return self\n",
    "\n",
    "    def predict_proba(self, X):\n",
    "        return self.estimator.predict_proba(X)\n",
    "\n",
    "    def predict(self, X):\n",
    "        return self.estimator.predict(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hai lớp StratifiedSubsetClassifierWEval và StratifiedSubsetClassifier được thiết kế như một wrapper thông minh cho các mô hình Boosting (XGBoost, CatBoost, LightGBM), với mục tiêu chính là huấn luyện nhanh hơn trên tập con dữ liệu nhưng vẫn duy trì độ tin cậy về phân phối lớp, khả năng đánh giá, và tính ổn định của mô hình. Ý tưởng cốt lõi nằm ở việc áp dụng Stratified Sampling, tức là lựa chọn mẫu theo cách giữ nguyên tỷ lệ giữa các lớp trong toàn bộ tập dữ liệu, giúp mô hình học được phân bố thật ngay cả khi chỉ dùng một phần nhỏ dataset.\n",
    "\n",
    "Phiên bản nâng cao StratifiedSubsetClassifierWEval bổ sung một cơ chế tách tập validation hợp lý, cũng theo phân tầng, đồng thời có các tham số linh hoạt như valid_size, val_cap_ratio và n_samples, cho phép điều khiển kích thước train/validation sao cho không quá lớn nhưng vẫn đủ đại diện. Lớp này còn tự động chọn metric Early Stopping dựa trên tỷ lệ lớp của validation, ví dụ: nếu dữ liệu bị mất cân bằng mạnh thì ưu tiên sử dụng AUPRC/PRAUC, nếu validation bị “single-class” thì fallback về logloss — đảm bảo thuật toán vẫn hoạt động ổn định trong mọi trường hợp.\n",
    "\n",
    "Trong quá trình huấn luyện, wrapper cũng tự động áp dụng các kỹ thuật xử lý mất cân bằng cho từng loại mô hình:\n",
    "\n",
    "Với XGBoost, tự động tính scale_pos_weight = n_neg / n_pos từ tập train.\n",
    "\n",
    "Với CatBoost, kích hoạt auto_class_weights=\"Balanced\" khi phù hợp.\n",
    "\n",
    "Đồng thời cấu hình Early Stopping đúng chuẩn của từng thư viện, truyền eval_set và giữ mô hình tốt nhất.\n",
    "\n",
    "Toàn bộ pipeline được kiểm soát bởi tham số random_state, đảm bảo các bước chọn mẫu, shuffle, chia validation, và huấn luyện đều tái lập được 100%.\n",
    "\n",
    "Trong khi đó, StratifiedSubsetClassifier là phiên bản rút gọn, chỉ thực hiện việc chọn tập con có phân tầng và huấn luyện trực tiếp mà không liên quan đến validation hay Early Stopping. Lớp này phù hợp khi muốn chạy thử mô hình nhanh hoặc kiểm tra baseline.\n",
    "\n",
    "Tổng thể, hai lớp này giúp tăng tốc quá trình thử nghiệm trên tập dữ liệu lớn, cải thiện sự ổn định trong điều kiện mất cân bằng lớp, tự động hóa tách validation và Early Stopping, đồng thời duy trì tính reproducible trong toàn bộ pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-10T18:58:07.814182Z",
     "iopub.status.busy": "2025-12-10T18:58:07.813678Z",
     "iopub.status.idle": "2025-12-10T18:58:07.960203Z",
     "shell.execute_reply": "2025-12-10T18:58:07.959329Z",
     "shell.execute_reply.started": "2025-12-10T18:58:07.814162Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# ==================== SCORING FUNCTIONS ====================\n",
    "\n",
    "class HostVisibleError(Exception):\n",
    "    pass\n",
    "\n",
    "def single_lab_f1(lab_solution: pl.DataFrame, lab_submission: pl.DataFrame, beta: float = 1) -> float:\n",
    "    label_frames: defaultdict[str, set[int]] = defaultdict(set)\n",
    "    prediction_frames: defaultdict[str, set[int]] = defaultdict(set)\n",
    "\n",
    "    for row in lab_solution.to_dicts():\n",
    "        label_frames[row['label_key']].update(range(row['start_frame'], row['stop_frame']))\n",
    "\n",
    "    for video in lab_solution['video_id'].unique():\n",
    "        active_labels: str = lab_solution.filter(pl.col('video_id') == video)['behaviors_labeled'].first()\n",
    "        active_labels: set[str] = set(json.loads(active_labels))\n",
    "        predicted_mouse_pairs: defaultdict[str, set[int]] = defaultdict(set)\n",
    "\n",
    "        for row in lab_submission.filter(pl.col('video_id') == video).to_dicts():\n",
    "            if ','.join([str(row['agent_id']), str(row['target_id']), row['action']]) not in active_labels:\n",
    "                continue\n",
    "           \n",
    "            new_frames = set(range(row['start_frame'], row['stop_frame']))\n",
    "            new_frames = new_frames.difference(prediction_frames[row['prediction_key']])\n",
    "            prediction_pair = ','.join([str(row['agent_id']), str(row['target_id'])])\n",
    "            if predicted_mouse_pairs[prediction_pair].intersection(new_frames):\n",
    "                raise HostVisibleError('Multiple predictions for the same frame from one agent/target pair')\n",
    "            prediction_frames[row['prediction_key']].update(new_frames)\n",
    "            predicted_mouse_pairs[prediction_pair].update(new_frames)\n",
    "\n",
    "    tps = defaultdict(int)\n",
    "    fns = defaultdict(int)\n",
    "    fps = defaultdict(int)\n",
    "    for key, pred_frames in prediction_frames.items():\n",
    "        action = key.split('_')[-1]\n",
    "        matched_label_frames = label_frames[key]\n",
    "        tps[action] += len(pred_frames.intersection(matched_label_frames))\n",
    "        fns[action] += len(matched_label_frames.difference(pred_frames))\n",
    "        fps[action] += len(pred_frames.difference(matched_label_frames))\n",
    "\n",
    "    distinct_actions = set()\n",
    "    for key, frames in label_frames.items():\n",
    "        action = key.split('_')[-1]\n",
    "        distinct_actions.add(action)\n",
    "        if key not in prediction_frames:\n",
    "            fns[action] += len(frames)\n",
    "\n",
    "    action_f1s = []\n",
    "    for action in distinct_actions:\n",
    "        if tps[action] + fns[action] + fps[action] == 0:\n",
    "            action_f1s.append(0)\n",
    "        else:\n",
    "            action_f1s.append((1 + beta**2) * tps[action] / ((1 + beta**2) * tps[action] + beta**2 * fns[action] + fps[action]))\n",
    "    return sum(action_f1s) / len(action_f1s)\n",
    "\n",
    "def mouse_fbeta(solution: pd.DataFrame, submission: pd.DataFrame, beta: float = 1) -> float:\n",
    "    if len(solution) == 0 or len(submission) == 0:\n",
    "        raise ValueError('Missing solution or submission data')\n",
    "\n",
    "    expected_cols = ['video_id', 'agent_id', 'target_id', 'action', 'start_frame', 'stop_frame']\n",
    "\n",
    "    for col in expected_cols:\n",
    "        if col not in solution.columns:\n",
    "            raise ValueError(f'Solution is missing column {col}')\n",
    "        if col not in submission.columns:\n",
    "            raise ValueError(f'Submission is missing column {col}')\n",
    "\n",
    "    solution: pl.DataFrame = pl.DataFrame(solution)\n",
    "    submission: pl.DataFrame = pl.DataFrame(submission)\n",
    "    assert (solution['start_frame'] <= solution['stop_frame']).all()\n",
    "    assert (submission['start_frame'] <= submission['stop_frame']).all()\n",
    "    solution_videos = set(solution['video_id'].unique())\n",
    "    submission = submission.filter(pl.col('video_id').is_in(solution_videos))\n",
    "\n",
    "    solution = solution.with_columns(\n",
    "        pl.concat_str(\n",
    "            [\n",
    "                pl.col('video_id').cast(pl.Utf8),\n",
    "                pl.col('agent_id').cast(pl.Utf8),\n",
    "                pl.col('target_id').cast(pl.Utf8),\n",
    "                pl.col('action'),\n",
    "            ],\n",
    "            separator='_',\n",
    "        ).alias('label_key'),\n",
    "    )\n",
    "    submission = submission.with_columns(\n",
    "        pl.concat_str(\n",
    "            [\n",
    "                pl.col('video_id').cast(pl.Utf8),\n",
    "                pl.col('agent_id').cast(pl.Utf8),\n",
    "                pl.col('target_id').cast(pl.Utf8),\n",
    "                pl.col('action'),\n",
    "            ],\n",
    "            separator='_',\n",
    "        ).alias('prediction_key'),\n",
    "    )\n",
    "\n",
    "    lab_scores = []\n",
    "    for lab in solution['lab_id'].unique():\n",
    "        lab_solution = solution.filter(pl.col('lab_id') == lab).clone()\n",
    "        lab_videos = set(lab_solution['video_id'].unique())\n",
    "        lab_submission = submission.filter(pl.col('video_id').is_in(lab_videos)).clone()\n",
    "        lab_scores.append(single_lab_f1(lab_solution, lab_submission, beta=beta))\n",
    "\n",
    "    return sum(lab_scores) / len(lab_scores)\n",
    "\n",
    "def score(solution: pd.DataFrame, submission: pd.DataFrame, row_id_column_name: str, beta: float = 1) -> float:\n",
    "    solution = solution.drop(row_id_column_name, axis='columns', errors='ignore')\n",
    "    submission = submission.drop(row_id_column_name, axis='columns', errors='ignore')\n",
    "    return mouse_fbeta(solution, submission, beta=beta)"
   ]
  },
  {
   "attachments": {
    "92284ad7-4d50-496e-9228-0c09776f2648.png": {
     "image/png": "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"
    }
   },
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(Scoring Functions)\n",
    "\n",
    "Phần tính điểm được xây dựng để tái hiện chính xác cách chấm của bài toán \"Mouse Action Detection\". Mỗi dự đoán không chỉ là một nhãn, mà còn gắn với khoảng thời gian liên tục (start_frame → stop_frame) và mỗi mẫu gồm nhiều hành vi đồng thời giữa các cặp chuột (agent–target). Vì vậy metric phải đánh giá theo frame-level thay vì sample-level.\n",
    "\n",
    "Cốt lõi của hệ thống chấm điểm nằm ở hàm single_lab_f1, nơi dữ liệu ground truth và prediction được quy đổi thành tập các frame ứng với từng hành động. Mỗi cặp (video, agent, target, action) được ánh xạ thành một khóa duy nhất gọi là label_key hoặc prediction_key, và sau đó các frame trong khoảng [start_frame, stop_frame) được đưa vào một set. Việc dùng set đảm bảo tính toán chính xác số frame trùng khớp mà không bị double-count.\n",
    "\n",
    "Trong quá trình xử lý từng video, hệ thống còn áp dụng một lớp lọc prediction: chỉ những hành vi nằm trong danh sách các hành vi ground truth của video đó (behaviors_labeled) mới được chấp nhận. Điều này tránh trường hợp mô hình bịa thê hành vi không xuất hiện trong video, vốn sẽ bị phạt nặng. Thêm vào đó, mỗi cặp chuột chỉ được phép đưa ra một dự đoán cho một frame, nếu không sẽ bị ném lỗi HostVisibleError — bảo đảm tính hợp lệ của submission.\n",
    "\n",
    "Sau khi thu được tập frame dự đoán và gán nhãn, thuật toán tính TP / FP / FN theo từng action và gom thành F1 theo công thức Fβ mở rộng.\n",
    "\n",
    "![image.png](attachment:92284ad7-4d50-496e-9228-0c09776f2648.png)\n",
    "\n",
    "Điểm cho một lab là trung bình F1 của tất cả các action trong lab đó.\n",
    "Hàm mouse_fbeta lặp qua từng lab_id, tách submission tương ứng, tính điểm bằng single_lab_f1, rồi cuối cùng lấy trung bình các lab – đây là lý do metric rất nhạy với những lab có ít hành động.\n",
    "\n",
    "Hàm score chỉ đóng vai trò bao bọc lại việc drop cột row_id_column_name và trả về giá trị cuối cùng.\n",
    "\n",
    "Toàn bộ thiết kế giúp mô phỏng đúng yêu cầu của contest:\n",
    "\n",
    "đánh giá theo frame-level thay vì event-level,\n",
    "\n",
    "xử lý theo từng lab để tránh bias do số lượng video khác nhau,\n",
    "\n",
    "kiểm soát chặt chẽ tính hợp lệ của submission,\n",
    "\n",
    "và sử dụng F1 cho dữ liệu hành vi hiếm (imbalanced behaviors)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-10T18:58:07.962248Z",
     "iopub.status.busy": "2025-12-10T18:58:07.962027Z",
     "iopub.status.idle": "2025-12-10T18:58:08.170019Z",
     "shell.execute_reply": "2025-12-10T18:58:08.169405Z",
     "shell.execute_reply.started": "2025-12-10T18:58:07.962231Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# ==================== DATA LOADING ====================\n",
    "\n",
    "train = pd.read_csv('/kaggle/input/MABe-mouse-behavior-detection/train.csv')\n",
    "\n",
    "# drop likely-sleeping MABe22 clips: condition == \"lights on\"\n",
    "train = train.loc[~(train['lab_id'].astype(str).str.contains('MABe22', na=False) &\n",
    "                    train['mouse1_condition'].astype(str).str.lower().eq('lights on'))].copy()\n",
    "\n",
    "train['n_mice'] = 4 - train[['mouse1_strain', 'mouse2_strain', 'mouse3_strain', 'mouse4_strain']].isna().sum(axis=1)\n",
    "\n",
    "test = pd.read_csv('/kaggle/input/MABe-mouse-behavior-detection/test.csv')\n",
    "test['sleeping'] = (\n",
    "    test['lab_id'].astype(str).str.contains('MABe22', na=False) &\n",
    "    test['mouse1_condition'].astype(str).str.lower().eq('lights on')\n",
    ")\n",
    "test['n_mice'] = 4 - test[['mouse1_strain','mouse2_strain','mouse3_strain','mouse4_strain']].isna().sum(axis=1)\n",
    "\n",
    "body_parts_tracked_list = list(np.unique(train.body_parts_tracked))\n",
    "\n",
    "drop_body_parts = ['headpiece_bottombackleft', 'headpiece_bottombackright', 'headpiece_bottomfrontleft', 'headpiece_bottomfrontright', \n",
    "                   'headpiece_topbackleft', 'headpiece_topbackright', 'headpiece_topfrontleft', 'headpiece_topfrontright',                  \n",
    "                   'spine_1', 'spine_2', 'tail_middle_1', 'tail_middle_2', 'tail_midpoint']\n",
    "\n",
    "_sex_cols = [f'mouse{i}_sex' for i in range(1,5)]\n",
    "_train_sex_lut = (train[['video_id'] + _sex_cols].drop_duplicates('video_id')\n",
    "                  .set_index('video_id').to_dict('index'))\n",
    "_test_sex_lut  = (test[['video_id']  + _sex_cols].drop_duplicates('video_id')\n",
    "                  .set_index('video_id').to_dict('index'))\n",
    "_FEATURE_TEMPLATES = {}\n",
    "\n",
    "def generate_mouse_data(dataset, traintest, traintest_directory=None,\n",
    "                        generate_single=True, generate_pair=True):\n",
    "    assert traintest in ['train', 'test']\n",
    "    if traintest_directory is None:\n",
    "        traintest_directory = f\"/kaggle/input/MABe-mouse-behavior-detection/{traintest}_tracking\"\n",
    "\n",
    "    def _to_num(x):\n",
    "        if isinstance(x, (int, np.integer)): return int(x)\n",
    "        m = re.search(r'(\\d+)$', str(x))\n",
    "        return int(m.group(1)) if m else None\n",
    "\n",
    "    for _, row in dataset.iterrows():\n",
    "        lab_id   = row.lab_id\n",
    "        video_id = row.video_id\n",
    "        fps      = float(row.frames_per_second)\n",
    "        n_mice   = int(row.n_mice)\n",
    "        arena_w  = float(row.get('arena_width_cm', np.nan))\n",
    "        arena_h  = float(row.get('arena_height_cm', np.nan))\n",
    "        sleeping = bool(getattr(row, 'sleeping', False))\n",
    "        arena_shape = row.get('arena_shape', 'rectangular')\n",
    "\n",
    "        if not isinstance(row.behaviors_labeled, str):\n",
    "            continue\n",
    "\n",
    "        # ---- tracking ----\n",
    "        path = f\"{traintest_directory}/{lab_id}/{video_id}.parquet\"\n",
    "        vid = pd.read_parquet(path)\n",
    "        if len(np.unique(vid.bodypart)) > 5:\n",
    "            vid = vid.query(\"~ bodypart.isin(@drop_body_parts)\")\n",
    "        pvid = vid.pivot(columns=['mouse_id','bodypart'], index='video_frame', values=['x','y'])\n",
    "        del vid\n",
    "        pvid = pvid.reorder_levels([1,2,0], axis=1).T.sort_index().T\n",
    "        pvid = (pvid / float(row.pix_per_cm_approx)).astype('float32', copy=False)\n",
    "\n",
    "        # available mouse_id labels in tracking (could be ints or strings)\n",
    "        avail = list(pvid.columns.get_level_values('mouse_id').unique())\n",
    "        avail_set = set(avail) | set(map(str, avail)) | {f\"mouse{_to_num(a)}\" for a in avail if _to_num(a) is not None}\n",
    "\n",
    "        def _resolve(agent_str):\n",
    "            \"\"\"Return the matching mouse_id label present in pvid (int or str), or None.\"\"\"\n",
    "            m = re.search(r'(\\d+)$', str(agent_str))\n",
    "            cand = [agent_str]\n",
    "            if m:\n",
    "                n = int(m.group(1))\n",
    "                cand = [n, n-1, str(n), f\"mouse{n}\", agent_str]  # try 1-based, 0-based, str, canonical\n",
    "            for c in cand:\n",
    "                if c in avail_set:  # compare within unified set\n",
    "                    # return the exact label used in columns\n",
    "                    if c in set(avail): return c\n",
    "                    # map back to the exact label that exists (int preferred)\n",
    "                    for a in avail:\n",
    "                        if str(a) == str(c) or f\"mouse{_to_num(a)}\" == str(c):\n",
    "                            return a\n",
    "            return None\n",
    "\n",
    "        # ---- behaviors ----\n",
    "        vb = json.loads(row.behaviors_labeled)\n",
    "        vb = sorted(list({b.replace(\"'\", \"\") for b in vb}))\n",
    "        vb = pd.DataFrame([b.split(',') for b in vb], columns=['agent','target','action'])\n",
    "        vb['agent']  = vb['agent'].astype(str)\n",
    "        vb['target'] = vb['target'].astype(str)\n",
    "        vb['action'] = vb['action'].astype(str).str.lower()\n",
    "\n",
    "        if traintest == 'train':\n",
    "            try:\n",
    "                annot = pd.read_parquet(path.replace('train_tracking', 'train_annotation'))\n",
    "            except FileNotFoundError:\n",
    "                continue\n",
    "\n",
    "        def _mk_meta(index, agent_id, target_id):\n",
    "            m = pd.DataFrame({\n",
    "                'lab_id':        lab_id,\n",
    "                'video_id':      video_id,\n",
    "                'agent_id':      agent_id,\n",
    "                'target_id':     target_id,\n",
    "                'video_frame':   index.astype('int32', copy=False),\n",
    "                'frames_per_second': np.float32(fps),\n",
    "                'sleeping':      sleeping,\n",
    "                'arena_shape':   arena_shape,\n",
    "                'arena_width_cm': np.float32(arena_w),\n",
    "                'arena_height_cm': np.float32(arena_h),\n",
    "                'n_mice':        np.int8(n_mice),\n",
    "            })\n",
    "            for c in ('lab_id','video_id','agent_id','target_id','arena_shape'):\n",
    "                m[c] = m[c].astype('category')\n",
    "            return m\n",
    "\n",
    "        # ---------- SINGLE ----------\n",
    "        if generate_single:\n",
    "            vb_single = vb.query(\"target == 'self'\")\n",
    "            for agent_str in pd.unique(vb_single['agent']):\n",
    "                col_lab = _resolve(agent_str)\n",
    "                if col_lab is None:\n",
    "                    # if verbose: print(f\"[skip single] {video_id} missing {agent_str} in tracking (avail={sorted(avail)})\")\n",
    "                    continue\n",
    "                actions = sorted(vb_single.loc[vb_single['agent'].eq(agent_str), 'action'].unique().tolist())\n",
    "                if not actions:\n",
    "                    continue\n",
    "\n",
    "                single = pvid.loc[:, col_lab]\n",
    "                meta_df = _mk_meta(single.index, agent_str, 'self')\n",
    "\n",
    "                if traintest == 'train':\n",
    "                    a_num = _to_num(col_lab)\n",
    "                    y = pd.DataFrame(False, index=single.index.astype('int32', copy=False), columns=actions)\n",
    "                    a_sub = annot.query(\"(agent_id == @a_num) & (target_id == @a_num)\")\n",
    "                    for i in range(len(a_sub)):\n",
    "                        ar = a_sub.iloc[i]\n",
    "                        a = str(ar.action).lower()\n",
    "                        if a in y.columns:\n",
    "                            y.loc[int(ar['start_frame']):int(ar['stop_frame']), a] = True\n",
    "                    yield 'single', single, meta_df, y\n",
    "                else:\n",
    "                    yield 'single', single, meta_df, actions\n",
    "\n",
    "        # ---------- PAIR (ONLY LABELED PAIRS) ----------\n",
    "        if generate_pair:\n",
    "            vb_pair = vb.query(\"target != 'self'\")\n",
    "            if len(vb_pair) > 0:\n",
    "                allowed_pairs = set(map(tuple, vb_pair[['agent','target']].itertuples(index=False, name=None)))\n",
    "\n",
    "                for agent_num, target_num in itertools.permutations(\n",
    "                        np.unique(pvid.columns.get_level_values('mouse_id')), 2):\n",
    "                    agent_str = f\"mouse{_to_num(agent_num)}\"\n",
    "                    target_str = f\"mouse{_to_num(target_num)}\"\n",
    "                    if (agent_str, target_str) not in allowed_pairs:\n",
    "                        continue\n",
    "\n",
    "                    a_col = _resolve(agent_str)\n",
    "                    b_col = _resolve(target_str)\n",
    "                    if a_col is None or b_col is None:\n",
    "                        # if verbose: print(f\"[skip pair] {video_id} missing {agent_str}->{target_str}\")\n",
    "                        continue\n",
    "\n",
    "                    actions = sorted(\n",
    "                        vb_pair.query(\"(agent == @agent_str) & (target == @target_str)\")['action'].unique().tolist()\n",
    "                    )\n",
    "                    if not actions:\n",
    "                        continue\n",
    "\n",
    "                    pair_xy = pd.concat([pvid[a_col], pvid[b_col]], axis=1, keys=['A','B'])\n",
    "                    meta_df = _mk_meta(pair_xy.index, agent_str, target_str)\n",
    "\n",
    "                    if traintest == 'train':\n",
    "                        a_num = _to_num(a_col); b_num = _to_num(b_col)\n",
    "                        y = pd.DataFrame(False, index=pair_xy.index.astype('int32', copy=False), columns=actions)\n",
    "                        a_sub = annot.query(\"(agent_id == @a_num) & (target_id == @b_num)\")\n",
    "                        for i in range(len(a_sub)):\n",
    "                            ar = a_sub.iloc[i]\n",
    "                            a = str(ar.action).lower()\n",
    "                            if a in y.columns:\n",
    "                                y.loc[int(ar['start_frame']):int(ar['stop_frame']), a] = True\n",
    "                        yield 'pair', pair_xy, meta_df, y\n",
    "                    else:\n",
    "                        yield 'pair', pair_xy, meta_df, actions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Khởi Tạo và Lọc Dữ liệu (Data Initialization and Filtering)\n",
    "Tải Dữ liệu Gốc: Code bắt đầu bằng việc tải hai tập dữ liệu chính: train.csv (huấn luyện) và test.csv (kiểm thử).\n",
    "Lọc Dữ liệu Ngủ: Một bước tiền xử lý quan trọng được thực hiện trên tập train là loại bỏ các clip từ bộ MABe22 được quay trong điều kiện \"lights on\" (thường là thời gian chuột nghỉ/ngủ), vì những clip này không chứa hành vi đa dạng. Tập test chỉ được đánh dấu cột sleeping chứ không bị loại bỏ.\n",
    "Tính Số Lượng Chuột (n_mice): Xác định số lượng chuột thực tế trong mỗi video bằng cách đếm các cột strain không bị thiếu (NaN).\n",
    "Loại bỏ Điểm Theo Dõi: Danh sách drop_body_parts định nghĩa các bộ phận cơ thể (tracking points) sẽ bị loại bỏ sau này, thường là các điểm ít thông tin hoặc gây nhiễu.\n",
    "\n",
    "2. Hàm Xử Lý Dữ Liệu Cốt Lõi: generate_mouse_data\n",
    "Đây là một hàm generator (hàm sinh) có nhiệm vụ lặp qua từng video và tạo ra các mẫu dữ liệu (data samples) ở cấp độ frame-by-frame, được chuẩn hóa theo hai loại: Hành vi Đơn và Hành vi Cặp.\n",
    "\n",
    "A. Tải và Chuẩn hóa Dữ liệu Tọa độ (Tracking Data)\n",
    "Tải Tọa độ Thô: Đối với mỗi video, code tải tệp .parquet chứa dữ liệu theo dõi tọa độ $x, y$ của các body parts theo thời gian.\n",
    "Chuyển đổi Định dạng: Dữ liệu được chuyển đổi thành định dạng \"rộng\" (wide format) trong DataFrame pvid, nơi các cột được tổ chức theo cấp độ: (mouse_id, bodypart, x/y). \n",
    "Index là video_frame.\n",
    "Chuẩn hóa Đơn vị: Tọa độ pixel thô được chia cho hệ số pix_per_cm_approx để chuyển đổi tọa độ từ pixel sang centimet (cm), giúp dữ liệu có ý nghĩa vật lý và dễ so sánh hơn.\n",
    "\n",
    "B. Ánh xạ ID Chuột (_resolve)\n",
    "Một bước thiết yếu là ánh xạ (mapping) \n",
    "ID chuột được sử dụng trong nhãn hành vi (mouse1, mouse2, v.v.) với ID chuột thực sự có trong dữ liệu tọa độ (1, 2, '1', '2', v.v.). \n",
    "Hàm _resolve đảm bảo tính nhất quán giữa dữ liệu hành vi và dữ liệu tọa độ.\n",
    "\n",
    "C. Trích xuất Mẫu Dữ liệu và Nhãn\n",
    "Hàm này tạo và trả về (yield) các mẫu dữ liệu đã được xử lý:\n",
    "Mẫu Hành vi Đơn (target == 'self'):\n",
    "* Features (X): Chọn dữ liệu tọa độ của một con chuột (Agent A).\n",
    "* Nhãn (Y) (Chỉ áp dụng cho train): Dữ liệu annotation chi tiết được tải và chuyển thành DataFrame boolean, đánh dấu True cho các frame mà hành vi đơn lẻ (ví dụ: grooming, sniffing) đang diễn ra.\n",
    "* Đầu ra: Trả về features (tọa độ A), metadata, và nhãn Y (nếu là train).\n",
    "\n",
    "Mẫu Hành vi Cặp (target != 'self'):\n",
    "* Lọc Cặp: Chỉ xử lý các cặp chuột (Agent A, Target B) đã được gán nhãn tương tác.\n",
    "* Features (X): Ghép (concatenate) dữ liệu tọa độ của hai con chuột (Agent A và Target B) thành một DataFrame duy nhất.\n",
    "* Nhãn (Y) (Chỉ áp dụng cho train): Nhãn hành vi tương tác (ví dụ: chase, attack) được ánh xạ thành DataFrame boolean tương ứng.\n",
    "* Đầu ra: Trả về features (tọa độ A+B), metadata, và nhãn Y (nếu là train)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-10T18:58:08.171158Z",
     "iopub.status.busy": "2025-12-10T18:58:08.170860Z",
     "iopub.status.idle": "2025-12-10T18:58:08.181025Z",
     "shell.execute_reply": "2025-12-10T18:58:08.180402Z",
     "shell.execute_reply.started": "2025-12-10T18:58:08.171119Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# ==================== ADAPTIVE THRESHOLDING ====================\n",
    "\n",
    "def predict_multiclass_adaptive(pred, meta, action_thresholds=defaultdict(lambda: 0.27)):\n",
    "    \"\"\"Adaptive thresholding per action + temporal smoothing\"\"\"\n",
    "    # Apply temporal smoothing\n",
    "    pred_smoothed = pred.rolling(window=5, min_periods=1, center=True).mean()\n",
    "    \n",
    "    ama = np.argmax(pred_smoothed, axis=1)\n",
    "    \n",
    "    max_probs = pred_smoothed.max(axis=1)\n",
    "    threshold_mask = np.zeros(len(pred_smoothed), dtype=bool)\n",
    "    for i, action in enumerate(pred_smoothed.columns):\n",
    "        action_mask = (ama == i)\n",
    "        threshold = action_thresholds.get(action, 0.27)\n",
    "        threshold_mask |= (action_mask & (max_probs >= threshold))\n",
    "    \n",
    "    ama = np.where(threshold_mask, ama, -1)\n",
    "    ama = pd.Series(ama, index=meta.video_frame)\n",
    "    \n",
    "    changes_mask = (ama != ama.shift(1)).values\n",
    "    ama_changes = ama[changes_mask]\n",
    "    meta_changes = meta[changes_mask]\n",
    "    mask = ama_changes.values >= 0\n",
    "    mask[-1] = False\n",
    "    \n",
    "    submission_part = pd.DataFrame({\n",
    "        'video_id': meta_changes['video_id'][mask].values,\n",
    "        'agent_id': meta_changes['agent_id'][mask].values,\n",
    "        'target_id': meta_changes['target_id'][mask].values,\n",
    "        'action': pred.columns[ama_changes[mask].values],\n",
    "        'start_frame': ama_changes.index[mask],\n",
    "        'stop_frame': ama_changes.index[1:][mask[:-1]]\n",
    "    })\n",
    "    \n",
    "    stop_video_id = meta_changes['video_id'][1:][mask[:-1]].values\n",
    "    stop_agent_id = meta_changes['agent_id'][1:][mask[:-1]].values\n",
    "    stop_target_id = meta_changes['target_id'][1:][mask[:-1]].values\n",
    "    \n",
    "    for i in range(len(submission_part)):\n",
    "        video_id = submission_part.video_id.iloc[i]\n",
    "        agent_id = submission_part.agent_id.iloc[i]\n",
    "        target_id = submission_part.target_id.iloc[i]\n",
    "        if i < len(stop_video_id):\n",
    "            if stop_video_id[i] != video_id or stop_agent_id[i] != agent_id or stop_target_id[i] != target_id:\n",
    "                new_stop_frame = meta.query(\"(video_id == @video_id)\").video_frame.max() + 1\n",
    "                submission_part.iat[i, submission_part.columns.get_loc('stop_frame')] = new_stop_frame\n",
    "        else:\n",
    "            new_stop_frame = meta.query(\"(video_id == @video_id)\").video_frame.max() + 1\n",
    "            submission_part.iat[i, submission_part.columns.get_loc('stop_frame')] = new_stop_frame\n",
    "    \n",
    "    # Filter out very short events (likely noise)\n",
    "    duration = submission_part.stop_frame - submission_part.start_frame\n",
    "    submission_part = submission_part[duration >= 3].reset_index(drop=True)\n",
    "    \n",
    "    if len(submission_part) > 0:\n",
    "        assert (submission_part.stop_frame > submission_part.start_frame).all(), 'stop <= start'\n",
    "    \n",
    "    if verbose: print(f'  actions found: {len(submission_part)}')\n",
    "    return submission_part"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hàm predict_multiclass_adaptive() thực hiện toàn bộ bước hậu xử lý dự đoán đa lớp bằng cách kết hợp ba kỹ thuật chính: làm mượt theo thời gian, ngưỡng thích ứng theo từng hành động và tái cấu trúc thành các phân đoạn hợp lệ. Trước hết, dự đoán frame-level được làm mượt bằng trung bình trượt 5 frame để giảm nhiễu và hạn chế tình trạng mô hình nhảy liên tục giữa các hành động. Sau đó, hàm áp dụng “adaptive thresholding”, tức là mỗi action được kiểm tra với một ngưỡng xác suất riêng nhằm tránh các kích hoạt giả khi xác suất cao tương đối nhưng vẫn thấp tuyệt đối, đặc biệt hiệu quả với các hành động hiếm. Khi xác định được action hợp lệ tại từng frame, hàm chuyển chuỗi dự đoán thành các phân đoạn liên tục bằng cách phát hiện các điểm thay đổi nhãn (state transition) để tạo start_frame và stop_frame. Tiếp theo, hàm xử lý các trường hợp phân đoạn bị lệch video/agent/target – thường phát sinh do smoothing – bằng cách điều chỉnh lại điểm kết thúc sao cho mỗi đoạn hoàn toàn nằm trong đúng video và đúng đối tượng. Cuối cùng, các đoạn có độ dài quá ngắn (dưới 3 frame) bị loại bỏ vì gần như luôn là nhiễu, giúp tăng độ tin cậy của kết quả. Kết quả trả về là một bảng sự kiện chuẩn hóa với video_id, agent_id, action, và start–stop frame, sẵn sàng dùng cho submission."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Adaptive thresholding là kỹ thuật dùng để quyết định xem một hành động có thật sự xảy ra hay không dựa trên xác suất dự đoán theo từng khung hình. Thay vì chọn hành động có xác suất cao nhất một cách trực tiếp, kỹ thuật này áp dụng các ngưỡng riêng cho từng hành động. Mỗi hành động sẽ có một ngưỡng tối thiểu để được xem là hợp lệ. Điều này giúp giảm nhiễu và hạn chế các dự đoán sai lệch ở những hành động có xác suất thấp.\n",
    "\n",
    "Bên cạnh đó, dự đoán theo thời gian thường dao động và dễ bị nhiễu. Vì vậy phương pháp này sử dụng bước làm mượt theo thời gian bằng cửa sổ trượt. Việc làm mượt giúp xác suất ổn định hơn và phản ánh xu hướng thực sự của hành động thay vì phản ứng với các điểm bất thường tức thời.\n",
    "\n",
    "Sau khi chọn được hành động hợp lệ theo ngưỡng, mô hình tiến hành phát hiện điểm thay đổi hành động bằng cách so sánh dự đoán giữa các khung hình liên tiếp. Mỗi lần hành động thay đổi sẽ đánh dấu bắt đầu một sự kiện mới. Khi hành động mới xuất hiện, hệ thống xác định khung hình bắt đầu và khung hình kết thúc nhằm tạo thành một sự kiện hoàn chỉnh.\n",
    "\n",
    "Kỹ thuật này cũng đảm bảo rằng các sự kiện ngắn bất thường không được đưa vào kết quả cuối cùng. Những sự kiện có độ dài quá ngắn thường là nhiễu nên sẽ bị loại bỏ. Cuối cùng thuật toán bảo đảm tính nhất quán giữa video agent và target để tránh các đoạn sự kiện bị đóng sai video.\n",
    "\n",
    "Nhờ áp dụng ngưỡng theo từng hành động, làm mượt thời gian và kiểm soát chất lượng sự kiện, adaptive thresholding giúp tăng độ chính xác và độ ổn định của kết quả dự đoán trong các bài toán nhận dạng hành động theo chuỗi thời gian."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-10T18:58:08.182339Z",
     "iopub.status.busy": "2025-12-10T18:58:08.181971Z",
     "iopub.status.idle": "2025-12-10T18:58:08.218021Z",
     "shell.execute_reply": "2025-12-10T18:58:08.217442Z",
     "shell.execute_reply.started": "2025-12-10T18:58:08.182316Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# ==================== ADVANCED FEATURE ENGINEERING (FPS-AWARE) ====================\n",
    "\n",
    "def safe_rolling(series, window, func, min_periods=None):\n",
    "    \"\"\"\n",
    "    Thực hiện rolling (cửa sổ trượt) một cách an toàn khi dữ liệu có NaN.\n",
    "\n",
    "    - Không làm thay đổi series gốc\n",
    "    - Chỉ tạo ra FEATURE mới đã được làm mượt / thống kê\n",
    "    - Cho phép thiếu dữ liệu trong window (tránh ra toàn NaN)\n",
    "    \"\"\"\n",
    "    # Nếu không chỉ định min_periods:\n",
    "    # → cho phép thiếu dữ liệu trong cửa sổ\n",
    "    # → mặc định cần tối thiểu 1/4 số điểm của window\n",
    "    if min_periods is None:\n",
    "        min_periods = max(1, window // 4)\n",
    "\n",
    "    # rolling với:\n",
    "    # - window: số frame trong cửa sổ\n",
    "    # - min_periods: số điểm tối thiểu để vẫn tính được\n",
    "    # - center=True: cửa sổ đặt giữa frame hiện tại (có dùng cả quá khứ + tương lai)\n",
    "    # - apply(func, raw=True): func nhận numpy array (nhanh hơn)\n",
    "    return series.rolling(\n",
    "        window,\n",
    "        min_periods=min_periods,\n",
    "        center=True\n",
    "    ).apply(func, raw=True)\n",
    "\n",
    "\n",
    "def _scale(n_frames_at_30fps, fps, ref=30.0):\n",
    "    \"\"\"\n",
    "    Scale số frame được định nghĩa theo chuẩn 30fps\n",
    "    sang số frame tương ứng với fps thực của video.\n",
    "\n",
    "    Dùng cho:\n",
    "    - window size của rolling\n",
    "    - smoothing\n",
    "    (KHÔNG dùng cho shift có hướng)\n",
    "    \"\"\"\n",
    "    # Công thức:\n",
    "    # n_frames_new = n_frames_30fps * fps / 30\n",
    "    # round để giữ đúng độ dài theo thời gian\n",
    "    # max(1, ...) để window không bao giờ = 0 frame\n",
    "    return max(\n",
    "        1,\n",
    "        int(round(n_frames_at_30fps * float(fps) / ref))\n",
    "    )\n",
    "\n",
    "\n",
    "def _scale_signed(n_frames_at_30fps, fps, ref=30.0):\n",
    "    \"\"\"\n",
    "    Scale số frame CÓ DẤU (+/-) theo fps,\n",
    "    dùng cho shift (dịch dữ liệu theo thời gian).\n",
    "\n",
    "    Đảm bảo:\n",
    "    - Giữ đúng hướng (quá khứ / tương lai)\n",
    "    - Giữ đúng độ dài theo thời gian\n",
    "    - Shift = 0 thì vẫn là 0 (không bị ép thành 1)\n",
    "    \"\"\"\n",
    "\n",
    "    # Trường hợp đặc biệt:\n",
    "    # Nếu không shift thì trả về 0 ngay\n",
    "    # (tránh bị ép thành ±1 frame)\n",
    "    if n_frames_at_30fps == 0:\n",
    "        return 0\n",
    "\n",
    "    # Lấy dấu của shift:\n",
    "    # +1 → nhìn về tương lai\n",
    "    # -1 → nhìn về quá khứ\n",
    "    s = 1 if n_frames_at_30fps > 0 else -1\n",
    "\n",
    "    # Scale độ lớn của shift (bỏ dấu trước)\n",
    "    # - abs(...) để lấy độ lớn\n",
    "    # - scale theo fps\n",
    "    # - round để tránh lệch thời gian\n",
    "    # - max(1, ...) để |shift| ≥ 1 thì không bao giờ về 0\n",
    "    mag = max(\n",
    "        1,\n",
    "        int(round(abs(n_frames_at_30fps) * float(fps) / ref))\n",
    "    )\n",
    "\n",
    "    # Ghép lại dấu × độ lớn\n",
    "    return s * mag\n",
    "\n",
    "\n",
    "def _fps_from_meta(meta_df, fallback_lookup, default_fps=30.0):\n",
    "    if 'frames_per_second' in meta_df.columns and pd.notnull(meta_df['frames_per_second']).any():\n",
    "        return float(meta_df['frames_per_second'].iloc[0])\n",
    "    vid = meta_df['video_id'].iloc[0]\n",
    "    return float(fallback_lookup.get(vid, default_fps))\n",
    "\n",
    "def _speed(cx: pd.Series, cy: pd.Series, fps: float) -> pd.Series:\n",
    "    return np.hypot(cx.diff(), cy.diff()).fillna(0.0) * float(fps)\n",
    "\n",
    "def _roll_future_mean(s: pd.Series, w: int, min_p: int = 1) -> pd.Series:\n",
    "    \"\"\"\n",
    "    Rolling MEAN của TƯƠNG LAI.\n",
    "\n",
    "    Ý nghĩa:\n",
    "    - Tại frame t, future mean cho biết:\n",
    "        → trong vài frame tới, giá trị này TRUNG BÌNH sẽ là bao nhiêu\n",
    "    - Phản ánh XU HƯỚNG hành vi sắp xảy ra:\n",
    "        + speed future mean ↑  → sắp tăng tốc / chạy\n",
    "        + speed future mean ↓  → sắp chậm lại / dừng / groom\n",
    "        + distance future mean ↓ → sắp tiếp cận\n",
    "        + angle future mean ↑ → sắp quay hướng\n",
    "\n",
    "    Mục đích trong ML:\n",
    "    - Giúp model \"nhìn trước\" chuyển tiếp hành vi (transition)\n",
    "    - Giảm nhiễu ở biên hành vi\n",
    "    - Phù hợp với bài toán video OFFLINE (có toàn bộ chuỗi)\n",
    "    \"\"\"\n",
    "    # mean trên đoạn [t, t+w-1]\n",
    "    return s.iloc[::-1].rolling(w, min_periods=min_p).mean().iloc[::-1]\n",
    "\n",
    "\n",
    "def _roll_future_var(s: pd.Series, w: int, min_p: int = 2) -> pd.Series:\n",
    "    \"\"\"\n",
    "    Rolling VARIANCE của TƯƠNG LAI.\n",
    "\n",
    "    Ý nghĩa:\n",
    "    - Tại frame t, future variance cho biết:\n",
    "        → trong vài frame tới, giá trị có ỔN ĐỊNH hay DAO ĐỘNG mạnh không\n",
    "    - Phản ánh MỨC ĐỘ CHUYỂN PHA của hành vi:\n",
    "        + var nhỏ  → hành vi sắp tới ổn định (đang duy trì)\n",
    "        + var lớn  → hành vi sắp thay đổi / chuyển trạng thái\n",
    "\n",
    "    Mục đích trong ML:\n",
    "    - Phát hiện điểm BẮT ĐẦU / KẾT THÚC hành vi\n",
    "    - Phân biệt đoạn ổn định vs đoạn chuyển tiếp\n",
    "    - Kết hợp rất mạnh với future mean (hướng + độ chắc chắn)\n",
    "\n",
    "    min_p = 2:\n",
    "    - Phương sai cần tối thiểu 2 điểm để có ý nghĩa\n",
    "    \"\"\"\n",
    "    # var trên đoạn [t, t+w-1]\n",
    "    return s.iloc[::-1].rolling(w, min_periods=min_p).var().iloc[::-1]\n",
    "\n",
    "\n",
    "\n",
    "def add_curvature_features(X, center_x, center_y, fps):\n",
    "    \"\"\"\n",
    "    Tạo các đặc trưng liên quan đến “đi thẳng vs đi cong” và “đổi hướng nhiều hay ít”.\n",
    "    Các cửa sổ được scale theo fps để ~ giữ nguyên ý nghĩa theo GIÂY giữa các video.\n",
    "    \"\"\"\n",
    "    # Vận tốc theo frame (dx/frame, dy/frame). Nếu tọa độ là cm thì đây là cm/frame.\n",
    "    vel_x = center_x.diff()\n",
    "    vel_y = center_y.diff()\n",
    "\n",
    "    # Gia tốc theo frame (thay đổi vận tốc). Bắt được “rẽ / quay / đổi hướng” tốt hơn speed thuần.\n",
    "    acc_x = vel_x.diff()\n",
    "    acc_y = vel_y.diff()\n",
    "\n",
    "    # cross_prod = v_x*a_y - v_y*a_x ~ độ “xoay” của vector vận tốc (rẽ trái/phải mạnh hay yếu)\n",
    "    cross_prod = vel_x * acc_y - vel_y * acc_x\n",
    "\n",
    "    # |v| = độ lớn vận tốc theo frame. Khi |v| nhỏ, hướng/curvature dễ nhiễu nên có epsilon ở dưới.\n",
    "    vel_mag = np.sqrt(vel_x**2 + vel_y**2)\n",
    "\n",
    "    # curvature ~ |v x a| / |v|^3  (độ cong hình học của quỹ đạo)\n",
    "    # Ý nghĩa hành vi:\n",
    "    # - curvature nhỏ: quỹ đạo gần thẳng, ít lượn\n",
    "    # - curvature lớn: quỹ đạo cong, rẽ gấp, lượn, quay vòng\n",
    "    #\n",
    "    # Map hành vi (gợi ý):\n",
    "    # - curv cao: explore/forage (đi vòng, lượn quanh), turning, approach-avoid,\n",
    "    #             nhiều tình huống social interaction khi vòng quanh đối tượng\n",
    "    # - curv thấp: locomotion thẳng (walk/run thẳng), chạy đuổi theo hướng ổn định,\n",
    "    #              di chuyển tuyến tính từ A→B\n",
    "    curvature = np.abs(cross_prod) / (vel_mag**3 + 1e-6)  # tương đối “ít phụ thuộc scale thời gian”\n",
    "\n",
    "    # Làm mượt curvature theo 2 thang thời gian:\n",
    "    # w=30 ~ 1 giây @30fps, w=60 ~ 2 giây @30fps (sau đó scale theo fps thực)\n",
    "    for w in [30, 60]:\n",
    "        ws = _scale(w, fps)\n",
    "\n",
    "        # curv_mean_30: “độ cong trung bình ~1s vừa qua”\n",
    "        # - cao: rẽ/liên tục đổi hướng trong ngắn hạn (zig-zag, lượn gấp, đảo hướng)\n",
    "        # - thấp: đi thẳng trong ngắn hạn\n",
    "        #\n",
    "        # curv_mean_60: “độ cong trung bình ~2s vừa qua”\n",
    "        # - cao: xu hướng lượn/vòng kéo dài (đi vòng quanh 1 vùng/đối tượng)\n",
    "        # - thấp: đi thẳng ổn định hoặc đứng yên\n",
    "        #\n",
    "        # Map hành vi (gợi ý):\n",
    "        # - (curv_mean_30 cao, curv_mean_60 thấp): rẽ/đổi hướng ngắn (1 cú quay đầu rồi đi tiếp)\n",
    "        # - (cả 2 cao): explore/lượn vòng, vòng quanh bạn chuột khác, patterns kiểu “circling”\n",
    "        # - (cả 2 thấp): đi thẳng, chạy thẳng, hoặc đứng (cần thêm speed để phân biệt đứng vs đi thẳng)\n",
    "        X[f'curv_mean_{w}'] = curvature.rolling(ws, min_periods=max(1, ws // 6)).mean()\n",
    "\n",
    "    # Góc hướng chuyển động tại mỗi frame (radian). Cho biết “đang đi theo hướng nào”.\n",
    "    angle = np.arctan2(vel_y, vel_x)\n",
    "\n",
    "    # Mức thay đổi hướng giữa 2 frame liên tiếp (|Δgóc|).\n",
    "    # Ý nghĩa: đổi hướng càng nhiều thì angle_change càng lớn.\n",
    "    #\n",
    "    # Map hành vi (gợi ý):\n",
    "    # - angle_change cao: turning liên tục, zig-zag, head/body jitter khi sniff/explore,\n",
    "    #                     các đoạn “do dự/đảo hướng” trước khi chuyển hành vi\n",
    "    # - angle_change thấp: đi thẳng/ổn định hướng\n",
    "    #\n",
    "    # Lưu ý kỹ thuật: arctan2 có wrap-around ±π nên đôi lúc diff() tạo spike giả.\n",
    "    angle_change = np.abs(angle.diff())\n",
    "\n",
    "    # turn_rate_30: tổng |Δgóc| trong ~1 giây (rolling sum)\n",
    "    # - dùng SUM (không phải mean) để bắt “quay nhiều lần nhỏ” trong 1s (jitter/dao động hướng).\n",
    "    # - cao: đổi hướng liên tục (thường gặp ở explore/sniff, grooming nhẹ khi di chuyển lắt léo,\n",
    "    #        hoặc social interaction kiểu vòng quanh/né tránh)\n",
    "    # - thấp: hướng ổn định (đi/chạy thẳng)\n",
    "    w = 30\n",
    "    ws = _scale(w, fps)\n",
    "    X[f'turn_rate_{w}'] = angle_change.rolling(ws, min_periods=max(1, ws // 6)).sum()\n",
    "\n",
    "    # Gợi ý cách “đọc” 3 feature này cùng nhau (để bạn map nhanh hành vi):\n",
    "    # - curv_mean_30 thấp & turn_rate_30 thấp  -> locomotion thẳng/ổn định hướng\n",
    "    # - curv_mean_30 cao  & curv_mean_60 thấp -> 1 cú rẽ/quay đầu ngắn\n",
    "    # - curv_mean_30 cao  & curv_mean_60 cao  -> lượn vòng/explore quanh vùng/đối tượng\n",
    "    # - turn_rate_30 rất cao nhưng speed thấp  -> có thể là jitter/pose-noise hoặc grooming tại chỗ\n",
    "    #                                            (cần kết hợp speed + displacement để xác nhận)\n",
    "\n",
    "    return X\n",
    "\n",
    "\n",
    "def add_multiscale_features(X, center_x, center_y, fps):\n",
    "    \"\"\"\n",
    "    Tạo các đặc trưng thời gian đa thang (multi-scale) dựa trên tốc độ di chuyển.\n",
    "\n",
    "    - Tốc độ được tính theo cm/s\n",
    "    - Cửa sổ thời gian (window) được scale theo fps để đảm bảo\n",
    "      các video khác fps vẫn tương đương về thời gian thực\n",
    "    \"\"\"\n",
    "\n",
    "    # ------------------------------------------------------------------\n",
    "    # TÍNH TỐC ĐỘ TỨC THỜI (INSTANTANEOUS SPEED)\n",
    "    # ------------------------------------------------------------------\n",
    "    # diff(): dịch chuyển giữa 2 frame liên tiếp (cm/frame)\n",
    "    # sqrt(dx^2 + dy^2): độ dài vector dịch chuyển\n",
    "    # * fps: đổi đơn vị từ cm/frame → cm/s\n",
    "    #\n",
    "    # speed phản ánh mức độ \"hoạt động\" tại từng frame\n",
    "    speed = np.sqrt(center_x.diff()**2 + center_y.diff()**2) * float(fps)\n",
    "\n",
    "    # ------------------------------------------------------------------\n",
    "    # CÁC THANG THỜI GIAN (scale chuẩn hoá theo 30 fps)\n",
    "    # 10  : ngắn hạn  (~0.3 s)  → bắt burst, chuyển động tức thời\n",
    "    # 40  : trung hạn (~1.3 s)  → hành vi ổn định ngắn\n",
    "    # 160 : dài hạn   (~5.3 s)  → xu hướng hoạt động tổng thể\n",
    "    # ------------------------------------------------------------------\n",
    "    scales = [10, 40, 160]\n",
    "\n",
    "    for scale in scales:\n",
    "        # ws (window size): số frame tương ứng với scale tại fps hiện tại\n",
    "        ws = _scale(scale, fps)\n",
    "\n",
    "        # Chỉ tính khi chuỗi đủ dài để tránh toàn NaN\n",
    "        if len(speed) >= ws:\n",
    "\n",
    "            # ----------------------------------------------------------\n",
    "            # sp_m{scale}: SPEED MEAN (tốc độ trung bình)\n",
    "            # ----------------------------------------------------------\n",
    "            # Ý nghĩa:\n",
    "            # - Mức độ di chuyển trung bình trong khoảng thời gian này\n",
    "            # - Giá trị lớn → di chuyển nhiều / hoạt động mạnh\n",
    "            # - Giá trị nhỏ → đứng yên / ít vận động\n",
    "            #\n",
    "            # Ví dụ:\n",
    "            # sp_m10  : tốc độ trung bình rất ngắn hạn (burst)\n",
    "            # sp_m160 : tốc độ nền dài hạn (baseline activity)\n",
    "            X[f'sp_m{scale}'] = speed.rolling(\n",
    "                ws,\n",
    "                min_periods=max(1, ws // 4)  # cho phép tính khi mới có ~25% dữ liệu\n",
    "            ).mean()\n",
    "\n",
    "            # ----------------------------------------------------------\n",
    "            # sp_s{scale}: SPEED STD (độ biến thiên tốc độ)\n",
    "            # ----------------------------------------------------------\n",
    "            # Ý nghĩa:\n",
    "            # - Đo mức độ \"giật cục\" của chuyển động\n",
    "            # - Cao  → lúc nhanh lúc chậm (không đều)\n",
    "            # - Thấp → di chuyển đều hoặc đứng yên ổn định\n",
    "            #\n",
    "            # Ví dụ:\n",
    "            # sp_s10  cao → chuyển động ngắn hạn rất thất thường\n",
    "            # sp_s160 cao → cả đoạn dài có pha chạy + pha đứng yên\n",
    "            X[f'sp_s{scale}'] = speed.rolling(\n",
    "                ws,\n",
    "                min_periods=max(1, ws // 4)\n",
    "            ).std()\n",
    "\n",
    "    # ------------------------------------------------------------------\n",
    "    # TỶ LỆ TỐC ĐỘ NGẮN HẠN / DÀI HẠN\n",
    "    # ------------------------------------------------------------------\n",
    "    # sp_ratio = sp_m10 / sp_m160\n",
    "    #\n",
    "    # Ý nghĩa hành vi:\n",
    "    # - sp_ratio >> 1 : đang có burst mạnh so với nền dài hạn\n",
    "    # - sp_ratio ≈ 1  : hành vi ổn định\n",
    "    # - sp_ratio << 1 : vừa giảm hoạt động / chuẩn bị đứng yên\n",
    "    #\n",
    "    # +1e-6 để tránh chia cho 0 khi tốc độ dài hạn rất nhỏ\n",
    "    if (\n",
    "        len(scales) >= 2\n",
    "        and f'sp_m{scales[0]}' in X.columns\n",
    "        and f'sp_m{scales[-1]}' in X.columns\n",
    "    ):\n",
    "        X['sp_ratio'] = (\n",
    "            X[f'sp_m{scales[0]}'] /\n",
    "            (X[f'sp_m{scales[-1]}'] + 1e-6)\n",
    "        )\n",
    "\n",
    "    return X\n",
    "\n",
    "\n",
    "def add_state_features(X, center_x, center_y, fps):\n",
    "    \"\"\"\n",
    "    MỤC TIÊU (vì sao sinh ra các feature này):\n",
    "    - Model (LGBM/CatBoost/...) không “hiểu” hành vi; nó chỉ thấy số (x, y, dx, dy, speed,...).\n",
    "    - Nhiều hành vi có speed tương tự nhau → dễ nhầm (false positive) → PR-AUC/F1 giảm.\n",
    "    - Vì vậy ta chuyển speed liên tục → “TRẠNG THÁI” rời rạc (0..3) + thống kê theo cửa sổ thời gian:\n",
    "        (1) s{state}_{window}: TỶ LỆ thời gian ở từng trạng thái trong ~vài giây gần nhất\n",
    "            -> cho model “bối cảnh”: đoạn này chủ yếu đứng yên / đi chậm / đi vừa / chạy nhanh\n",
    "            -> giúp phân biệt hành vi kéo dài (freeze/rest) với event ngắn (burst), giảm FP.\n",
    "        (2) trans_{window}: SỐ LẦN đổi trạng thái trong cửa sổ\n",
    "            -> đo “độ giật cục / không ổn định” (stop–go–stop–go)\n",
    "            -> giúp tách grooming/di chuyển lắt nhắt khỏi chạy đều hoặc đứng yên, giảm FP mạnh (tốt cho PR-AUC).\n",
    "    - Tất cả ngưỡng và cửa sổ đều được scale theo fps để “ý nghĩa theo thời gian thực” không đổi giữa các video.\n",
    "    \"\"\"\n",
    "\n",
    "    # ------------------------------------------------------------\n",
    "    # 1) TÍNH TỐC ĐỘ (cm/s)\n",
    "    # ------------------------------------------------------------\n",
    "    # center_x, center_y: toạ độ theo frame (đã chuẩn hoá đơn vị cm).\n",
    "    # diff() -> dịch chuyển giữa 2 frame liên tiếp (cm/frame).\n",
    "    # sqrt(dx^2 + dy^2) -> quãng đường/frame (cm/frame).\n",
    "    # * fps -> đổi sang cm/s để so sánh được giữa các video.\n",
    "    speed = np.sqrt(center_x.diff()**2 + center_y.diff()**2) * float(fps)  # cm/s\n",
    "\n",
    "    # ------------------------------------------------------------\n",
    "    # 2) LÀM MƯỢT SPEED (giảm nhiễu tracking → state ít nhảy bậy)\n",
    "    # ------------------------------------------------------------\n",
    "    # Nếu không làm mượt: chỉ cần rung nhẹ tọa độ là speed nhảy → state đổi liên tục → trans tăng giả → tăng FP.\n",
    "    # ~15 frame @30fps ≈ 0.5s (đủ ngắn để không “lì”, đủ dài để lọc noise).\n",
    "    w_ma = _scale(15, fps)\n",
    "    speed_ma = speed.rolling(w_ma, min_periods=max(1, w_ma // 3)).mean()\n",
    "\n",
    "    try:\n",
    "        # --------------------------------------------------------\n",
    "        # 3) CHIA SPEED THÀNH 4 “TRẠNG THÁI HÀNH VI” (0..3)\n",
    "        # --------------------------------------------------------\n",
    "        # Ý nghĩa trạng thái (gốc theo cm/frame):\n",
    "        #   state 0: <= 0.5  cm/frame  -> gần như đứng yên / chuyển động rất nhỏ\n",
    "        #   state 1: 0.5–2.0 cm/frame  -> di chuyển chậm\n",
    "        #   state 2: 2.0–5.0 cm/frame  -> di chuyển vừa\n",
    "        #   state 3: > 5.0  cm/frame  -> di chuyển nhanh\n",
    "        #\n",
    "        # LÝ DO *fps:\n",
    "        # - speed_ma đang là cm/s. Ngưỡng gốc là cm/frame.\n",
    "        # - Đổi ngưỡng sang cm/s: (cm/frame) * (frame/s) = cm/s\n",
    "        # - Nhờ vậy “đứng yên / chậm / vừa / nhanh” giữ nguyên ý nghĩa giữa 30fps và 60fps.\n",
    "        bins = [-np.inf, 0.5 * fps, 2.0 * fps, 5.0 * fps, np.inf]\n",
    "\n",
    "        # speed_states: chuỗi trạng thái theo từng frame\n",
    "        # -> biến tín hiệu liên tục thành tín hiệu rời rạc có “ngữ nghĩa”.\n",
    "        speed_states = pd.cut(speed_ma, bins=bins, labels=[0, 1, 2, 3]).astype(float)\n",
    "\n",
    "        # --------------------------------------------------------\n",
    "        # 4) THỐNG KÊ “BỐI CẢNH” THEO CỬA SỔ THỜI GIAN\n",
    "        # --------------------------------------------------------\n",
    "        # Chọn 2 cửa sổ (chuẩn @30fps):\n",
    "        # - 60  frame ≈ 2 giây  : bối cảnh ngắn (gần thời điểm hiện tại)\n",
    "        # - 120 frame ≈ 4 giây  : bối cảnh trung (ổn định hơn, giảm nhiễu)\n",
    "        #\n",
    "        # LÝ DO:\n",
    "        # - Hành vi không chỉ là 1 frame, mà là pattern trong vài giây.\n",
    "        # - Thống kê theo cửa sổ giúp model:\n",
    "        #   + phân biệt “đứng yên kéo dài” với “đứng yên chớp nhoáng”\n",
    "        #   + phân biệt “chạy đều” với “giật cục”\n",
    "        #   + giảm false positive -> tăng PR-AUC/F1.\n",
    "        for window in [60, 120]:\n",
    "            ws = _scale(window, fps)\n",
    "\n",
    "            # Nếu video quá ngắn không đủ cửa sổ thì bỏ qua để khỏi tạo cột toàn NaN.\n",
    "            if len(speed_states) >= ws:\n",
    "\n",
    "                # ------------------------------------------------\n",
    "                # 4a) s{state}_{window}: TỶ LỆ thời gian ở từng trạng thái\n",
    "                # ------------------------------------------------\n",
    "                # Ta biến state thành chuỗi 0/1 cho từng state:\n",
    "                #   I(state_t == k)\n",
    "                # Rolling mean của chuỗi 0/1 = “% thời gian” thuộc state đó trong cửa sổ.\n",
    "                #\n",
    "                # Ý nghĩa hành vi:\n",
    "                # - s0_* cao -> đoạn vừa rồi chủ yếu đứng yên (hữu ích cho freeze/rest, hoặc loại FP cho chase)\n",
    "                # - s3_* cao -> đoạn vừa rồi chủ yếu chạy nhanh (hữu ích cho chase/escape)\n",
    "                # - s1_*, s2_* -> lục cục/di chuyển nhỏ (hữu ích cho exploration/sniff/groom nhẹ tuỳ bài)\n",
    "                #\n",
    "                # Tại sao tốt cho PR-AUC/F1:\n",
    "                # - Model ít “bắn nhầm” khi thấy bối cảnh không khớp (giảm FP).\n",
    "                for state in [0, 1, 2, 3]:\n",
    "                    X[f's{state}_{window}'] = (\n",
    "                        (speed_states == state).astype(float)\n",
    "                        .rolling(ws, min_periods=max(1, ws // 6))\n",
    "                        .mean()\n",
    "                    )\n",
    "\n",
    "                # ------------------------------------------------\n",
    "                # 4b) trans_{window}: SỐ LẦN đổi trạng thái trong cửa sổ\n",
    "                # ------------------------------------------------\n",
    "                # state_changes[t] = 1 nếu state_t != state_{t-1}, ngược lại 0.\n",
    "                # Rolling sum = “đếm” số lần chuyển pha (stop->go, go->stop, chậm->nhanh,...).\n",
    "                #\n",
    "                # Ý nghĩa hành vi:\n",
    "                # - trans_* cao  -> chuyển động giật cục, đổi nhịp liên tục (hay gặp ở grooming/lắt nhắt)\n",
    "                # - trans_* thấp -> ổn định: hoặc đứng yên lâu (s0 cao), hoặc chạy đều (s3 cao)\n",
    "                #\n",
    "                # Tại sao tốt cho PR-AUC/F1:\n",
    "                # - Nhiều FP đến từ đoạn “trông giống” nếu chỉ nhìn speed,\n",
    "                #   nhưng pattern đổi nhịp khác hẳn → trans giúp tách, giảm FP mạnh.\n",
    "                state_changes = (speed_states != speed_states.shift(1)).astype(float)\n",
    "                X[f'trans_{window}'] = (\n",
    "                    state_changes.rolling(ws, min_periods=max(1, ws // 6)).sum()\n",
    "                )\n",
    "\n",
    "    except Exception:\n",
    "        # An toàn pipeline: nếu gặp lỗi (NaN nhiều, kiểu dữ liệu, pd.cut, v.v.)\n",
    "        # thì không làm hỏng toàn bộ quá trình tạo feature.\n",
    "        # (Khi debug, bạn có thể đổi thành logging để biết lúc nào bị fail.)\n",
    "        pass\n",
    "\n",
    "    return X\n",
    "\n",
    "\n",
    "\n",
    "def add_longrange_features(X, center_x, center_y, fps):\n",
    "    \"\"\"\n",
    "    Tạo các đặc trưng “dài hạn” (long-range) để model nhìn được:\n",
    "    - Xu hướng vị trí (drift) / vùng hoạt động (home range) trong vài giây\n",
    "    - Quỹ đạo “mượt” (giảm nhiễu, giữ xu hướng)\n",
    "    - Vị trí tương đối của tốc độ hiện tại so với lịch sử gần (percentile tốc độ)\n",
    "\n",
    "    LÝ DO (vì sao cần):\n",
    "    - Nhiều hành vi không chỉ phụ thuộc “frame hiện tại”, mà phụ thuộc bối cảnh vài giây:\n",
    "        + đang ở yên một góc hay đang di chuyển xuyên vùng?\n",
    "        + đang tăng tốc so với nền hay chỉ chạy đều?\n",
    "    - Các feature dài hạn giúp giảm false positive (tốt cho PR-AUC/F1) vì model biết “nền” của đoạn đó.\n",
    "    - Window/span được scale theo fps để ý nghĩa theo thời gian thực không đổi giữa video.\n",
    "    \"\"\"\n",
    "\n",
    "    # ------------------------------------------------------------\n",
    "    # 1) ROLLING MEAN DÀI HẠN CỦA VỊ TRÍ (x_ml*, y_ml*)\n",
    "    # ------------------------------------------------------------\n",
    "    # Ý nghĩa:\n",
    "    # - x_ml{window}, y_ml{window} = vị trí trung bình trong cửa sổ dài (≈ vài giây)\n",
    "    # - Đây là “vị trí xu hướng” (trend position), làm mượt quỹ đạo, giảm nhiễu rung.\n",
    "    # - Giúp model biết chuột đang “neo” ở vùng nào trong không gian trong đoạn dài.\n",
    "    #\n",
    "    # Tại sao hữu ích:\n",
    "    # - Phân biệt “đi loanh quanh tại chỗ” vs “di chuyển xuyên vùng”\n",
    "    # - Có ích khi hành vi gắn với vị trí/khu vực (góc tường, trung tâm arena, vùng gần con khác...)\n",
    "    for window in [120, 240]:\n",
    "        ws = _scale(window, fps)  # window chuẩn @30fps -> số frame thực tế\n",
    "        if len(center_x) >= ws:\n",
    "            # min_periods: cần tối thiểu số frame để mean có ý nghĩa, tránh đầu chuỗi toàn NaN\n",
    "            X[f'x_ml{window}'] = center_x.rolling(ws, min_periods=max(5, ws // 6)).mean()\n",
    "            X[f'y_ml{window}'] = center_y.rolling(ws, min_periods=max(5, ws // 6)).mean()\n",
    "\n",
    "    # ------------------------------------------------------------\n",
    "    # 2) EWM (EXPONENTIALLY WEIGHTED MEAN) CỦA VỊ TRÍ (x_e*, y_e*)\n",
    "    # ------------------------------------------------------------\n",
    "    # EWM mean = trung bình luỹ thừa (mẫu gần hiện tại được trọng số lớn hơn mẫu cũ)\n",
    "    #\n",
    "    # Ý nghĩa:\n",
    "    # - x_e{span}, y_e{span} = “quỹ đạo xu hướng” nhưng phản ứng nhanh hơn rolling mean\n",
    "    # - Ít lag hơn rolling mean (rolling cắt cứng theo cửa sổ, EWM giảm dần theo thời gian)\n",
    "    #\n",
    "    # Tại sao hữu ích:\n",
    "    # - Nắm xu hướng vị trí ngay cả khi hành vi đổi pha (chạy -> dừng)\n",
    "    # - Là một dạng “low-pass filter” giảm rung nhưng vẫn bám theo chuyển động\n",
    "    #\n",
    "    # span cũng được hiểu theo frame (chuẩn @30fps) và scale theo fps\n",
    "    for span in [60, 120]:\n",
    "        s = _scale(span, fps)\n",
    "        X[f'x_e{span}'] = center_x.ewm(span=s, min_periods=1).mean()\n",
    "        X[f'y_e{span}'] = center_y.ewm(span=s, min_periods=1).mean()\n",
    "\n",
    "    # ------------------------------------------------------------\n",
    "    # 3) TÍNH TỐC ĐỘ (cm/s)\n",
    "    # ------------------------------------------------------------\n",
    "    # dx, dy: cm/frame; *fps -> cm/s\n",
    "    speed = np.sqrt(center_x.diff()**2 + center_y.diff()**2) * float(fps)\n",
    "\n",
    "    # ------------------------------------------------------------\n",
    "    # 4) sp_pct{window}: PERCENTILE (RANK PCT) CỦA SPEED TRONG CỬA SỔ\n",
    "    # ------------------------------------------------------------\n",
    "    # rank(pct=True) trả về giá trị trong [0,1]:\n",
    "    # - 0.0  ~ thuộc nhóm thấp nhất trong cửa sổ\n",
    "    # - 0.5  ~ mức trung bình\n",
    "    # - 1.0  ~ thuộc nhóm cao nhất trong cửa sổ (đỉnh tốc độ)\n",
    "    #\n",
    "    # Ý nghĩa hành vi:\n",
    "    # - sp_pct60 cao: frame hiện tại là “nhanh bất thường” so với ~2s gần nhất (burst)\n",
    "    # - sp_pct120 cao: nhanh bất thường so với ~4s gần nhất (burst bền hơn)\n",
    "    #\n",
    "    # Tại sao tốt cho PR-AUC/F1:\n",
    "    # - Percentile là “chuẩn hoá theo nền” → giảm phụ thuộc cá thể/video\n",
    "    # - Giúp model tách “đỉnh tốc độ” khỏi “chạy đều”:\n",
    "    #   + chạy đều: percentile quanh mức trung bình\n",
    "    #   + bùng nổ: percentile nhảy lên gần 1.0\n",
    "    for window in [60, 120]:\n",
    "        ws = _scale(window, fps)\n",
    "        if len(speed) >= ws:\n",
    "            # rolling(rank pct) = trong mỗi cửa sổ, lấy thứ hạng của speed hiện tại\n",
    "            X[f'sp_pct{window}'] = speed.rolling(\n",
    "                ws,\n",
    "                min_periods=max(5, ws // 6)\n",
    "            ).rank(pct=True)\n",
    "\n",
    "    return X\n",
    "\n",
    "def add_cumulative_distance_single(\n",
    "    X, cx, cy, fps,\n",
    "    horizon_frames_base: int = 180,\n",
    "    colname: str = \"path_cum180\"\n",
    "):\n",
    "    \"\"\"\n",
    "    Tạo feature QUÃNG ĐƯỜNG DI CHUYỂN TÍCH LŨY (cumulative path length)\n",
    "    quanh mỗi frame, dùng để mô tả mức độ HOẠT ĐỘNG tổng thể của chuột\n",
    "    trong một khoảng thời gian dài (vài giây).\n",
    "\n",
    "    Ý nghĩa hành vi:\n",
    "    - Phân biệt burst ngắn (spike speed) vs hoạt động kéo dài\n",
    "    - Phân biệt resting / grooming / exploration / chase\n",
    "    - Giảm false positive do nhiễu hoặc spike rất ngắn\n",
    "\n",
    "    horizon_frames_base:\n",
    "    - Số frame chuẩn tại 30fps (180 @30fps ≈ 6 giây mỗi phía)\n",
    "    - Sẽ được scale theo fps thực tế\n",
    "    \"\"\"\n",
    "\n",
    "    # ------------------------------------------------------------\n",
    "    # 1) XÁC ĐỊNH BÁN KÍNH THỜI GIAN L (FRAME)\n",
    "    # ------------------------------------------------------------\n",
    "    # _scale(...) đảm bảo ý nghĩa theo THỜI GIAN THỰC (giây) là bất biến theo fps\n",
    "    # Ví dụ:\n",
    "    #   fps = 30  -> L = 180 frame  (~6 giây)\n",
    "    #   fps = 60  -> L = 360 frame  (~6 giây)\n",
    "    L = max(1, _scale(horizon_frames_base, fps))  # số frame mỗi phía\n",
    "\n",
    "    # ------------------------------------------------------------\n",
    "    # 2) TÍNH ĐỘ DÀI BƯỚC ĐI GIỮA 2 FRAME LIÊN TIẾP\n",
    "    # ------------------------------------------------------------\n",
    "    # cx.diff(), cy.diff()  : độ dịch chuyển theo X, Y giữa frame t và t-1\n",
    "    # np.hypot(dx, dy)     : sqrt(dx^2 + dy^2)\n",
    "    #\n",
    "    # Vì cx, cy đã ở đơn vị cm:\n",
    "    # -> step = quãng đường di chuyển (cm / frame)\n",
    "    step = np.hypot(cx.diff(), cy.diff())\n",
    "\n",
    "    # ------------------------------------------------------------\n",
    "    # 3) TÍNH TỔNG QUÃNG ĐƯỜNG DI CHUYỂN TRONG CỬA SỔ ±L FRAME\n",
    "    # ------------------------------------------------------------\n",
    "    # rolling window = 2*L + 1:\n",
    "    #   - L frame trước\n",
    "    #   - frame hiện tại\n",
    "    #   - L frame sau\n",
    "    #\n",
    "    # center=True:\n",
    "    #   - feature \"acausal\" (dùng cả tương lai)\n",
    "    #   - phù hợp cho offline training / labeling\n",
    "    #\n",
    "    # sum():\n",
    "    #   - cộng toàn bộ step trong cửa sổ\n",
    "    #   - cho ra TỔNG QUÃNG ĐƯỜNG (cm) trong ~2L+1 frame\n",
    "    #\n",
    "    # min_periods:\n",
    "    #   - không cần đủ toàn bộ cửa sổ mới tính\n",
    "    #   - nhưng cần tối thiểu:\n",
    "    #       + 5 frame\n",
    "    #       + hoặc ~1/6 cửa sổ\n",
    "    #   - để tránh nhiễu và NaN quá nhiều ở đầu/cuối video\n",
    "    path = step.rolling(\n",
    "        2 * L + 1,\n",
    "        min_periods=max(5, L // 6),\n",
    "        center=True\n",
    "    ).sum()\n",
    "\n",
    "    # ------------------------------------------------------------\n",
    "    # 4) GHI FEATURE VÀO DATAFRAME\n",
    "    # ------------------------------------------------------------\n",
    "    # fillna(0.0):\n",
    "    #   - các frame không đủ dữ liệu (đầu/cuối) → coi như không hoạt động\n",
    "    #\n",
    "    # astype(float32):\n",
    "    #   - giảm bộ nhớ\n",
    "    #   - tăng tốc cho LightGBM / CatBoost\n",
    "    X[colname] = path.fillna(0.0).astype(np.float32)\n",
    "\n",
    "    return X\n",
    "\n",
    "\n",
    "\n",
    "def add_groom_microfeatures(X, df, fps):\n",
    "    \"\"\"\n",
    "    Sinh các ĐẶC TRƯNG VI MÔ (micro-features) chuyên để nhận diện hành vi GROOMING.\n",
    "\n",
    "    Grooming có đặc điểm:\n",
    "    - ĐẦU / MŨI chuyển động nhiều\n",
    "    - THÂN gần như đứng yên\n",
    "    - Chuyển động nhỏ, nhanh, lặp lại\n",
    "    - Không tạo quãng đường tích lũy lớn như locomotion\n",
    "\n",
    "    Các feature trong hàm này đều nhằm đo:\n",
    "    - mức độ TÁCH BIỆT chuyển động đầu ↔ thân\n",
    "    - dao động hình học nhỏ quanh thân\n",
    "    - rung / giật hướng đầu\n",
    "    \"\"\"\n",
    "\n",
    "    # ------------------------------------------------------------\n",
    "    # 1) KIỂM TRA KEYPOINT BẮT BUỘC\n",
    "    # ------------------------------------------------------------\n",
    "    # df có dạng MultiIndex cột: (part, coord)\n",
    "    # Grooming bắt buộc phải có:\n",
    "    #   - body_center: đại diện cho thân\n",
    "    #   - nose       : đại diện cho đầu\n",
    "    parts = df.columns.get_level_values(0)\n",
    "    if 'body_center' not in parts or 'nose' not in parts:\n",
    "        # Thiếu keypoint thì không thể sinh feature grooming\n",
    "        return X\n",
    "\n",
    "    # ------------------------------------------------------------\n",
    "    # 2) LẤY TỌA ĐỘ HÌNH HỌC\n",
    "    # ------------------------------------------------------------\n",
    "    # C(t) = (cx, cy)  : tâm thân\n",
    "    # N(t) = (nx, ny)  : mũi / đầu\n",
    "    cx = df['body_center']['x']\n",
    "    cy = df['body_center']['y']\n",
    "    nx = df['nose']['x']\n",
    "    ny = df['nose']['y']\n",
    "\n",
    "    # ------------------------------------------------------------\n",
    "    # 3) TÍNH TỐC ĐỘ THÂN VÀ TỐC ĐỘ ĐẦU (cm/s)\n",
    "    # ------------------------------------------------------------\n",
    "    # step = sqrt(dx^2 + dy^2)   (cm / frame)\n",
    "    # speed = step * fps         (cm / s)\n",
    "    #\n",
    "    # cs(t): tốc độ thân\n",
    "    # ns(t): tốc độ mũi\n",
    "    cs = (np.sqrt(cx.diff()**2 + cy.diff()**2) * float(fps)).fillna(0)\n",
    "    ns = (np.sqrt(nx.diff()**2 + ny.diff()**2) * float(fps)).fillna(0)\n",
    "\n",
    "    # ------------------------------------------------------------\n",
    "    # 4) CỬA SỔ THỜI GIAN ~1 GIÂY (FPS-INVARIANT)\n",
    "    # ------------------------------------------------------------\n",
    "    # 30 frame @30fps ≈ 1 giây\n",
    "    # _scale(...) đảm bảo ý nghĩa theo GIÂY không đổi khi fps khác\n",
    "    w30 = _scale(30, fps)\n",
    "\n",
    "    # ------------------------------------------------------------\n",
    "    # 5) FEATURE 1: HEAD–BODY DECOUPLING\n",
    "    # ------------------------------------------------------------\n",
    "    # Công thức gốc:\n",
    "    #   D(t) = ns(t) / (cs(t) + ε)\n",
    "    #\n",
    "    # Ý nghĩa:\n",
    "    #   - Grooming:  ns >> cs  → D lớn\n",
    "    #   - Chạy:      ns ≈ cs   → D ≈ 1\n",
    "    #\n",
    "    # + ε = 1e-3 để tránh chia cho 0\n",
    "    # + clip(0,10) để chặn outlier khi cs ≈ 0\n",
    "    # + rolling median (~1s) để giảm spike giả / nhiễu tracking\n",
    "    X['head_body_decouple'] = (\n",
    "        ns / (cs + 1e-3)\n",
    "    ).clip(0, 10).rolling(\n",
    "        w30,\n",
    "        min_periods=max(1, w30 // 3)\n",
    "    ).median()\n",
    "\n",
    "    # ------------------------------------------------------------\n",
    "    # 6) FEATURE 2: DAO ĐỘNG BÁN KÍNH MŨI–THÂN\n",
    "    # ------------------------------------------------------------\n",
    "    # r(t) = || N(t) - C(t) ||\n",
    "    #\n",
    "    # Grooming:\n",
    "    #   - đầu cúi/ngẩng/chải\n",
    "    #   - khoảng cách mũi–thân dao động mạnh\n",
    "    #\n",
    "    # Locomotion:\n",
    "    #   - khoảng cách tương đối ổn định\n",
    "    r = np.sqrt((nx - cx)**2 + (ny - cy)**2)\n",
    "\n",
    "    # std(r) trong ~1s → mức độ dao động hình học của đầu\n",
    "    X['nose_rad_std'] = r.rolling(\n",
    "        w30,\n",
    "        min_periods=max(1, w30 // 3)\n",
    "    ).std().fillna(0)\n",
    "\n",
    "    # ------------------------------------------------------------\n",
    "    # 7) FEATURE 3: RUNG HƯỚNG ĐẦU (NẾU CÓ TAIL_BASE)\n",
    "    # ------------------------------------------------------------\n",
    "    # Dùng vector từ tail_base → nose để xác định hướng đầu\n",
    "    if 'tail_base' in parts:\n",
    "        # θ(t) = arctan2(dy, dx)\n",
    "        ang = np.arctan2(\n",
    "            df['nose']['y'] - df['tail_base']['y'],\n",
    "            df['nose']['x'] - df['tail_base']['x']\n",
    "        )\n",
    "\n",
    "        # Δθ(t) = |θ(t) - θ(t-1)|\n",
    "        # (chưa unwrap → có thể spike khi qua ±π, chấp nhận được cho micro-feature)\n",
    "        dang = np.abs(ang.diff()).fillna(0)\n",
    "\n",
    "        # Mean |Δθ| trong ~1s → mức độ rung / lắc đầu\n",
    "        X['head_orient_jitter'] = dang.rolling(\n",
    "            w30,\n",
    "            min_periods=max(1, w30 // 3)\n",
    "        ).mean()\n",
    "\n",
    "    return X\n",
    "\n",
    "def add_groom_microfeatures(X, df, fps):\n",
    "    \"\"\"\n",
    "    Sinh các ĐẶC TRƯNG VI MÔ (micro-features) chuyên để nhận diện hành vi GROOMING.\n",
    "\n",
    "    Grooming có đặc điểm:\n",
    "    - ĐẦU / MŨI chuyển động nhiều\n",
    "    - THÂN gần như đứng yên\n",
    "    - Chuyển động nhỏ, nhanh, lặp lại\n",
    "    - Không tạo quãng đường tích lũy lớn như locomotion\n",
    "\n",
    "    Các feature trong hàm này đều nhằm đo:\n",
    "    - mức độ TÁCH BIỆT chuyển động đầu ↔ thân\n",
    "    - dao động hình học nhỏ quanh thân\n",
    "    - rung / giật hướng đầu\n",
    "    \"\"\"\n",
    "\n",
    "    # ------------------------------------------------------------\n",
    "    # 1) KIỂM TRA KEYPOINT BẮT BUỘC\n",
    "    # ------------------------------------------------------------\n",
    "    # df có dạng MultiIndex cột: (part, coord)\n",
    "    # Grooming bắt buộc phải có:\n",
    "    #   - body_center: đại diện cho thân\n",
    "    #   - nose       : đại diện cho đầu\n",
    "    parts = df.columns.get_level_values(0)\n",
    "    if 'body_center' not in parts or 'nose' not in parts:\n",
    "        # Thiếu keypoint thì không thể sinh feature grooming\n",
    "        return X\n",
    "\n",
    "    # ------------------------------------------------------------\n",
    "    # 2) LẤY TỌA ĐỘ HÌNH HỌC\n",
    "    # ------------------------------------------------------------\n",
    "    # C(t) = (cx, cy): tâm thân\n",
    "    # N(t) = (nx, ny): mũi / đầu\n",
    "    cx = df['body_center']['x']\n",
    "    cy = df['body_center']['y']\n",
    "    nx = df['nose']['x']\n",
    "    ny = df['nose']['y']\n",
    "\n",
    "    # ------------------------------------------------------------\n",
    "    # 3) TÍNH TỐC ĐỘ THÂN VÀ TỐC ĐỘ ĐẦU (cm/s)\n",
    "    # ------------------------------------------------------------\n",
    "    # cs(t) = tốc độ thân (body speed): phản ánh locomotion tổng thể (chạy/đi)\n",
    "    # ns(t) = tốc độ mũi (nose speed): phản ánh chuyển động vi mô ở vùng đầu (grooming, sniffing)\n",
    "    #\n",
    "    # Grooming thường có: ns cao nhưng cs thấp  → đầu hoạt động nhiều, thân ít di chuyển\n",
    "    cs = (np.sqrt(cx.diff()**2 + cy.diff()**2) * float(fps)).fillna(0)\n",
    "    ns = (np.sqrt(nx.diff()**2 + ny.diff()**2) * float(fps)).fillna(0)\n",
    "\n",
    "    # ------------------------------------------------------------\n",
    "    # 4) CỬA SỔ THỜI GIAN ~1 GIÂY (FPS-INVARIANT)\n",
    "    # ------------------------------------------------------------\n",
    "    # w30 ~ 1 giây: đủ dài để \"nhìn\" nhịp grooming (lặp lại), nhưng không quá dài để bị trễ\n",
    "    w30 = _scale(30, fps)\n",
    "\n",
    "    # ------------------------------------------------------------\n",
    "    # 5) FEATURE 1: head_body_decouple\n",
    "    # ------------------------------------------------------------\n",
    "    # Ý NGHĨA ĐẶC TRƯNG:\n",
    "    #   head_body_decouple(t) đo mức độ \"đầu tách rời thân\" trong ~1 giây:\n",
    "    #\n",
    "    #   D(t) = ns(t) / (cs(t) + ε)\n",
    "    #\n",
    "    # Diễn giải:\n",
    "    #   - D lớn (>>1): mũi/đầu chuyển động nhiều hơn thân → gợi ý grooming/sniffing tại chỗ\n",
    "    #   - D ≈ 1      : đầu và thân di chuyển cùng nhau → gợi ý locomotion (đi/chạy)\n",
    "    #   - D nhỏ (<1) : thân di chuyển nhiều nhưng mũi ít (hiếm, có thể do tracking)\n",
    "    #\n",
    "    # Tại sao median rolling?\n",
    "    #   - Giảm \"spike giả\" do 1-2 frame keypoint nhảy\n",
    "    #   - Tập trung vào chuyển động lặp lại ổn định của grooming trong ~1 giây\n",
    "    X['head_body_decouple'] = (\n",
    "        ns / (cs + 1e-3)\n",
    "    ).clip(0, 10).rolling(\n",
    "        w30,\n",
    "        min_periods=max(1, w30 // 3)\n",
    "    ).median()\n",
    "\n",
    "    # ------------------------------------------------------------\n",
    "    # 6) FEATURE 2: nose_rad_std\n",
    "    # ------------------------------------------------------------\n",
    "    # Ý NGHĨA ĐẶC TRƯNG:\n",
    "    #   nose_rad_std(t) đo mức độ DAO ĐỘNG của khoảng cách mũi–tâm thân trong ~1 giây.\n",
    "    #\n",
    "    #   r(t) = ||N(t) - C(t)|| = sqrt((nx-cx)^2 + (ny-cy)^2)\n",
    "    #   nose_rad_std(t) = std(r) trong cửa sổ ~1 giây\n",
    "    #\n",
    "    # Diễn giải:\n",
    "    #   - nose_rad_std cao: đầu cúi/ngẩng/đưa ra-vào liên tục quanh thân → rất hợp grooming (chải mặt/tai)\n",
    "    #   - nose_rad_std thấp: hình học đầu–thân ổn định → hợp locomotion chạy thẳng hoặc đứng yên\n",
    "    #\n",
    "    # (fillna(0) để tránh NaN đầu đoạn/thiếu dữ liệu)\n",
    "    r = np.sqrt((nx - cx)**2 + (ny - cy)**2)\n",
    "    X['nose_rad_std'] = r.rolling(\n",
    "        w30,\n",
    "        min_periods=max(1, w30 // 3)\n",
    "    ).std().fillna(0)\n",
    "\n",
    "    # ------------------------------------------------------------\n",
    "    # 7) FEATURE 3: head_orient_jitter (NẾU CÓ tail_base)\n",
    "    # ------------------------------------------------------------\n",
    "    # Ý NGHĨA ĐẶC TRƯNG:\n",
    "    #   head_orient_jitter(t) đo mức độ \"lắc/rung hướng đầu\" trong ~1 giây.\n",
    "    #\n",
    "    # Dùng tail_base → nose để đại diện trục thân-đầu (body axis):\n",
    "    #   θ(t) = arctan2(ny - ty, nx - tx)\n",
    "    #   Δθ(t) = |θ(t) - θ(t-1)|\n",
    "    #   head_orient_jitter(t) = mean(Δθ) trong cửa sổ ~1 giây\n",
    "    #\n",
    "    # Diễn giải:\n",
    "    #   - jitter cao: đầu đổi hướng nhỏ nhưng liên tục (lắc/giật) → hay gặp trong grooming (chải, liếm)\n",
    "    #   - jitter thấp: hướng đầu ổn định → hay gặp khi chạy thẳng hoặc đứng yên\n",
    "    #\n",
    "    # Lưu ý:\n",
    "    #   - Góc có chu kỳ (-π ↔ +π). Nếu chuột quay qua ranh giới này, diff có thể tạo spike.\n",
    "    #   - Nếu muốn \"mượt\" hơn có thể dùng np.unwrap(ang) trước khi diff.\n",
    "    if 'tail_base' in parts:\n",
    "        ang = np.arctan2(\n",
    "            df['nose']['y'] - df['tail_base']['y'],\n",
    "            df['nose']['x'] - df['tail_base']['x']\n",
    "        )\n",
    "        dang = np.abs(ang.diff()).fillna(0)\n",
    "        X['head_orient_jitter'] = dang.rolling(\n",
    "            w30,\n",
    "            min_periods=max(1, w30 // 3)\n",
    "        ).mean()\n",
    "\n",
    "    return X\n",
    "\n",
    "\n",
    "# ===============================================================\n",
    "# 1) Past–vs–Future speed asymmetry (acausal, continuous)\n",
    "#    Δv(t) = agg_future(speed) - agg_past(speed)\n",
    "# ===============================================================\n",
    "def add_speed_asymmetry_future_past_single(\n",
    "    X: pd.DataFrame, cx: pd.Series, cy: pd.Series, fps: float,\n",
    "    horizon_base: int = 30, agg: str = \"mean\"\n",
    ") -> pd.DataFrame:\n",
    "    # -----------------------------------------------------------\n",
    "    # MỤC TIÊU ĐẶC TRƯNG:\n",
    "    #   Sinh ra \"spd_asym_1s\" đo độ BẤT ĐỐI XỨNG tốc độ quanh frame t:\n",
    "    #     spd_asym(t) = v_future(t) - v_past(t)\n",
    "    #\n",
    "    #   - spd_asym > 0  : tương lai nhanh hơn quá khứ → đang TĂNG TỐC (onset)\n",
    "    #   - spd_asym < 0  : tương lai chậm hơn quá khứ → đang GIẢM TỐC (offset/kết thúc)\n",
    "    #   - spd_asym ≈ 0  : trạng thái ổn định (đi/chạy đều, hoặc đứng yên đều)\n",
    "    #\n",
    "    #   Vì dùng cả \"future\" nên đây là feature ACAUSAL (offline):\n",
    "    #   - tốt cho training / hậu nghiệm (đã có cả video)\n",
    "    #   - không phù hợp realtime (vì realtime không có tương lai)\n",
    "    # -----------------------------------------------------------\n",
    "\n",
    "    # -----------------------------------------------------------\n",
    "    # 1) XÁC ĐỊNH ĐỘ DÀI CỬA SỔ THỜI GIAN (fps-invariant)\n",
    "    # -----------------------------------------------------------\n",
    "    # horizon_base=30 nghĩa là ~1 giây ở 30fps.\n",
    "    # _scale(horizon_base, fps): đổi số frame chuẩn @30fps sang fps thực,\n",
    "    # để cùng một \"thời gian thực\" khi fps thay đổi.\n",
    "    # max(3, ...): đảm bảo cửa sổ tối thiểu 3 frame để giảm nhiễu.\n",
    "    w = max(3, _scale(horizon_base, fps))\n",
    "\n",
    "    # -----------------------------------------------------------\n",
    "    # 2) TÍNH SPEED THEO FRAME (cm/s)\n",
    "    # -----------------------------------------------------------\n",
    "    # v(t) = sqrt((cx_t-cx_{t-1})^2 + (cy_t-cy_{t-1})^2) * fps\n",
    "    # -> tốc độ thân (body speed) tại frame t\n",
    "    v = _speed(cx, cy, fps)\n",
    "\n",
    "    # -----------------------------------------------------------\n",
    "    # 3) CHỌN PHÉP GỘP (AGGREGATION) CHO CỬA SỔ\n",
    "    # -----------------------------------------------------------\n",
    "    # agg=\"mean\"  : nhạy với biên độ tăng tốc/giảm tốc, bắt onset mạnh\n",
    "    # agg=\"median\": bền với spike giả (1-2 frame nhảy), nhưng ít nhạy hơn\n",
    "    if agg == \"median\":\n",
    "        # -------------------- PAST --------------------\n",
    "        # v_past(t) = median{ v(t-w+1..t) }\n",
    "        # (center=False) → causal: dùng dữ liệu quá khứ + hiện tại\n",
    "        v_past = v.rolling(\n",
    "            w,\n",
    "            min_periods=max(3, w // 4),\n",
    "            center=False\n",
    "        ).median()\n",
    "\n",
    "        # ------------------- FUTURE -------------------\n",
    "        # v_fut(t) = median{ v(t+1..t+w) }\n",
    "        # Cách làm: đảo chuỗi → rolling median → đảo lại\n",
    "        # => thu được \"median tương lai\" (acausal)\n",
    "        v_fut = (\n",
    "            v.iloc[::-1]\n",
    "             .rolling(w, min_periods=max(3, w // 4))\n",
    "             .median()\n",
    "             .iloc[::-1]\n",
    "        )\n",
    "    else:\n",
    "        # -------------------- PAST --------------------\n",
    "        # v_past(t) = mean{ v(t-w+1..t) }\n",
    "        # (center=False) → chỉ nhìn quá khứ (có thể dùng realtime)\n",
    "        v_past = v.rolling(\n",
    "            w,\n",
    "            min_periods=max(3, w // 4),\n",
    "            center=False\n",
    "        ).mean()\n",
    "\n",
    "        # ------------------- FUTURE -------------------\n",
    "        # v_fut(t) = mean{ v(t+1..t+w) }\n",
    "        # _roll_future_mean: helper tính rolling mean ở tương lai (acausal)\n",
    "        v_fut = _roll_future_mean(v, w, min_p=max(3, w // 4))\n",
    "\n",
    "    # -----------------------------------------------------------\n",
    "    # 4) TÍNH ĐẶC TRƯNG BẤT ĐỐI XỨNG TỐC ĐỘ\n",
    "    # -----------------------------------------------------------\n",
    "    # spd_asym_1s(t) = v_fut(t) - v_past(t)\n",
    "    #\n",
    "    # Ý nghĩa hành vi:\n",
    "    # - onset (bắt đầu chạy/escape/chase): future tăng → spd_asym dương lớn\n",
    "    # - offset (kết thúc hành vi): future giảm → spd_asym âm lớn\n",
    "    # - chạy đều/đứng yên đều: future ≈ past → spd_asym gần 0\n",
    "    #\n",
    "    # fillna(0): đầu/cuối video không đủ cửa sổ → đặt 0 để tránh NaN\n",
    "    X[\"spd_asym_1s\"] = (v_fut - v_past).fillna(0.0)\n",
    "\n",
    "    return X\n",
    "\n",
    "# ===============================================================\n",
    "# 2) Distribution shift (future vs past) via symmetric KL of\n",
    "#    Gaussian fits on speed \n",
    "# ===============================================================\n",
    "def add_gauss_shift_speed_future_past_single(\n",
    "    X: pd.DataFrame, cx: pd.Series, cy: pd.Series, fps: float,\n",
    "    window_base: int = 30, eps: float = 1e-6\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Feature: spd_symkl_1s = độ “khác nhau” giữa PHÂN PHỐI tốc độ QUÁ KHỨ và TƯƠNG LAI quanh mỗi frame.\n",
    "\n",
    "    Ý tưởng:\n",
    "    - Lấy speed v(t) tại mỗi frame.\n",
    "    - Fit (xấp xỉ) speed trong quá khứ và tương lai bằng 2 Gaussian 1D:\n",
    "        Np ~ N(mu_p, va_p)  (past window)\n",
    "        Nf ~ N(mu_f, va_f)  (future window)\n",
    "    - Đo “độ lệch phân phối” bằng symmetric KL:\n",
    "        symKL = KL(Np||Nf) + KL(Nf||Np)\n",
    "\n",
    "    Ý nghĩa hành vi:\n",
    "    - symKL nhỏ: hành vi ổn định (past ~ future), ví dụ chạy đều / đứng đều\n",
    "    - symKL lớn: đang chuyển pha (transition), onset/offset hành vi, hoặc nhịp chuyển mạnh\n",
    "      (tăng tốc/giảm tốc hoặc độ dao động speed thay đổi)\n",
    "\n",
    "    Vì sao cần symKL dù đã có asym (future_mean - past_mean)?\n",
    "    - asym đo HƯỚNG thay đổi (tăng hay giảm mean), nhưng có thể “mù” nếu mean không đổi mà variance đổi.\n",
    "    - symKL đo MỨC ĐỘ khác nhau của phân phối (mean + variance), giúp:\n",
    "        + bắt transition “không đổi mean” (ví dụ rung/jitter làm var tăng)\n",
    "        + lọc spike giả tốt hơn khi kết hợp với asym\n",
    "    \"\"\"\n",
    "\n",
    "    # w: số frame của cửa sổ ~ window_base frame ở chuẩn 30fps, scale theo fps thực.\n",
    "    # max(5, ...) để cửa sổ không quá nhỏ (var/mean ổn định hơn).\n",
    "    w = max(5, _scale(window_base, fps))\n",
    "\n",
    "    # v(t): speed tại mỗi frame (đơn vị/giây). Nếu cx,cy là cm → cm/s; nếu pixel → pixel/s.\n",
    "    # v(t) = sqrt( (Δx)^2 + (Δy)^2 ) * fps\n",
    "    v = _speed(cx, cy, fps)\n",
    "\n",
    "    # -------------------- THỐNG KÊ QUÁ KHỨ (PAST) --------------------\n",
    "    # Past window (causal): [t-w+1, ..., t]\n",
    "    # mu_p(t) = mean(v_{t-w+1:t})\n",
    "    # va_p(t) = var (v_{t-w+1:t})\n",
    "    #\n",
    "    # min_periods = max(3, w//4): cần đủ điểm để mean/var tin cậy (ít nhất 3, hoặc 1/4 cửa sổ).\n",
    "    mu_p = v.rolling(w, min_periods=max(3, w//4)).mean()\n",
    "    va_p = v.rolling(w, min_periods=max(3, w//4)).var().clip(lower=eps)  # eps tránh var=0\n",
    "\n",
    "    # -------------------- THỐNG KÊ TƯƠNG LAI (FUTURE) --------------------\n",
    "    # Future window (acausal): [t, ..., t+w-1]\n",
    "    # mu_f(t) = mean(v_{t:t+w-1})\n",
    "    # va_f(t) = var (v_{t:t+w-1})\n",
    "    #\n",
    "    # Lưu ý: dùng future phù hợp bài toán OFFLINE (có toàn bộ video).\n",
    "    mu_f = _roll_future_mean(v, w, min_p=max(3, w//4))\n",
    "    va_f = _roll_future_var(v, w, min_p=max(3, w//4)).clip(lower=eps)  # eps tránh var=0\n",
    "\n",
    "    # -------------------- SYMMETRIC KL GIỮA 2 GAUSSIAN 1D --------------------\n",
    "    # Xấp xỉ:\n",
    "    #   Np = N(mu_p, va_p)\n",
    "    #   Nf = N(mu_f, va_f)\n",
    "    #\n",
    "    # KL giữa 2 Gaussian 1D:\n",
    "    #   KL(Np||Nf) = 0.5 * [ (va_p/va_f) + (mu_f - mu_p)^2/va_f - 1 + ln(va_f/va_p) ]\n",
    "    #   KL(Nf||Np) = 0.5 * [ (va_f/va_p) + (mu_p - mu_f)^2/va_p - 1 + ln(va_p/va_f) ]\n",
    "    #\n",
    "    # symmetric_KL = KL(Np||Nf) + KL(Nf||Np)  (luôn >= 0, không phụ thuộc hướng so sánh)\n",
    "    kl_pf = 0.5 * (\n",
    "        (va_p / va_f)\n",
    "        + ((mu_f - mu_p) ** 2) / va_f\n",
    "        - 1.0\n",
    "        + np.log(va_f / va_p)\n",
    "    )\n",
    "    kl_fp = 0.5 * (\n",
    "        (va_f / va_p)\n",
    "        + ((mu_p - mu_f) ** 2) / va_p\n",
    "        - 1.0\n",
    "        + np.log(va_p / va_f)\n",
    "    )\n",
    "\n",
    "    # spd_symkl_1s(t): “mức độ chuyển pha” của speed quanh frame t\n",
    "    # - lớn: past vs future khác mạnh (transition/onset/offset), hoặc var thay đổi lớn\n",
    "    # - nhỏ: ổn định\n",
    "    #\n",
    "    # replace inf -> NaN -> fill 0 để tránh phá model khi gặp trường hợp số học xấu/thiếu dữ liệu.\n",
    "    X[\"spd_symkl_1s\"] = (kl_pf + kl_fp).replace([np.inf, -np.inf], np.nan).fillna(0.0)\n",
    "\n",
    "    return X\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Những đặc trưng này cần được diễn giải chi tiết bằng các công thức toán học riêng ở báo cáo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-10T18:58:08.219000Z",
     "iopub.status.busy": "2025-12-10T18:58:08.218737Z",
     "iopub.status.idle": "2025-12-10T18:58:08.251544Z",
     "shell.execute_reply": "2025-12-10T18:58:08.250756Z",
     "shell.execute_reply.started": "2025-12-10T18:58:08.218982Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def transform_single(single_mouse, body_parts_tracked, fps):\n",
    "    \"\"\"Enhanced single mouse transform (FPS-aware windows/lags; distances in cm).\"\"\"\n",
    "    available_body_parts = single_mouse.columns.get_level_values(0)\n",
    "\n",
    "    # Base distance features (squared distances across body parts)\n",
    "    # ============================================================\n",
    "# BASE DISTANCE FEATURES\n",
    "# (Khoảng cách hình học giữa các cặp body part – dạng bình phương)\n",
    "# ============================================================\n",
    "# Mục đích trong pipeline:\n",
    "# - Mô tả hình dạng cơ thể (pose geometry) theo từng frame\n",
    "# - Phát hiện các trạng thái hành vi: duỗi người, co người, grooming, sniffing, v.v.\n",
    "# - Là feature nền tảng cho hầu hết mô hình tree-based (LGBM / CatBoost / XGB)\n",
    "#\n",
    "# Với mỗi cặp body part (p1, p2):\n",
    "#   p1(t) = (x1(t), y1(t))\n",
    "#   p2(t) = (x2(t), y2(t))\n",
    "#\n",
    "# Công thức toán học của feature tại frame t:\n",
    "#   d²(p1, p2, t) = (x1(t) - x2(t))² + (y1(t) - y2(t))²\n",
    "#\n",
    "# LƯU Ý:\n",
    "# - Đây là BÌNH PHƯƠNG khoảng cách Euclid (d²), không phải d.\n",
    "# - Nếu x,y đo bằng cm → đơn vị feature là cm².\n",
    "# - Dùng d² giúp:\n",
    "#   + tránh sqrt (nhanh hơn)\n",
    "#   + ổn định số\n",
    "#   + vẫn giữ quan hệ lớn/nhỏ của khoảng cách\n",
    "    X = pd.DataFrame({\n",
    "        f\"{p1}+{p2}\": \n",
    "                # single_mouse[p1] và single_mouse[p2] là DataFrame con (x, y)\n",
    "        # Hiệu tọa độ → (Δx, Δy)\n",
    "        # Bình phương từng thành phần → (Δx², Δy²)\n",
    "        # Cộng theo hàng (axis=1) → Δx² + Δy²\n",
    "        np.square(single_mouse[p1] - single_mouse[p2]).sum(axis=1, skipna=False)\n",
    "        for p1, p2 in itertools.combinations(body_parts_tracked, 2)\n",
    "        if p1 in available_body_parts and p2 in available_body_parts\n",
    "    })\n",
    "    X = X.reindex(columns=[f\"{p1}+{p2}\" for p1, p2 in itertools.combinations(body_parts_tracked, 2)], copy=False)\n",
    "\n",
    "    # Speed-like features via lagged displacements (duration-aware lag)\n",
    "# ============================================================\n",
    "# SPEED-LIKE FEATURES (dịch chuyển có trễ theo thời gian – FPS-aware)\n",
    "# ============================================================\n",
    "# Mục đích trong pipeline dự đoán hành động:\n",
    "# - Bắt chuyển động nhỏ & nhanh ở vùng đầu (tai) → rất mạnh cho grooming/sniffing\n",
    "# - Bắt sự “lệch đầu so với thân” theo thời gian → tách grooming khỏi locomotion\n",
    "# - Dùng lag ~ 0.33s (10 frame ở 30fps) để giảm nhiễu so với diff 1 frame\n",
    "#\n",
    "# Điều kiện: chỉ tính nếu có đủ các keypoint tai trái, tai phải, gốc đuôi\n",
    "if all(p in single_mouse.columns for p in ['ear_left', 'ear_right', 'tail_base']):\n",
    "    # _scale(10, fps): quy đổi 10 frame ở 30fps sang fps hiện tại để giữ nguyên khoảng thời gian thực\n",
    "    # lag ≈ round(10 * fps / 30)\n",
    "    # => Δt = lag / fps ≈ 10/30 ≈ 0.333s (gần như cố định theo thời gian, không phụ thuộc fps)\n",
    "    lag = _scale(10, fps)\n",
    "\n",
    "    # shifted: phiên bản \"quá khứ\" của (ear_left, ear_right, tail_base)\n",
    "    # shifted[p](t) = p(t - lag)\n",
    "    shifted = single_mouse[['ear_left', 'ear_right', 'tail_base']].shift(lag)\n",
    "\n",
    "    speeds = pd.DataFrame({\n",
    "        # sp_lf: bình phương độ dịch chuyển của tai trái trong khoảng Δt\n",
    "        # Công thức (tại frame t):\n",
    "        #   sp_lf(t) = (x_EL(t) - x_EL(t-lag))^2 + (y_EL(t) - y_EL(t-lag))^2\n",
    "        # Mục đích: đo cường độ chuyển động vùng đầu (tai) → mạnh cho grooming/sniffing; thấp khi resting\n",
    "        'sp_lf': np.square(single_mouse['ear_left'] - shifted['ear_left']).sum(axis=1, skipna=False),\n",
    "\n",
    "        # sp_rt: bình phương độ dịch chuyển của tai phải trong khoảng Δt\n",
    "        #   sp_rt(t) = (x_ER(t) - x_ER(t-lag))^2 + (y_ER(t) - y_ER(t-lag))^2\n",
    "        # Mục đích: tương tự sp_lf; giúp ổn định vì có 2 tai (giảm rủi ro mất keypoint một bên)\n",
    "        'sp_rt': np.square(single_mouse['ear_right'] - shifted['ear_right']).sum(axis=1, skipna=False),\n",
    "\n",
    "        # sp_lf2: khoảng cách (bình phương) giữa tai trái hiện tại và gốc đuôi ở quá khứ\n",
    "        #   sp_lf2(t) = (x_EL(t) - x_TB(t-lag))^2 + (y_EL(t) - y_TB(t-lag))^2\n",
    "        # Mục đích:\n",
    "        # - đo \"độ lệch đầu so với trục thân theo thời gian\"\n",
    "        # - bắt quay đầu/uốn người/grooming (đầu chuyển động mạnh khi thân ít đổi)\n",
    "        # - giúp phân biệt grooming vs locomotion (đi thẳng: đầu & thân di chuyển đồng bộ hơn)\n",
    "        'sp_lf2': np.square(single_mouse['ear_left'] - shifted['tail_base']).sum(axis=1, skipna=False),\n",
    "\n",
    "        # sp_rt2: tương tự sp_lf2 cho tai phải\n",
    "        #   sp_rt2(t) = (x_ER(t) - x_TB(t-lag))^2 + (y_ER(t) - y_TB(t-lag))^2\n",
    "        # Mục đích: bổ sung đối xứng trái/phải → bền hơn với nhiễu pose estimation\n",
    "        'sp_rt2': np.square(single_mouse['ear_right'] - shifted['tail_base']).sum(axis=1, skipna=False),\n",
    "    })\n",
    "\n",
    "    # Ghép 4 feature mới vào ma trận feature X (cùng index theo frame)\n",
    "    X = pd.concat([X, speeds], axis=1)\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# ELONGATION FEATURE (tỉ lệ \"dài / rộng\" của cơ thể – từ feature hình học)\n",
    "# ============================================================\n",
    "# Điều kiện: cần tồn tại 2 cột khoảng cách cơ bản đã tính trước:\n",
    "# - 'nose+tail_base'     ~ chiều dài cơ thể (d² giữa mũi và gốc đuôi)\n",
    "# - 'ear_left+ear_right' ~ độ rộng đầu (d² giữa hai tai)\n",
    "if 'nose+tail_base' in X.columns and 'ear_left+ear_right' in X.columns:\n",
    "    # elong: tỉ lệ kéo dài cơ thể (dạng bình phương vì tử & mẫu đều là d²)\n",
    "    # Công thức:\n",
    "    #   elong(t) = d²(nose, tail_base, t) / ( d²(ear_left, ear_right, t) + eps )\n",
    "    # với:\n",
    "    #   d²(a,b,t) = (x_a(t)-x_b(t))^2 + (y_a(t)-y_b(t))^2\n",
    "    # eps = 1e-6 để tránh chia cho 0\n",
    "    #\n",
    "    # Mục đích trong dự đoán hành động:\n",
    "    # - elong cao: chuột duỗi dài / locomotion / đứng thẳng hơn\n",
    "    # - elong thấp: chuột co người / grooming / resting\n",
    "    # - feature hình thái rất ổn định, giúp tách nhóm hành vi “tĩnh vs động” và “co vs duỗi”\n",
    "    X['elong'] = X['nose+tail_base'] / (X['ear_left+ear_right'] + 1e-6)\n",
    "\n",
    "\n",
    " # ============================================================\n",
    "# BODY ANGLE / ORIENTATION FEATURE (hướng & độ “thẳng/ cong” của cơ thể)\n",
    "# ============================================================\n",
    "# Điều kiện: phải có đủ 3 keypoint để xác định “trục thân” quanh body_center:\n",
    "# - nose       : đại diện hướng đầu\n",
    "# - body_center: điểm trung tâm thân (mốc tham chiếu)\n",
    "# - tail_base  : đại diện hướng đuôi\n",
    "if all(p in available_body_parts for p in ['nose', 'body_center', 'tail_base']):\n",
    "\n",
    "    # v1: vector từ body_center -> nose (hướng về phía đầu)\n",
    "    # v1(t) = nose(t) - body_center(t) = (x_n(t)-x_c(t), y_n(t)-y_c(t))\n",
    "    v1 = single_mouse['nose'] - single_mouse['body_center']\n",
    "\n",
    "    # v2: vector từ body_center -> tail_base (hướng về phía đuôi)\n",
    "    # v2(t) = tail_base(t) - body_center(t) = (x_t(t)-x_c(t), y_t(t)-y_c(t))\n",
    "    v2 = single_mouse['tail_base'] - single_mouse['body_center']\n",
    "\n",
    "    # body_ang: cosine của góc giữa 2 vector v1 và v2 (cos θ)\n",
    "    #\n",
    "    # Công thức tích vô hướng (dot product):\n",
    "    #   v1·v2 = v1x*v2x + v1y*v2y\n",
    "    #\n",
    "    # Chuẩn vector (norm):\n",
    "    #   ||v1|| = sqrt(v1x^2 + v1y^2)\n",
    "    #   ||v2|| = sqrt(v2x^2 + v2y^2)\n",
    "    #\n",
    "    # Cosine similarity:\n",
    "    #   cosθ(t) = (v1·v2) / (||v1|| * ||v2|| + eps)\n",
    "    # eps = 1e-6 để tránh chia cho 0 khi vector gần như bằng 0 (keypoint trùng nhau / lỗi pose)\n",
    "    #\n",
    "    # Giá trị và ý nghĩa hình học:\n",
    "    # - cosθ ≈ -1 : v1 và v2 ngược hướng → thân “thẳng” (đầu và đuôi hai phía đối nhau qua body_center)\n",
    "    # - cosθ ≈  0 : vuông góc → thân cong mạnh (body_center lệch, chuột uốn người)\n",
    "    # - cosθ ≈ +1 : cùng hướng → hiếm về mặt hình học nếu body_center nằm giữa đầu/đuôi,\n",
    "    #               thường chỉ xảy ra khi pose lỗi hoặc body_center lệch bất thường\n",
    "    #\n",
    "    # Mục đích trong pipeline dự đoán hành động:\n",
    "    # - Bắt “độ cong của thân” và trạng thái pose:\n",
    "    #   + Grooming / cuộn người: thường làm thân cong → cosθ tăng lên (ít âm hơn), dao động mạnh\n",
    "    #   + Locomotion thẳng: thân thẳng → cosθ gần -1 ổn định\n",
    "    #   + Turning / reorient: cosθ thay đổi nhanh theo thời gian (kết hợp với các feature temporal sẽ mạnh)\n",
    "    # - Đây là feature orientation/pose rất hữu ích vì không phụ thuộc tuyệt đối vị trí,\n",
    "    #   chỉ phụ thuộc hình dạng tương đối của cơ thể.\n",
    "    X['body_ang'] = (v1['x'] * v2['x'] + v1['y'] * v2['y']) / (\n",
    "        np.sqrt(v1['x']**2 + v1['y']**2) * np.sqrt(v2['x']**2 + v2['y']**2) + 1e-6\n",
    "    )\n",
    "\n",
    "\n",
    "    # Core temporal features (windows scaled by fps)\n",
    "# ============================================================\n",
    "# CORE TEMPORAL FEATURES (đặc trưng theo thời gian từ body_center – FPS-aware)\n",
    "# ============================================================\n",
    "# Mục đích trong pipeline dự đoán hành động:\n",
    "# - Dùng body_center để mô tả “chuyển động tổng thể” của chuột (global motion)\n",
    "# - Bắt các hành vi:\n",
    "#   + locomotion / chạy / đi lại: disp, rng, act cao\n",
    "#   + resting / đứng yên: các đại lượng thấp\n",
    "#   + turning / reorient: act tăng, mean/var thay đổi theo cửa sổ\n",
    "# - Dùng nhiều thang thời gian (5,15,30,60) để bắt:\n",
    "#   + chuyển động ngắn (micro-movement) vs dài (drift/locomotion)\n",
    "#\n",
    "# Điều kiện: phải có body_center trong dữ liệu\n",
    "if 'body_center' in available_body_parts:\n",
    "\n",
    "    # cx(t), cy(t): tọa độ tâm thân theo thời gian\n",
    "    # cx = x_body_center(t), cy = y_body_center(t)\n",
    "    cx = single_mouse['body_center']['x']\n",
    "    cy = single_mouse['body_center']['y']\n",
    "\n",
    "    # Duyệt các cửa sổ thời gian \"định nghĩa ở 30 fps\"\n",
    "    # w = [5, 15, 30, 60] frame @30fps tương ứng khoảng:\n",
    "    # - 5  -> 0.167s\n",
    "    # - 15 -> 0.5s\n",
    "    # - 30 -> 1.0s\n",
    "    # - 60 -> 2.0s\n",
    "    for w in [5, 15, 30, 60]:\n",
    "\n",
    "        # ws: số frame cửa sổ sau khi scale theo fps thực tế\n",
    "        # ws ≈ round(w * fps / 30)  => giữ nguyên độ dài theo thời gian thực\n",
    "        ws = _scale(w, fps)\n",
    "\n",
    "        # rolling với:\n",
    "        # - min_periods=1: vùng biên (đầu/cuối video) vẫn tính được (không bị NaN hàng loạt)\n",
    "        # - center=True : cửa sổ đặt đối xứng quanh frame t (dùng thông tin 2 phía)\n",
    "        roll = dict(min_periods=1, center=True)\n",
    "\n",
    "        # -----------------------------\n",
    "        # (1) Rolling MEAN vị trí\n",
    "        # -----------------------------\n",
    "        # cx_mw(t) = mean_{k in window(t,ws)} cx(k)\n",
    "        # cy_mw(t) = mean_{k in window(t,ws)} cy(k)\n",
    "        # Mục đích:\n",
    "        # - làm trơn vị trí (smooth trajectory)\n",
    "        # - cung cấp “vị trí trung bình cục bộ” → giúp phân biệt drift/locomotion vs jitter\n",
    "        X[f'cx_m{w}'] = cx.rolling(ws, **roll).mean()\n",
    "        X[f'cy_m{w}'] = cy.rolling(ws, **roll).mean()\n",
    "\n",
    "        # -----------------------------\n",
    "        # (2) Rolling STD (độ dao động vị trí)\n",
    "        # -----------------------------\n",
    "        # cx_sw(t) = std_{k in window} cx(k)\n",
    "        # cy_sw(t) = std_{k in window} cy(k)\n",
    "        # Mục đích:\n",
    "        # - đo mức rung/dao động quanh vị trí trung tâm\n",
    "        # - resting: std nhỏ; locomotion/di chuyển nhiều: std lớn\n",
    "        X[f'cx_s{w}'] = cx.rolling(ws, **roll).std()\n",
    "        X[f'cy_s{w}'] = cy.rolling(ws, **roll).std()\n",
    "\n",
    "        # -----------------------------\n",
    "        # (3) Range (phạm vi di chuyển trong cửa sổ)\n",
    "        # -----------------------------\n",
    "        # x_rngw(t) = max(cx) - min(cx) trong cửa sổ\n",
    "        # y_rngw(t) = max(cy) - min(cy) trong cửa sổ\n",
    "        # Mục đích:\n",
    "        # - đo “độ mở rộng” quãng đường (đi xa hay chỉ lắc nhẹ)\n",
    "        # - hữu ích cho locomotion vs grooming/resting\n",
    "        X[f'x_rng{w}'] = cx.rolling(ws, **roll).max() - cx.rolling(ws, **roll).min()\n",
    "        X[f'y_rng{w}'] = cy.rolling(ws, **roll).max() - cy.rolling(ws, **roll).min()\n",
    "\n",
    "        # -----------------------------\n",
    "        # (4) dispw: dịch chuyển ròng (net displacement) trong cửa sổ\n",
    "        # -----------------------------\n",
    "        # diff:\n",
    "        #   dx(t) = cx(t) - cx(t-1)\n",
    "        #   dy(t) = cy(t) - cy(t-1)\n",
    "        #\n",
    "        # code đang làm:\n",
    "        #   sum_dx(t) = Σ_{k in window} dx(k)\n",
    "        #   sum_dy(t) = Σ_{k in window} dy(k)\n",
    "        #   dispw(t)  = sqrt( sum_dx(t)^2 + sum_dy(t)^2 )\n",
    "        #\n",
    "        # Ý nghĩa:\n",
    "        # - Đây là “dịch chuyển ròng” (net displacement), gần với:\n",
    "        #     || (cx(t_end) - cx(t_start), cy(t_end) - cy(t_start)) ||\n",
    "        # - Cao khi chuột thật sự đi từ chỗ A sang chỗ B (locomotion)\n",
    "        # - Thấp khi chuột chuyển động lắc qua lại tại chỗ (grooming)\n",
    "        #\n",
    "        # Lưu ý:\n",
    "        # - Đây KHÔNG phải “tổng quãng đường” (path length).\n",
    "        #   Nếu muốn path length: Σ sqrt(dx^2 + dy^2) trong cửa sổ.\n",
    "        X[f'disp{w}'] = np.sqrt(\n",
    "            cx.diff().rolling(ws, min_periods=1).sum()**2 +\n",
    "            cy.diff().rolling(ws, min_periods=1).sum()**2\n",
    "        )\n",
    "\n",
    "        # -----------------------------\n",
    "        # (5) actw: mức hoạt động (activity) dựa trên biến thiên vận tốc\n",
    "        # -----------------------------\n",
    "        # dx(t), dy(t) như trên\n",
    "        #\n",
    "        # code đang làm:\n",
    "        #   var_dx(t) = Var_{k in window} dx(k)\n",
    "        #   var_dy(t) = Var_{k in window} dy(k)\n",
    "        #   actw(t)   = sqrt( var_dx(t) + var_dy(t) )\n",
    "        #\n",
    "        # Ý nghĩa:\n",
    "        # - đo “độ rung / mức thay đổi chuyển động” trong cửa sổ\n",
    "        # - grooming / shaking: dx,dy dao động nhanh → var cao → act cao\n",
    "        # - resting: var gần 0\n",
    "        # - locomotion đều: var vừa phải (tùy đều hay giật)\n",
    "        #\n",
    "        # act thường bổ sung tốt cho disp:\n",
    "        # - disp cao + act cao  -> chạy/di chuyển mạnh\n",
    "        # - disp thấp + act cao -> rung tại chỗ (grooming)\n",
    "        # - disp thấp + act thấp-> nghỉ\n",
    "        X[f'act{w}'] = np.sqrt(\n",
    "            cx.diff().rolling(ws, min_periods=1).var() +\n",
    "            cy.diff().rolling(ws, min_periods=1).var()\n",
    "        )\n",
    "\n",
    "\n",
    "        # Advanced features (fps-scaled)\n",
    "        # MỤC ĐÍCH CHUNG:\n",
    "# - Bổ sung feature “hình học + thời gian + trạng thái” để model phân biệt hành vi tốt hơn\n",
    "# - Tất cả window/lag đều FPS-aware: ws = round(w * fps / 30) → giữ ý nghĩa theo GIÂY giữa các video\n",
    "# - Nhóm feature này đặc biệt hữu ích cho:\n",
    "#   + Locomotion / exploration / turning (đi thẳng vs đi cong, xu hướng dài hạn)\n",
    "#   + Grooming (đầu hoạt động mạnh nhưng thân ít đi)\n",
    "#   + Transition (onset/offset hành vi) nhờ so sánh past–future\n",
    "# cong thuc o cell ben tren \n",
    "        X = add_curvature_features(X, cx, cy, fps)\n",
    "        X = add_multiscale_features(X, cx, cy, fps)\n",
    "        X = add_state_features(X, cx, cy, fps)\n",
    "        X = add_longrange_features(X, cx, cy, fps)\n",
    "        X = add_cumulative_distance_single(X, cx, cy, fps, horizon_frames_base=180)\n",
    "        X = add_groom_microfeatures(X, single_mouse, fps)\n",
    "        X = add_speed_asymmetry_future_past_single(X, cx, cy, fps, horizon_base=30)         \n",
    "        X = add_gauss_shift_speed_future_past_single(X, cx, cy, fps, window_base=30)\n",
    "  \n",
    " # ================= NOSE–TAIL FEATURES (FPS-AWARE TEMPORAL LAGS) =================\n",
    "# MỤC ĐÍCH CHUNG:\n",
    "# - Đo hình học TRỤC CƠ THỂ (đầu ↔ đuôi) và sự thay đổi của nó theo thời gian\n",
    "# - Bắt các hành vi liên quan đến:\n",
    "#   + co / duỗi thân\n",
    "#   + cúi đầu / cong lưng\n",
    "#   + grooming (đầu hoạt động, thân ít di chuyển)\n",
    "#   + chuyển pha hành vi (onset / offset)\n",
    "# - Các lag được scale theo fps để giữ đúng ý nghĩa theo GIÂY\n",
    "\n",
    "if all(p in available_body_parts for p in ['nose', 'tail_base']):\n",
    "\n",
    "    # ------------------------------------------------------------\n",
    "    # 1) KHOẢNG CÁCH MŨI – GỐC ĐUÔI (NOSE–TAIL DISTANCE)\n",
    "    # ------------------------------------------------------------\n",
    "    # nt_dist(t) = || nose(t) - tail_base(t) ||\n",
    "    #\n",
    "    # Công thức hình học:\n",
    "    #   nt_dist(t) = sqrt( (x_n(t) - x_t(t))^2 + (y_n(t) - y_t(t))^2 )\n",
    "    #\n",
    "    # Ý nghĩa hình thái:\n",
    "    # - Đại diện cho \"độ dài tức thời\" của trục cơ thể\n",
    "    # - Thân duỗi thẳng  → nt_dist lớn\n",
    "    # - Thân cong / cúi đầu / co người → nt_dist nhỏ\n",
    "    #\n",
    "    # Ý nghĩa hành vi:\n",
    "    # - Locomotion thẳng: nt_dist thường ổn định\n",
    "    # - Grooming: nt_dist dao động (đầu cúi/ngẩng/chải)\n",
    "    # - Transition hành vi: nt_dist thay đổi có xu hướng (tăng hoặc giảm)\n",
    "    nt_dist = np.sqrt(\n",
    "        (single_mouse['nose']['x'] - single_mouse['tail_base']['x'])**2 +\n",
    "        (single_mouse['nose']['y'] - single_mouse['tail_base']['y'])**2\n",
    "    )\n",
    "\n",
    "    # ------------------------------------------------------------\n",
    "    # 2) CÁC LAG THỜI GIAN (FPS-INVARIANT)\n",
    "    # ------------------------------------------------------------\n",
    "    # lag = số frame chuẩn @30fps:\n",
    "    #   10 frame ≈ 0.33 s\n",
    "    #   20 frame ≈ 0.67 s\n",
    "    #   40 frame ≈ 1.33 s\n",
    "    #\n",
    "    # _scale(lag, fps):\n",
    "    #   → chuyển lag chuẩn sang số frame thực tế của video\n",
    "    #   → giữ nguyên ý nghĩa theo THỜI GIAN THỰC giữa các video\n",
    "    for lag in [10, 20, 40]:\n",
    "        l = _scale(lag, fps)\n",
    "\n",
    "        # --------------------------------------------------------\n",
    "        # 2a) nt_lg{lag}: GIÁ TRỊ QUÁ KHỨ CỦA NOSE–TAIL DISTANCE\n",
    "        # --------------------------------------------------------\n",
    "        # nt_lg{lag}(t) = nt_dist(t - l)\n",
    "        #\n",
    "        # Ý nghĩa:\n",
    "        # - Cung cấp \"bối cảnh hình thái\" trong quá khứ\n",
    "        # - Cho model biết:\n",
    "        #   + thân trước đó dài hay ngắn?\n",
    "        #   + xu hướng cong/duỗi đang diễn ra trong bao lâu?\n",
    "        #\n",
    "        # Hữu ích khi kết hợp với nt_df{lag} để bắt xu hướng\n",
    "        X[f'nt_lg{lag}'] = nt_dist.shift(l)\n",
    "\n",
    "        # --------------------------------------------------------\n",
    "        # 2b) nt_df{lag}: ĐỘ THAY ĐỔI NOSE–TAIL DISTANCE\n",
    "        # --------------------------------------------------------\n",
    "        # nt_df{lag}(t) = nt_dist(t) - nt_dist(t - l)\n",
    "        #\n",
    "        # Diễn giải dấu:\n",
    "        # - nt_df > 0  → thân đang DUỖI RA (nose–tail tăng)\n",
    "        # - nt_df < 0  → thân đang CO / CONG (nose–tail giảm)\n",
    "        # - nt_df ≈ 0  → hình thái thân ổn định\n",
    "        #\n",
    "        # Ý nghĩa hành vi:\n",
    "        # - Grooming:\n",
    "        #     nt_df dao động ± nhanh (đầu cúi/ngẩng lặp lại)\n",
    "        # - Locomotion đều:\n",
    "        #     nt_df ≈ 0 trong nhiều frame\n",
    "        # - Transition (onset/offset):\n",
    "        #     nt_df có xu hướng cùng dấu trong ~0.3–1.3s\n",
    "        #\n",
    "        # Lý do dùng nhiều lag:\n",
    "        # - lag nhỏ (10): bắt biến đổi nhanh (micro posture change)\n",
    "        # - lag lớn (40): bắt xu hướng hình thái kéo dài\n",
    "        X[f'nt_df{lag}'] = nt_dist - nt_dist.shift(l)\n",
    "\n",
    "\n",
    " # ================= EAR FEATURES (FPS-AWARE OFFSETS) =================\n",
    "# MỤC ĐÍCH:\n",
    "# - ear_d(t)=||ear_left(t)-ear_right(t)|| phản ánh hình học vùng đầu (bề ngang/pose) và mức rung đầu\n",
    "# - ear_o{off}: lấy ear_d ở quá khứ/tương lai (~0.33s, ~0.67s) để cung cấp \"temporal context\"\n",
    "# - ear_con: hệ số biến thiên (std/mean) của ear_d trong ~1s → đo mức dao động tương đối (head jitter/grooming)\n",
    "\n",
    "if all(p in available_body_parts for p in ['ear_left', 'ear_right']):\n",
    "\n",
    "    # ear_d(t) = sqrt((x_L-x_R)^2 + (y_L-y_R)^2)\n",
    "    # - lớn/nhỏ thay đổi theo hướng quay đầu + dao động keypoint\n",
    "    ear_d = np.sqrt(\n",
    "        (single_mouse['ear_left']['x'] - single_mouse['ear_right']['x'])**2 +\n",
    "        (single_mouse['ear_left']['y'] - single_mouse['ear_right']['y'])**2\n",
    "    )\n",
    "\n",
    "    # Offsets (fps-invariant): off ∈ {-20,-10,+10,+20} frames @30fps (~±0.33s, ±0.67s)\n",
    "    # ear_o{off}(t) = ear_d(t + Δt_off)  (acausal nếu off>0)\n",
    "    for off in [-20, -10, 10, 20]:\n",
    "        o = _scale_signed(off, fps)      # giữ dấu và giữ ý nghĩa theo giây\n",
    "        X[f'ear_o{off}'] = ear_d.shift(-o)  # shift(-o) để off<0 lấy quá khứ, off>0 lấy tương lai\n",
    "\n",
    "    # ear_con(t) = std_w(ear_d)/ (mean_w(ear_d)+eps)  (Coefficient of Variation)\n",
    "    # - cao: ear_d dao động mạnh tương đối → grooming/head jitter/sniff hoặc tracking rung\n",
    "    # - thấp: ổn định → đứng yên/locomotion ổn định\n",
    "    w = _scale(30, fps)  # ~1s\n",
    "    X['ear_con'] = (\n",
    "        ear_d.rolling(w, min_periods=1, center=True).std() /\n",
    "        (ear_d.rolling(w, min_periods=1, center=True).mean() + 1e-6)\n",
    "    )\n",
    "\n",
    "return X.astype(np.float32, copy=False)\n",
    "\n",
    "\n",
    "def transform_pair(mouse_pair, body_parts_tracked, fps):\n",
    "    \"\"\"Enhanced pair transform (FPS-aware windows/lags; distances in cm).\"\"\"\n",
    "    avail_A = mouse_pair['A'].columns.get_level_values(0)\n",
    "    avail_B = mouse_pair['B'].columns.get_level_values(0)\n",
    "\n",
    "    # Inter-mouse distances (squared distances across all part pairs)\n",
    "    X = pd.DataFrame({\n",
    "        f\"12+{p1}+{p2}\": np.square(mouse_pair['A'][p1] - mouse_pair['B'][p2]).sum(axis=1, skipna=False)\n",
    "        for p1, p2 in itertools.product(body_parts_tracked, repeat=2)\n",
    "        if p1 in avail_A and p2 in avail_B\n",
    "    })\n",
    "    X = X.reindex(columns=[f\"12+{p1}+{p2}\" for p1, p2 in itertools.product(body_parts_tracked, repeat=2)], copy=False)\n",
    "\n",
    "# ================= SPEED-LIKE FEATURES (FPS-AWARE LAGGED DISPLACEMENT) =================\n",
    "# MỤC ĐÍCH:\n",
    "# - sp_A, sp_B: mức độ di chuyển ngắn hạn (~0.33s) của từng con (activity burst)\n",
    "# - sp_AB: “độ bám theo” thô: A hiện tại so với B quá khứ (gợi ý following/chase)\n",
    "# Lưu ý: dùng squared displacement (không sqrt, không chia thời gian) vì tree model học vẫn tốt.\n",
    "\n",
    "if ('A', 'ear_left') in mouse_pair.columns and ('B', 'ear_left') in mouse_pair.columns:\n",
    "    lag = _scale(10, fps)  # 10 frame @30fps ≈ 0.33s → scale để giữ thời gian thực\n",
    "\n",
    "    shA = mouse_pair['A']['ear_left'].shift(lag)  # A(t-lag)\n",
    "    shB = mouse_pair['B']['ear_left'].shift(lag)  # B(t-lag)\n",
    "\n",
    "    # sp_A(t)  = ||A(t) - A(t-lag)||^2\n",
    "    # sp_B(t)  = ||B(t) - B(t-lag)||^2\n",
    "    # sp_AB(t) = ||A(t) - B(t-lag)||^2  (A “gặp” vị trí quá khứ của B -> dấu hiệu chase/follow)\n",
    "    speeds = pd.DataFrame({\n",
    "        'sp_A':  np.square(mouse_pair['A']['ear_left'] - shA).sum(axis=1, skipna=False),\n",
    "        'sp_AB': np.square(mouse_pair['A']['ear_left'] - shB).sum(axis=1, skipna=False),\n",
    "        'sp_B':  np.square(mouse_pair['B']['ear_left'] - shB).sum(axis=1, skipna=False),\n",
    "    })\n",
    "\n",
    "    X = pd.concat([X, speeds], axis=1)\n",
    "\n",
    "# ================= ELONGATION RATIO =================\n",
    "# elong(t) = d^2(nose, tail_base) / ( d^2(ear_left, ear_right) + eps )\n",
    "# - cao: thân duỗi thẳng (locomotion/chase)\n",
    "# - thấp/dao động: co/cong/grooming\n",
    "# NOTE: trong transform_pair, các cột 'nose+tail_base'/'ear_left+ear_right' có thể không tồn tại\n",
    "#       nếu bạn chỉ tạo cột dạng '12+...'. Nếu muốn, hãy tính elong_A/elong_B riêng.\n",
    "if 'nose+tail_base' in X.columns and 'ear_left+ear_right' in X.columns:\n",
    "    X['elong'] = X['nose+tail_base'] / (X['ear_left+ear_right'] + 1e-6)\n",
    "\n",
    "\n",
    "# ================= RELATIVE ORIENTATION (COSINE SIMILARITY) =================\n",
    "# MỤC ĐÍCH:\n",
    "# - Đo 2 con chuột đang quay cùng hướng hay ngược hướng (body axis alignment)\n",
    "# - Dùng trục thân: tail_base -> nose\n",
    "#\n",
    "# dir_A(t) = nose_A(t) - tail_A(t)\n",
    "# dir_B(t) = nose_B(t) - tail_B(t)\n",
    "#\n",
    "# rel_ori(t) = cos(theta) = (dir_A · dir_B) / (||dir_A|| * ||dir_B|| + eps)\n",
    "# - ≈ +1 : cùng hướng (song song, following/side-by-side)\n",
    "# - ≈  0 : vuông góc\n",
    "# - ≈ -1 : ngược hướng (face-to-face / đối đầu / quay mặt nhau)\n",
    "# eps giúp tránh chia 0 khi vector rất nhỏ do tracking/noise\n",
    "\n",
    "if all(p in avail_A for p in ['nose', 'tail_base']) and all(p in avail_B for p in ['nose', 'tail_base']):\n",
    "    dir_A = mouse_pair['A']['nose'] - mouse_pair['A']['tail_base']\n",
    "    dir_B = mouse_pair['B']['nose'] - mouse_pair['B']['tail_base']\n",
    "    X['rel_ori'] = (dir_A['x'] * dir_B['x'] + dir_A['y'] * dir_B['y']) / (\n",
    "        np.sqrt(dir_A['x']**2 + dir_A['y']**2) * np.sqrt(dir_B['x']**2 + dir_B['y']**2) + 1e-6\n",
    "    )\n",
    "\n",
    "\n",
    "# ================= APPROACH RATE (FPS-AWARE) =================\n",
    "# MỤC ĐÍCH:\n",
    "# - Đo A và B đang tiến lại gần hay tách ra trong ~0.33s\n",
    "# - Dùng nose-nose distance vì phản ánh tương tác xã hội (sniff/approach) mạnh\n",
    "#\n",
    "# cur(t)  = ||nose_A(t) - nose_B(t)||^2\n",
    "# past(t) = ||nose_A(t-lag) - nose_B(t-lag)||^2   (lag ~10 frame @30fps, scale theo fps)\n",
    "# appr(t) = cur(t) - past(t)\n",
    "# - appr < 0 : khoảng cách GIẢM -> đang APPROACH (tiếp cận)\n",
    "# - appr > 0 : khoảng cách TĂNG -> đang WITHDRAW/AVOID (rời xa)\n",
    "# - appr ~ 0 : giữ khoảng cách\n",
    "\n",
    "if all(p in avail_A for p in ['nose']) and all(p in avail_B for p in ['nose']):\n",
    "    cur = np.square(mouse_pair['A']['nose'] - mouse_pair['B']['nose']).sum(axis=1, skipna=False)\n",
    "    lag = _scale(10, fps)  # ~0.33s\n",
    "    shA_n = mouse_pair['A']['nose'].shift(lag)\n",
    "    shB_n = mouse_pair['B']['nose'].shift(lag)\n",
    "    past = np.square(shA_n - shB_n).sum(axis=1, skipna=False)\n",
    "    X['appr'] = cur - past\n",
    "\n",
    "\n",
    " # ================= DISTANCE BINS (BODY CENTER) =================\n",
    "# MỤC ĐÍCH:\n",
    "# - Phân vùng khoảng cách thân–thân thành các mức rời rạc (one-hot)\n",
    "# - Giúp model học \"ngữ cảnh tương tác\" rõ ràng hơn so với distance liên tục\n",
    "#\n",
    "# cd(t) = || body_center_A(t) - body_center_B(t) ||  (cm)\n",
    "#\n",
    "# v_cls : cd < 5 cm   -> rất gần (tiếp xúc / sniff / face contact)\n",
    "# cls   : 5–15 cm     -> gần (tương tác trực tiếp)\n",
    "# med   : 15–30 cm    -> trung bình (quan sát / chuẩn bị tiếp cận)\n",
    "# far   : >= 30 cm    -> xa (không tương tác)\n",
    "#\n",
    "# Lưu ý:\n",
    "# - Mỗi frame đúng 1 bin = 1\n",
    "# - Không phụ thuộc fps (pure geometry)\n",
    "# - Giảm overfit, tăng PR-AUC/F1 cho social behaviors\n",
    "\n",
    "if 'body_center' in avail_A and 'body_center' in avail_B:\n",
    "    cd = np.sqrt(\n",
    "        (mouse_pair['A']['body_center']['x'] - mouse_pair['B']['body_center']['x'])**2 +\n",
    "        (mouse_pair['A']['body_center']['y'] - mouse_pair['B']['body_center']['y'])**2\n",
    "    )\n",
    "    X['v_cls'] = (cd < 5.0).astype(float)\n",
    "    X['cls']   = ((cd >= 5.0) & (cd < 15.0)).astype(float)\n",
    "    X['med']   = ((cd >= 15.0) & (cd < 30.0)).astype(float)\n",
    "    X['far']   = (cd >= 30.0).astype(float)\n",
    "\n",
    "# ================= TEMPORAL INTERACTION FEATURES (FPS-AWARE) =================\n",
    "# MỤC ĐÍCH:\n",
    "# - Từ khoảng cách thân–thân theo frame → tạo đặc trưng theo thời gian (multi-scale context)\n",
    "# - Bắt các pattern tương tác: đứng gần ổn định, tiếp cận/rời xa, chase/avoid, đi cùng nhau...\n",
    "#\n",
    "# cd_full(t) = ||C_A(t) - C_B(t)||^2  (squared distance between body centers)\n",
    "# Rolling windows w in {5,15,30,60} frame @30fps (scale theo fps để giữ thời gian thực)\n",
    "\n",
    "if 'body_center' in avail_A and 'body_center' in avail_B:\n",
    "    cd_full = np.square(mouse_pair['A']['body_center'] - mouse_pair['B']['body_center']).sum(axis=1, skipna=False)\n",
    "\n",
    "    for w in [5, 15, 30, 60]:\n",
    "        ws = _scale(w, fps)\n",
    "        roll = dict(min_periods=1, center=True)  # acausal context quanh frame t\n",
    "\n",
    "        # d_mw  = mean_w(cd_full): mức gần/xa trung bình trong ~w (gợi ý contact vs ignore)\n",
    "        # d_sw  = std_w(cd_full): độ dao động khoảng cách (cao -> chase/avoid, thấp -> ổn định)\n",
    "        # d_mnw = min_w(cd_full): có lúc rất gần (bắt event sniff ngắn)\n",
    "        # d_mxw = max_w(cd_full): có lúc rất xa (bắt vòng quanh/thoát ra)\n",
    "        X[f'd_m{w}']  = cd_full.rolling(ws, **roll).mean()\n",
    "        X[f'd_s{w}']  = cd_full.rolling(ws, **roll).std()\n",
    "        X[f'd_mn{w}'] = cd_full.rolling(ws, **roll).min()\n",
    "        X[f'd_mx{w}'] = cd_full.rolling(ws, **roll).max()\n",
    "\n",
    "        # intw = 1 / (1 + Var_w(cd_full)): “độ ổn định tương tác”\n",
    "        # - var nhỏ -> int ~1 (đứng gần/đi cùng ổn định)\n",
    "        # - var lớn -> int ~0 (chase/avoid làm khoảng cách biến thiên mạnh)\n",
    "        d_var = cd_full.rolling(ws, **roll).var()\n",
    "        X[f'int{w}'] = 1 / (1 + d_var)\n",
    "\n",
    "        # coord(t) = vA(t) · vB(t) = ΔxAΔxB + ΔyAΔyB  (velocity alignment thô)\n",
    "        # - coord >0: cùng hướng (following/di chuyển song song)\n",
    "        # - coord <0: ngược hướng (đối đầu/né tránh)\n",
    "        Axd = mouse_pair['A']['body_center']['x'].diff()\n",
    "        Ayd = mouse_pair['A']['body_center']['y'].diff()\n",
    "        Bxd = mouse_pair['B']['body_center']['x'].diff()\n",
    "        Byd = mouse_pair['B']['body_center']['y'].diff()\n",
    "        coord = Axd * Bxd + Ayd * Byd\n",
    "\n",
    "        # co_mw = mean_w(coord): xu hướng alignment trong ~w\n",
    "        # co_sw = std_w(coord): độ “hỗn loạn” alignment (cao -> circling/đổi pha liên tục)\n",
    "        X[f'co_m{w}'] = coord.rolling(ws, **roll).mean()\n",
    "        X[f'co_s{w}'] = coord.rolling(ws, **roll).std()\n",
    "\n",
    "\n",
    "# ================= NOSE–NOSE DYNAMICS (FPS-AWARE LAGS) =================\n",
    "# MỤC ĐÍCH:\n",
    "# - Nose-nose distance phản ánh trực tiếp “tương tác chủ động” (sniff/face contact)\n",
    "# - Tạo đặc trưng theo thời gian: quá khứ, thay đổi khoảng cách, và % thời gian ở gần\n",
    "#\n",
    "# nn(t) = || nose_A(t) - nose_B(t) ||  (cm)\n",
    "# Với mỗi lag (10/20/40 frame @30fps, scale theo fps):\n",
    "# - nn_lg(t)  = nn(t-l)               : khoảng cách quá khứ (context)\n",
    "# - nn_ch(t)  = nn(t) - nn(t-l)       : delta distance\n",
    "#     * <0 -> đang approach (tiến lại gần)\n",
    "#     * >0 -> đang withdraw/avoid (rời xa)\n",
    "# - cl_ps(t)  = mean_{window=l}( I[nn < 10cm] )\n",
    "#     * % thời gian “ở gần” trong ~lag (giảm FP, tăng precision/PR-AUC)\n",
    "\n",
    "if 'nose' in avail_A and 'nose' in avail_B:\n",
    "    nn = np.sqrt(\n",
    "        (mouse_pair['A']['nose']['x'] - mouse_pair['B']['nose']['x'])**2 +\n",
    "        (mouse_pair['A']['nose']['y'] - mouse_pair['B']['nose']['y'])**2\n",
    "    )\n",
    "\n",
    "    for lag in [10, 20, 40]:\n",
    "        l = _scale(lag, fps)\n",
    "        X[f'nn_lg{lag}'] = nn.shift(l)              # nn(t-l)\n",
    "        X[f'nn_ch{lag}'] = nn - nn.shift(l)         # nn(t) - nn(t-l)\n",
    "\n",
    "        is_cl = (nn < 10.0).astype(float)           # I[nn(t) < 10cm]\n",
    "        X[f'cl_ps{lag}'] = is_cl.rolling(l, min_periods=1).mean()  # % close time\n",
    "\n",
    "\n",
    "  # ================= VELOCITY ALIGNMENT (FPS-AWARE OFFSETS) =================\n",
    "# MỤC ĐÍCH:\n",
    "# - Đo 2 con di chuyển CÙNG HƯỚNG hay NGƯỢC HƯỚNG (directional coupling)\n",
    "# - Dùng cosine similarity của vận tốc thân (body_center):\n",
    "#\n",
    "# vA(t) = (ΔxA, ΔyA), vB(t) = (ΔxB, ΔyB)\n",
    "# val(t) = cos(theta) = (vA·vB) / (||vA|| ||vB|| + eps)  ∈ [-1,1]\n",
    "#   ~ +1 : cùng hướng (following / chase song song)\n",
    "#   ~  0 : không liên quan / vuông góc / một con đứng yên\n",
    "#   ~ -1 : ngược hướng (avoid/withdraw/confront)\n",
    "#\n",
    "# Tạo thêm offsets va_{off} để bắt chuyển pha:\n",
    "# - va_-20, va_-10 : alignment quá khứ\n",
    "# - va_0           : alignment hiện tại\n",
    "# - va_+10, va_+20 : alignment tương lai (acausal, tốt cho offline)\n",
    "    if 'body_center' in avail_A and 'body_center' in avail_B:\n",
    "        Avx = mouse_pair['A']['body_center']['x'].diff()\n",
    "        Avy = mouse_pair['A']['body_center']['y'].diff()\n",
    "        Bvx = mouse_pair['B']['body_center']['x'].diff()\n",
    "        Bvy = mouse_pair['B']['body_center']['y'].diff()\n",
    "        val = (Avx * Bvx + Avy * Bvy) / (np.sqrt(Avx**2 + Avy**2) * np.sqrt(Bvx**2 + Bvy**2) + 1e-6)\n",
    "\n",
    "        for off in [-20, -10, 0, 10, 20]:\n",
    "            o = _scale_signed(off, fps) # giữ đúng thời gian thực + giữ dấu (past/future)\n",
    "            X[f'va_{off}'] = val.shift(-o)# -o: future->present, +o: past->present\n",
    "        # ================= INTERACTION CONSISTENCY (CV OF DISTANCE) =================\n",
    "    # int_con(t) = std_w(cd_full) / (mean_w(cd_full) + eps)\n",
    "    # - thấp: khoảng cách ổn định (đứng gần/xa ổn định hoặc đi cùng nhau ổn định)\n",
    "    # - cao : khoảng cách dao động mạnh (chase/avoid/circling), thường giúp giảm FP -> tăng PR-AUC\n",
    "        w = _scale(30, fps)\n",
    "        X['int_con'] = cd_full.rolling(w, min_periods=1, center=True).std() / \\\n",
    "                       (cd_full.rolling(w, min_periods=1, center=True).mean() + 1e-6)\n",
    "\n",
    "        # Advanced interaction (fps-adjusted internals)\n",
    "        X = add_interaction_features(X, mouse_pair, avail_A, avail_B, fps)\n",
    "        \n",
    "\n",
    "    return X.astype(np.float32, copy=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hàm transform_single được thiết kế để trích xuất các đặc trưng hành vi từ dữ liệu theo dõi chuyển động của một con chuột đơn lẻ. Ý tưởng chính là biến đổi các tọa độ thô của từng bộ phận cơ thể thành những đặc trưng có ý nghĩa sinh học và hành vi. Các đặc trưng này bao gồm thông tin không gian, tốc độ, hướng di chuyển và các biến đổi theo thời gian. Toàn bộ các phép tính đều được điều chỉnh theo số khung hình mỗi giây nhằm bảo đảm rằng đặc trưng nhất quán giữa các video có tốc độ ghi hình khác nhau.\n",
    "\n",
    "Đầu tiên hàm tính toán các đặc trưng khoảng cách giữa mọi cặp bộ phận cơ thể. Giá trị sử dụng là bình phương khoảng cách để tránh phép căn bậc hai không cần thiết và để nhấn mạnh sự thay đổi về hình dạng cơ thể. Nhóm đặc trưng này cung cấp thông tin về tư thế, độ dài cơ thể, độ mở của tai và các mối quan hệ hình học quan trọng.\n",
    "\n",
    "Tiếp theo hàm tạo ra các đặc trưng về tốc độ bằng cách dùng độ lệch theo thời gian giữa các khung hình. Độ trễ thời gian được điều chỉnh theo fps để bảo đảm rằng một đơn vị thời gian luôn mang cùng ý nghĩa giữa các video. Các đặc trưng tốc độ được tính trên các bộ phận như tai trái, tai phải và gốc đuôi nhằm phản ánh sự chuyển động cục bộ của đầu và thân.\n",
    "\n",
    "Hàm cũng tạo ra đặc trưng độ kéo dài cơ thể dựa trên tỷ lệ giữa khoảng cách mũi với gốc đuôi và khoảng cách giữa hai tai. Tỷ lệ này có thể phản ánh trạng thái cơ thể khi chuột đang vươn dài hoặc thu nhỏ. Sau đó hàm tính các đặc trưng về góc định hướng của cơ thể bằng cách đo góc tạo bởi các vectơ hướng từ mũi và đuôi đến trung tâm thân. Đây là một đặc trưng quan trọng để nhận diện tư thế và hướng chuyển động.\n",
    "\n",
    "Phần quan trọng tiếp theo là các đặc trưng theo thời gian dựa trên cửa sổ trượt. Các cửa sổ được mở rộng hoặc thu hẹp theo fps nhằm bảo đảm rằng các đặc trưng như giá trị trung bình, độ lệch chuẩn, biên độ chuyển động và tổng độ dịch chuyển đều tương ứng với cùng một khoảng thời gian thực tế. Các đặc trưng này phản ánh nhịp độ hoạt động, mức dao động và mức ổn định trong chuyển động của chuột.\n",
    "\n",
    "Sau phần đặc trưng cơ bản hàm bổ sung một loạt đặc trưng nâng cao bao gồm độ cong quỹ đạo, đặc trưng đa tỉ lệ, trạng thái chuyển động, khoảng cách tích lũy, các đặc trưng liên quan đến hành vi chăm sóc cơ thể và bất đối xứng tốc độ giữa tương lai và quá khứ. Những đặc trưng này được thiết kế để phát hiện các hành vi tinh tế như di chuyển nhanh, dừng tạm thời hoặc thay đổi hướng đột ngột.\n",
    "\n",
    "Cuối cùng hàm thêm các đặc trưng liên quan đến mối quan hệ giữa mũi và gốc đuôi cùng với các thuộc tính của tai. Các đặc trưng này giúp mô tả hành vi liếm chải, cúi đầu hoặc hướng chú ý. Tất cả giá trị sau cùng được chuẩn hóa về dạng số thực và trả lại dưới dạng bảng đặc trưng hoàn chỉnh."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hàm transform_pair mở rộng các ý tưởng trên để xử lý dữ liệu của hai con chuột cùng lúc. Mục tiêu của hàm là mô tả tương tác không gian và thời gian giữa hai cá thể. Đây là bước quan trọng trong phân tích hành vi xã hội như tiếp cận, theo dõi, né tránh hoặc giao tiếp.\n",
    "\n",
    "Đầu tiên hàm tạo các đặc trưng về khoảng cách giữa từng cặp bộ phận của hai con chuột. Việc character hóa sự gần gũi giữa từng bộ phận giúp nhận biết các hành vi như ngửi, tiếp xúc hoặc rượt đuổi. Sau đó hàm tính các đặc trưng tốc độ dựa trên độ trễ theo thời gian cho từng chuột và cho cả hai chuột kết hợp. Điều này giúp mô tả các trạng thái như chuột A tiến lại gần chuột B hoặc hai con di chuyển đồng bộ.\n",
    "\n",
    "Hàm bổ sung đặc trưng góc định hướng tương đối giữa hai chuột nhằm xác định xem chúng đang đối mặt hay quay lưng nhau. Kế đến hàm tính tốc độ tiếp cận dựa trên sự thay đổi khoảng cách mũi của hai cá thể theo thời gian. Đây là một tín hiệu quan trọng trong các hành vi như tiến lại gần hoặc tránh né.\n",
    "\n",
    "Một nhóm đặc trưng quan trọng khác là phân loại mức khoảng cách giữa hai chuột. Khoảng cách được chia thành các mức rất gần gần trung bình và xa. Việc phân mức như vậy giúp mô hình nhận biết các tình huống giao tiếp xã hội quan trọng.\n",
    "\n",
    "Sau đó hàm áp dụng các bộ đặc trưng theo thời gian để mô tả biến động khoảng cách và mức tương tác trong các cửa sổ thời gian khác nhau. Các đặc trưng này phản ánh mức độ ổn định của sự tiếp xúc, xu hướng tiến lại gần hoặc rời xa, cũng như mức độ đồng bộ trong vận động của hai cá thể.\n",
    "\n",
    "Tiếp theo hàm tính các đặc trưng động lực học của khoảng cách giữa hai mũi. Điều này giúp nhận diện các thay đổi tinh tế trong hành vi như kiểm tra mùi hoặc theo dõi. Hàm cũng tính toán mức độ thẳng hàng vận tốc giữa hai chuột thông qua đặc trưng căn chỉnh vận tốc. Đây là một tín hiệu quan trọng để phát hiện các hành vi rượt đuổi hoặc di chuyển cùng hướng.\n",
    "\n",
    "Cuối cùng các đặc trưng cao cấp về tương tác được thêm vào nhằm mô tả quan hệ xã hội đa chiều hơn giữa hai cá thể. Tất cả đặc trưng được điều chỉnh theo fps và trả về dưới dạng bảng dữ liệu hoàn chỉnh."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-10T18:58:08.252870Z",
     "iopub.status.busy": "2025-12-10T18:58:08.252493Z",
     "iopub.status.idle": "2025-12-10T18:58:08.266884Z",
     "shell.execute_reply": "2025-12-10T18:58:08.266315Z",
     "shell.execute_reply.started": "2025-12-10T18:58:08.252837Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# helpers\n",
    "def _find_lgbm_step(pipe):\n",
    "    try:\n",
    "        if \"stratifiedsubsetclassifier__estimator\" in pipe.get_params():\n",
    "            est = pipe.get_params()[\"stratifiedsubsetclassifier__estimator\"]\n",
    "            if isinstance(est, lightgbm.LGBMClassifier):\n",
    "                return \"stratifiedsubsetclassifier\"\n",
    "        if \"stratifiedsubsetclassifierweval__estimator\" in pipe.get_params():\n",
    "            est = pipe.get_params()[\"stratifiedsubsetclassifierweval__estimator\"]\n",
    "            if isinstance(est, lightgbm.LGBMClassifier):\n",
    "                return \"stratifiedsubsetclassifierweval\"\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "    return None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hàm _find_lgbm_step được viết ra để kiểm tra xem trong một pipeline có bước nào đang chứa mô hình LightGBM hay không. Mục tiêu là tự động phát hiện đúng vị trí của mô hình LightGBM trong pipeline để phục vụ cho các thao tác tiếp theo như tinh chỉnh tham số, lấy thuộc tính mô hình hoặc đo lường thông số trong quá trình huấn luyện. Thay vì đặt tên bước cố định, hàm này cho phép mã linh hoạt với nhiều pipeline khác nhau có thể thay đổi cấu trúc hoặc tên bước.\n",
    "\n",
    "Khi hàm chạy, nó lấy toàn bộ tham số của pipeline thông qua get_params. Sau đó hàm kiểm tra xem có khóa nào tương ứng với tên bước chứa mô hình cần tìm hay không. Hai tên bước được hàm xem xét là stratifiedsubsetclassifier và stratifiedsubsetclassifierweval. Đây là những tên thường dùng trong các pipeline đặc biệt có chứa bộ phân lớp con mẫu có trọng số. Hàm lần lượt kiểm tra khóa chứa tên bước kèm theo hậu tố estimator và xác định xem giá trị của khóa đó có phải là một mô hình LightGBM hay không.\n",
    "\n",
    "Nếu một trong hai bước chứa mô hình LightGBM, hàm trả về tên bước tương ứng để người dùng có thể truy cập lại mô hình này một cách trực tiếp trong pipeline. Trong trường hợp xảy ra lỗi hoặc không tìm thấy bước chứa LightGBM, hàm trả về giá trị rỗng để báo hiệu rằng pipeline không có mô hình LightGBM. Cách xử lý này giúp đảm bảo mã mạnh mẽ hơn trước các pipeline cấu trúc bất thường hoặc lỗi phát sinh trong quá trình truy xuất tham số."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-10T18:58:08.268069Z",
     "iopub.status.busy": "2025-12-10T18:58:08.267696Z",
     "iopub.status.idle": "2025-12-10T18:58:08.286637Z",
     "shell.execute_reply": "2025-12-10T18:58:08.285853Z",
     "shell.execute_reply.started": "2025-12-10T18:58:08.268042Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def submit_ensemble(body_parts_tracked_str, switch_tr, X_tr, label, meta, n_samples=1_500_000):\n",
    "    models = []\n",
    "    models.append(make_pipeline(\n",
    "        StratifiedSubsetClassifier(_make_lgbm(\n",
    "            n_estimators=225, learning_rate=0.07, min_child_samples=40,\n",
    "            num_leaves=31, subsample=0.8, colsample_bytree=0.8, verbose=-1, gpu_use_dp=USE_GPU\n",
    "        ), n_samples)\n",
    "    ))\n",
    "    models.append(make_pipeline(\n",
    "        StratifiedSubsetClassifier(_make_lgbm(\n",
    "            n_estimators=150, learning_rate=0.1, min_child_samples=20,\n",
    "            num_leaves=63, max_depth=8, subsample=0.7, colsample_bytree=0.9,\n",
    "            reg_alpha=0.1, reg_lambda=0.1, verbose=-1, gpu_use_dp=USE_GPU\n",
    "        ), (n_samples and int(n_samples/1.25)))\n",
    "    ))\n",
    "    models.append(make_pipeline(\n",
    "        StratifiedSubsetClassifier(_make_lgbm(\n",
    "            n_estimators=100, learning_rate=0.05, min_child_samples=30,\n",
    "            num_leaves=127, max_depth=10, subsample=0.75, verbose=-1, gpu_use_dp=USE_GPU,\n",
    "        ), (n_samples and int(n_samples/1.66)))\n",
    "    ))\n",
    "\n",
    "    xgb0 = _make_xgb(\n",
    "        n_estimators=180, learning_rate=0.08, max_depth=6,\n",
    "        min_child_weight=8 if USE_GPU else 5, gamma=1.0 if USE_GPU else 0.,\n",
    "        subsample=0.8, colsample_bytree=0.8, single_precision_histogram=USE_GPU,\n",
    "        verbosity=0\n",
    "    )\n",
    "    models.append(make_pipeline(StratifiedSubsetClassifier(xgb0, n_samples and int(n_samples/1.2))))\n",
    "\n",
    "    cb_est = _make_cb(iterations=120, learning_rate=0.1, depth=6,\n",
    "                      verbose=False, allow_writing_files=False)\n",
    "    models.append(make_pipeline(StratifiedSubsetClassifier(cb_est, n_samples)))\n",
    "\n",
    "    model_names = ['lgbm_225', 'lgbm_150', 'lgbm_100', 'xgb_180', 'cat_120']\n",
    "\n",
    "    if USE_GPU:\n",
    "        xgb1 = XGBClassifier(\n",
    "            random_state=SEED, booster=\"gbtree\", tree_method=\"gpu_hist\",\n",
    "            n_estimators=2000, learning_rate=0.05, grow_policy=\"lossguide\",\n",
    "            max_leaves=255, max_depth=0, min_child_weight=10, gamma=0.0,\n",
    "            subsample=0.90, colsample_bytree=1.00, colsample_bylevel=0.85,\n",
    "            reg_alpha=0.0, reg_lambda=1.0, max_bin=256,\n",
    "            single_precision_histogram=True, verbosity=0\n",
    "        )\n",
    "        models.append(make_pipeline(\n",
    "            StratifiedSubsetClassifierWEval(xgb1, n_samples and int(n_samples/2.),\n",
    "                                            random_state=SEED, valid_size=0.10, val_cap_ratio=0.25,\n",
    "                                            es_rounds=\"auto\", es_metric=\"auto\")\n",
    "        ))\n",
    "        xgb2 = XGBClassifier(\n",
    "            random_state=SEED, booster=\"gbtree\", tree_method=\"gpu_hist\",\n",
    "            n_estimators=1400, learning_rate=0.06, max_depth=7,\n",
    "            min_child_weight=12, subsample=0.70, colsample_bytree=0.80,\n",
    "            reg_alpha=0.0, reg_lambda=1.5, max_bin=256,\n",
    "            single_precision_histogram=True, verbosity=0\n",
    "        )\n",
    "        models.append(make_pipeline(\n",
    "            StratifiedSubsetClassifierWEval(xgb2, n_samples and int(n_samples/1.5),\n",
    "                                            random_state=SEED, valid_size=0.10, val_cap_ratio=0.25,\n",
    "                                            es_rounds=\"auto\", es_metric=\"auto\")\n",
    "        ))\n",
    "\n",
    "        cb1 = CatBoostClassifier(\n",
    "            random_seed=SEED, task_type=\"GPU\", devices=\"0\",\n",
    "            iterations=4000, learning_rate=0.03, depth=8, l2_leaf_reg=6.0,\n",
    "            bootstrap_type=\"Bayesian\", bagging_temperature=0.5,\n",
    "            random_strength=0.5, loss_function=\"Logloss\",\n",
    "            eval_metric=\"PRAUC:type=Classic\", auto_class_weights=\"Balanced\",\n",
    "            border_count=64, verbose=False, allow_writing_files=False\n",
    "        )\n",
    "        models.append(make_pipeline(\n",
    "            StratifiedSubsetClassifierWEval(cb1, n_samples and int(n_samples/2.0),\n",
    "                                            random_state=SEED, valid_size=0.10, val_cap_ratio=0.25,\n",
    "                                            es_rounds=\"auto\", es_metric=\"auto\")\n",
    "        ))\n",
    "        model_names.extend(['xgb1', 'xgb2', 'cat_bay'])\n",
    "\n",
    "    model_list = []\n",
    "    for action in label.columns:\n",
    "        action_mask = ~label[action].isna().values\n",
    "        y_action = label[action][action_mask].values.astype(int)\n",
    "        meta_masked = meta.iloc[action_mask]\n",
    "  \n",
    "        trained = []\n",
    "        for model_idx, m in enumerate(models):\n",
    "            m_clone = clone(m)\n",
    "            try:\n",
    "                t0 = perf_counter()\n",
    "                m_clone.fit(X_tr[action_mask], y_action)\n",
    "                dt = perf_counter() - t0\n",
    "                print(f\"trained model {model_names[model_idx]} | {switch_tr} | action={action} | {dt:.1f}s\", flush=True)\n",
    "            except Exception:\n",
    "                step = _find_lgbm_step(m_clone)\n",
    "                if step is None:\n",
    "                    continue\n",
    "                try:\n",
    "                    m_clone.set_params(**{f\"{step}__estimator__device\": \"cpu\"})\n",
    "                    t0 = perf_counter()\n",
    "                    m_clone.fit(X_tr[action_mask], y_action)\n",
    "                    dt = perf_counter() - t0\n",
    "                    print(f\"trained (CPU fallback) {model_names[model_idx]} | {switch_tr} | action={action} | {dt:.1f}s\", flush=True)\n",
    "                except Exception as e2:\n",
    "                    print(e2)\n",
    "                    continue\n",
    "            trained.append(m_clone)\n",
    "\n",
    "        if trained:\n",
    "            model_list.append((action, trained))\n",
    "\n",
    "    del X_tr; gc.collect()\n",
    "\n",
    "    # ---- TEST INFERENCE ----\n",
    "    body_parts_tracked = json.loads(body_parts_tracked_str)\n",
    "    if len(body_parts_tracked) > 5:\n",
    "        body_parts_tracked = [b for b in body_parts_tracked if b not in drop_body_parts]\n",
    "\n",
    "    test_subset = test[test.body_parts_tracked == body_parts_tracked_str]\n",
    "    generator = generate_mouse_data(\n",
    "        test_subset, 'test',\n",
    "        generate_single=(switch_tr == 'single'),\n",
    "        generate_pair=(switch_tr == 'pair')\n",
    "    )\n",
    "    fps_lookup = (test_subset[['video_id','frames_per_second']]\n",
    "                    .drop_duplicates('video_id')\n",
    "                    .set_index('video_id')['frames_per_second'].to_dict())\n",
    "\n",
    "    for switch_te, data_te, meta_te, actions_te in generator:\n",
    "        assert switch_te == switch_tr\n",
    "        try:\n",
    "            fps_i = _fps_from_meta(meta_te, fps_lookup, default_fps=30.0)\n",
    "            if switch_te == 'single':\n",
    "                X_te = transform_single(data_te, body_parts_tracked, fps_i)\n",
    "            else:\n",
    "                X_te = transform_pair(data_te, body_parts_tracked, fps_i)\n",
    "\n",
    "            del data_te\n",
    "\n",
    "            pred = pd.DataFrame(index=meta_te.video_frame)\n",
    "            for action, trained in model_list:\n",
    "                if action in actions_te:\n",
    "                    probs = []\n",
    "                    for mi, mdl in enumerate(trained):\n",
    "                        probs.append(mdl.predict_proba(X_te)[:, 1])\n",
    "                    pred[action] = np.mean(probs, axis=0)\n",
    "\n",
    "            del X_te; gc.collect()\n",
    "\n",
    "            if pred.shape[1] != 0:\n",
    "                submission_list.append(predict_multiclass_adaptive(pred, meta_te))\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "            try: del data_te\n",
    "            except: pass\n",
    "            gc.collect()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hàm submit ensemble được thiết kế để huấn luyện và suy luận một tập hợp mô hình mạnh dựa trên các thuật toán học máy phổ biến như LightGBM, XGBoost và CatBoost. Đây là một chiến lược kết hợp mô hình nhằm tăng độ chính xác và độ ổn định trong dự đoán nhờ việc khai thác sự đa dạng của các thuật toán và tham số. Các mô hình được tạo với thành phần StratifiedSubsetClassifier, cho phép huấn luyện trên một phần dữ liệu được lấy mẫu theo phân phối của nhãn, từ đó giảm chi phí tính toán cho các tập dữ liệu lớn nhưng vẫn giữ được chất lượng học.\n",
    "\n",
    "Bước đầu tiên của hàm là tạo danh sách các mô hình với nhiều cấu hình khác nhau. Ba mô hình LightGBM được xây dựng với số lượng cây, tốc độ học, độ sâu và số lá khác nhau để tạo sự đa dạng về hành vi học. Bên cạnh đó, hàm khởi tạo thêm một mô hình XGBoost cơ bản và một mô hình CatBoost, cả hai đều được bao trong bộ phân lớp con để bảo đảm chúng được học theo các mẫu phân tầng. Khi GPU khả dụng, hàm bổ sung thêm ba mô hình nâng cao gồm hai mô hình XGBoost lớn và một mô hình CatBoost với cấu hình bayesian nhằm tận dụng sức mạnh tính toán của GPU và mở rộng phạm vi biểu diễn của tập mô hình.\n",
    "\n",
    "Sau khi thiết lập danh sách mô hình, hàm thực hiện huấn luyện cho từng hành động riêng biệt. Với mỗi hành động, chỉ những mẫu có nhãn hợp lệ được giữ lại. Tập mô hình được nhân bản và huấn luyện độc lập bằng cách đo thời gian, in nhật ký và tự động chuyển sang chế độ CPU nếu thiết lập GPU gây lỗi. Khi một mô hình huấn luyện thành công, nó được lưu lại trong danh sách mô hình cho hành động tương ứng.\n",
    "\n",
    "Khi kết thúc quá trình huấn luyện, hàm bước sang phần suy luận. Dữ liệu kiểm tra được phân tách theo loại chuyển động và được biến đổi thành các đặc trưng phù hợp bằng hàm xử lý dành cho dữ liệu đơn hoặc dữ liệu theo cặp. Đối với mỗi hành động xuất hiện trong dữ liệu kiểm tra, mô hình sẽ tạo ra xác suất dự đoán bằng cách lấy trung bình qua tất cả các mô hình đã huấn luyện cho hành động đó. Các xác suất này được ghép lại thành một bảng dự đoán chung.\n",
    "\n",
    "Bảng dự đoán sau đó được chuyển cho hàm dự đoán cuối cùng áp dụng cơ chế ngưỡng động adaptive thresholding. Phương pháp này giúp tìm và xác định các đoạn hành động xảy ra trong video bằng cách làm mượt dự đoán theo thời gian, chọn hành động theo ngưỡng và lọc bỏ các đoạn nhiễu quá ngắn. Kết quả cuối cùng được đưa vào danh sách nộp bài.\n",
    "\n",
    "Nhờ việc kết hợp nhiều thuật toán, dùng mẫu phân tầng, điều chỉnh linh hoạt theo hành động và xử lý ngưỡng thông minh, hàm submit ensemble mang lại hệ thống dự đoán giàu tính ổn định và có khả năng tổng quát hóa tốt đối với dữ liệu chuỗi thời gian của bài toán nhận dạng hành động."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-10T18:58:08.287868Z",
     "iopub.status.busy": "2025-12-10T18:58:08.287475Z",
     "iopub.status.idle": "2025-12-10T18:58:08.305215Z",
     "shell.execute_reply": "2025-12-10T18:58:08.304584Z",
     "shell.execute_reply.started": "2025-12-10T18:58:08.287843Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def robustify(submission, dataset, traintest, traintest_directory=None):\n",
    "    if traintest_directory is None:\n",
    "        traintest_directory = f\"/kaggle/input/MABe-mouse-behavior-detection/{traintest}_tracking\"\n",
    "\n",
    "    submission = submission[submission.start_frame < submission.stop_frame]\n",
    "\n",
    "    group_list = []\n",
    "    for _, group in submission.groupby(['video_id', 'agent_id', 'target_id']):\n",
    "        group = group.sort_values('start_frame')\n",
    "        mask = np.ones(len(group), dtype=bool)\n",
    "        last_stop = 0\n",
    "        for i, (_, row) in enumerate(group.iterrows()):\n",
    "            if row['start_frame'] < last_stop:\n",
    "                mask[i] = False\n",
    "            else:\n",
    "                last_stop = row['stop_frame']\n",
    "        group_list.append(group[mask])\n",
    "    submission = pd.concat(group_list) if group_list else submission\n",
    "\n",
    "    s_list = []\n",
    "    for _, row in dataset.iterrows():\n",
    "        lab_id = row['lab_id']\n",
    "        video_id = row['video_id']\n",
    "        if (submission.video_id == video_id).any():\n",
    "            continue\n",
    "\n",
    "        if verbose:\n",
    "            print(f\"Video {video_id} has no predictions\")\n",
    "\n",
    "        path = f\"{traintest_directory}/{lab_id}/{video_id}.parquet\"\n",
    "        vid = pd.read_parquet(path)\n",
    "\n",
    "        vid_behaviors = eval(row['behaviors_labeled'])\n",
    "        vid_behaviors = sorted(list({b.replace(\"'\", \"\") for b in vid_behaviors}))\n",
    "        vid_behaviors = [b.split(',') for b in vid_behaviors]\n",
    "        vid_behaviors = pd.DataFrame(vid_behaviors, columns=['agent', 'target', 'action'])\n",
    "\n",
    "        start_frame = vid.video_frame.min()\n",
    "        stop_frame = vid.video_frame.max() + 1\n",
    "\n",
    "        for (agent, target), actions in vid_behaviors.groupby(['agent', 'target']):\n",
    "            batch_len = int(np.ceil((stop_frame - start_frame) / len(actions)))\n",
    "            for i, (_, action_row) in enumerate(actions.iterrows()):\n",
    "                batch_start = start_frame + i * batch_len\n",
    "                batch_stop = min(batch_start + batch_len, stop_frame)\n",
    "                s_list.append((video_id, agent, target, action_row['action'], batch_start, batch_stop))\n",
    "\n",
    "    if len(s_list) > 0:\n",
    "        submission = pd.concat([\n",
    "            submission,\n",
    "            pd.DataFrame(s_list, columns=['video_id', 'agent_id', 'target_id', 'action', 'start_frame', 'stop_frame'])\n",
    "        ])\n",
    "\n",
    "    submission = submission.reset_index(drop=True)\n",
    "    return submission"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hàm robustify có nhiệm vụ làm cho bảng dự đoán cuối cùng trở nên ổn định và đầy đủ hơn. Nó thực hiện hai nhóm công việc chính gồm loại bỏ các đoạn dự đoán bị chồng lấn không hợp lý và bổ sung dự đoán giả khi một video không có bất kỳ dự đoán nào. Điều này giúp bảo đảm rằng kết quả đầu ra luôn phù hợp với định dạng mong đợi và không bị lỗi khi chấm điểm.\n",
    "\n",
    "Đầu tiên, hàm kiểm tra và loại bỏ những dòng dự đoán có thời điểm bắt đầu lớn hơn hoặc bằng thời điểm kết thúc. Sau đó, các dự đoán được gom theo nhóm video, agent và target. Trong từng nhóm, các đoạn được sắp xếp theo thời gian xuất hiện. Hàm tạo một mặt nạ để giữ lại chỉ những đoạn không chồng lấn với đoạn trước đó. Nếu một đoạn mới có thời điểm bắt đầu nhỏ hơn thời điểm kết thúc của đoạn trước, nó sẽ bị loại bỏ. Bước này giúp loại bỏ các trường hợp trùng lặp hoặc sai lệch do nhiễu của hệ thống dự đoán.\n",
    "\n",
    "Sau khi làm sạch các đoạn chồng lấn, hàm chuyển sang bước bù dự đoán cho các video không có bất kỳ dự đoán nào. Với mỗi video trong tập dữ liệu gốc, nếu không xuất hiện trong bảng dự đoán, hàm sẽ tải file theo dõi tương ứng để lấy tất cả khung hình. Sau đó, hàm đọc danh sách hành vi được gán nhãn trong metadata và tách thành từng cặp agent, target và tên hành động.\n",
    "\n",
    "Với mỗi cặp agent target của video đó, hàm chia toàn bộ khung hình video thành các lô bằng nhau theo số hành động có sẵn. Mỗi hành động sẽ nhận một đoạn dự đoán trải đều từ đầu tới cuối video. Các đoạn này là giả lập và không phản ánh mô hình nhưng bảo đảm rằng video đó luôn có dự đoán hợp lệ, tránh lỗi khi tính điểm.\n",
    "\n",
    "Cuối cùng, tất cả đoạn dự đoán cũ và đoạn bổ sung được ghép lại thành bảng hoàn chỉnh. Chỉ số được làm phẳng và bảng được trả về. Nhờ đó, robustify giúp hệ thống dự đoán trở nên ổn định hơn, không gặp lỗi thiếu dữ liệu và loại bỏ các đoạn dự đoán bất thường trước khi gửi bài."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**MAIN LOOP**\n",
    "Vòng lặp chính chịu trách nhiệm xử lý toàn bộ dữ liệu huấn luyện theo từng nhóm bộ phận cơ thể được theo dõi. Mỗi nhóm bộ phận tương ứng với một dạng cấu trúc đầu vào khác nhau và được mô hình huấn luyện độc lập. Điều này giúp mô hình phù hợp hơn với chất lượng và mức độ chi tiết của dữ liệu thu được.\n",
    "\n",
    "Khi bắt đầu mỗi vòng lặp, mã chuyển chuỗi bộ phận theo dõi thành danh sách và loại bỏ những bộ phận ít quan trọng nếu số lượng vượt quá năm. Sau đó dữ liệu huấn luyện được lọc theo nhóm bộ phận này để tạo thành một tập con riêng. Vòng lặp tiếp tục tạo bảng tra cứu số khung hình mỗi giây cho từng video nhằm đảm bảo việc chuẩn hóa đặc trưng theo thời gian được chính xác.\n",
    "\n",
    "Dữ liệu sau đó được tách thành hai loại gồm single và pair thông qua hàm sinh dữ liệu đầu vào. Loại single chứa các hành vi dựa trên một cá thể còn loại pair mô tả tương tác giữa hai cá thể. Hai loại dữ liệu này khác nhau về hình thức và đều được xử lý riêng để giúp mô hình học đúng bản chất của hành vi.\n",
    "\n",
    "Với từng loại dữ liệu single hoặc pair, mã lần lượt biến đổi dữ liệu thô thành đặc trưng đầu vào bằng các hàm transform tương ứng. Các đặc trưng của từng video được ghép lại tạo thành một bảng lớn dùng để huấn luyện. Nhãn và metadata cũng được ghép lại theo cùng cách. Khi đặc trưng đã sẵn sàng hàm submit ensemble được gọi để huấn luyện toàn bộ mô hình trong tổ hợp và thực hiện dự đoán cho tập kiểm tra.\n",
    "\n",
    "Sau khi xử lý xong một loại dữ liệu, các biến tạm được giải phóng để tiết kiệm bộ nhớ. Quá trình này tiếp tục cho đến khi mọi nhóm bộ phận theo dõi đều được xử lý. Nếu không có dự đoán nào được tạo ra, mã sẽ sinh một dự đoán mặc định để tránh lỗi khi chấm điểm.\n",
    "\n",
    "Cuối cùng toàn bộ dự đoán được ghép lại rồi đưa qua hàm robustify để loại bỏ những đoạn trùng lặp và bổ sung dự đoán cho các video không xuất hiện trong đầu ra. Bảng dự đoán đã làm sạch được lưu thành tệp và in ra số lượng hành vi dự đoán. Nhờ đó vòng lặp chính đảm bảo mọi nhóm dữ liệu đều được sử dụng, mô hình được huấn luyện đầy đủ và kết quả đầu ra luôn hợp lệ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-10T18:58:08.306578Z",
     "iopub.status.busy": "2025-12-10T18:58:08.305954Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0. Processing: 12 body parts\n",
      "\n",
      "1. Processing: 18 body parts\n",
      "  Single: (652695, 121)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1 warning generated.\n",
      "1 warning generated.\n",
      "1 warning generated.\n",
      "1 warning generated.\n",
      "1 warning generated.\n",
      "1 warning generated.\n",
      "1 warning generated.\n",
      "1 warning generated.\n",
      "1 warning generated.\n",
      "1 warning generated.\n",
      "1 warning generated.\n",
      "1 warning generated.\n",
      "1 warning generated.\n",
      "1 warning generated.\n",
      "1 warning generated.\n",
      "1 warning generated.\n",
      "1 warning generated.\n",
      "1 warning generated.\n",
      "1 warning generated.\n",
      "1 warning generated.\n",
      "1 warning generated.\n",
      "1 warning generated.\n",
      "1 warning generated.\n",
      "1 warning generated.\n",
      "1 warning generated.\n",
      "1 warning generated.\n",
      "1 warning generated.\n",
      "1 warning generated.\n",
      "1 warning generated.\n",
      "1 warning generated.\n",
      "1 warning generated.\n",
      "1 warning generated.\n",
      "1 warning generated.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trained model lgbm_225 | single | action=rear | 23.9s\n",
      "trained model lgbm_150 | single | action=rear | 16.2s\n",
      "trained model lgbm_100 | single | action=rear | 15.2s\n",
      "trained model xgb_180 | single | action=rear | 12.1s\n",
      "trained model cat_120 | single | action=rear | 17.8s\n",
      "trained model xgb1 | single | action=rear | 95.6s\n",
      "trained model xgb2 | single | action=rear | 39.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric PRAUC:type=Classic is not implemented on GPU. Will use CPU for metric computation, this could significantly affect learning time\n",
      "Metric PRAUC:type=Classic is not implemented on GPU. Will use CPU for metric computation, this could significantly affect learning time\n",
      "Metric PRAUC:type=Classic is not implemented on GPU. Will use CPU for metric computation, this could significantly affect learning time\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trained model cat_bay | single | action=rear | 93.8s\n",
      "  actions found: 14\n",
      "  actions found: 79\n",
      "  actions found: 48\n",
      "  actions found: 121\n",
      "  Pair: (1524906, 140)\n",
      "trained model lgbm_225 | pair | action=approach | 21.9s\n",
      "trained model lgbm_150 | pair | action=approach | 21.4s\n",
      "trained model lgbm_100 | pair | action=approach | 17.6s\n",
      "trained model xgb_180 | pair | action=approach | 21.5s\n",
      "trained model cat_120 | pair | action=approach | 7.7s\n",
      "trained model xgb1 | pair | action=approach | 92.2s\n",
      "trained model xgb2 | pair | action=approach | 74.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric PRAUC:type=Classic is not implemented on GPU. Will use CPU for metric computation, this could significantly affect learning time\n",
      "Metric PRAUC:type=Classic is not implemented on GPU. Will use CPU for metric computation, this could significantly affect learning time\n",
      "Metric PRAUC:type=Classic is not implemented on GPU. Will use CPU for metric computation, this could significantly affect learning time\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trained model cat_bay | pair | action=approach | 153.3s\n",
      "trained model lgbm_225 | pair | action=attack | 21.1s\n",
      "trained model lgbm_150 | pair | action=attack | 20.2s\n",
      "trained model lgbm_100 | pair | action=attack | 16.2s\n",
      "trained model xgb_180 | pair | action=attack | 21.3s\n",
      "trained model cat_120 | pair | action=attack | 6.7s\n",
      "trained model xgb1 | pair | action=attack | 72.9s\n",
      "trained model xgb2 | pair | action=attack | 77.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric PRAUC:type=Classic is not implemented on GPU. Will use CPU for metric computation, this could significantly affect learning time\n",
      "Metric PRAUC:type=Classic is not implemented on GPU. Will use CPU for metric computation, this could significantly affect learning time\n",
      "Metric PRAUC:type=Classic is not implemented on GPU. Will use CPU for metric computation, this could significantly affect learning time\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trained model cat_bay | pair | action=attack | 150.4s\n",
      "trained model lgbm_225 | pair | action=avoid | 29.1s\n",
      "trained model lgbm_150 | pair | action=avoid | 23.4s\n",
      "trained model lgbm_100 | pair | action=avoid | 18.6s\n",
      "trained model xgb_180 | pair | action=avoid | 23.9s\n",
      "trained model cat_120 | pair | action=avoid | 8.6s\n",
      "trained model xgb1 | pair | action=avoid | 106.9s\n",
      "trained model xgb2 | pair | action=avoid | 72.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric PRAUC:type=Classic is not implemented on GPU. Will use CPU for metric computation, this could significantly affect learning time\n",
      "Metric PRAUC:type=Classic is not implemented on GPU. Will use CPU for metric computation, this could significantly affect learning time\n",
      "Metric PRAUC:type=Classic is not implemented on GPU. Will use CPU for metric computation, this could significantly affect learning time\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trained model cat_bay | pair | action=avoid | 152.9s\n",
      "trained model lgbm_225 | pair | action=chase | 23.0s\n",
      "trained model lgbm_150 | pair | action=chase | 24.8s\n",
      "trained model lgbm_100 | pair | action=chase | 18.0s\n",
      "trained model xgb_180 | pair | action=chase | 24.3s\n",
      "trained model cat_120 | pair | action=chase | 7.4s\n",
      "trained model xgb1 | pair | action=chase | 80.3s\n",
      "trained model xgb2 | pair | action=chase | 75.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric PRAUC:type=Classic is not implemented on GPU. Will use CPU for metric computation, this could significantly affect learning time\n",
      "Metric PRAUC:type=Classic is not implemented on GPU. Will use CPU for metric computation, this could significantly affect learning time\n",
      "Metric PRAUC:type=Classic is not implemented on GPU. Will use CPU for metric computation, this could significantly affect learning time\n"
     ]
    }
   ],
   "source": [
    "# ==================== MAIN LOOP ====================\n",
    "\n",
    "submission_list = []\n",
    "\n",
    "for section in range(len(body_parts_tracked_list)):\n",
    "    body_parts_tracked_str = body_parts_tracked_list[section]\n",
    "    try:\n",
    "        body_parts_tracked = json.loads(body_parts_tracked_str)\n",
    "        print(f\"{section}. Processing: {len(body_parts_tracked)} body parts\")\n",
    "        if len(body_parts_tracked) > 5:\n",
    "            body_parts_tracked = [b for b in body_parts_tracked if b not in drop_body_parts]\n",
    "\n",
    "        train_subset = train[train.body_parts_tracked == body_parts_tracked_str]\n",
    "\n",
    "        _fps_lookup = (\n",
    "            train_subset[['video_id', 'frames_per_second']]\n",
    "            .drop_duplicates('video_id')\n",
    "            .set_index('video_id')['frames_per_second']\n",
    "            .to_dict()\n",
    "        )\n",
    "\n",
    "        single_list, single_label_list, single_meta_list = [], [], []\n",
    "        pair_list, pair_label_list, pair_meta_list = [], [], []\n",
    "\n",
    "        for switch, data, meta, label in generate_mouse_data(train_subset, 'train'):\n",
    "            if switch == 'single':\n",
    "                single_list.append(data)\n",
    "                single_meta_list.append(meta)\n",
    "                single_label_list.append(label)\n",
    "            else:\n",
    "                pair_list.append(data)\n",
    "                pair_meta_list.append(meta)\n",
    "                pair_label_list.append(label)\n",
    "\n",
    "        if len(single_list) > 0:\n",
    "            single_feats_parts = []\n",
    "            for data_i, meta_i in zip(single_list, single_meta_list):\n",
    "                fps_i = _fps_from_meta(meta_i, _fps_lookup, default_fps=30.0)\n",
    "                Xi = transform_single(data_i, body_parts_tracked, fps_i).astype(np.float32)\n",
    "                single_feats_parts.append(Xi)\n",
    "\n",
    "            X_tr = pd.concat(single_feats_parts, axis=0, ignore_index=True)\n",
    " \n",
    "            single_label = pd.concat(single_label_list, axis=0, ignore_index=True)\n",
    "            single_meta  = pd.concat(single_meta_list,  axis=0, ignore_index=True)\n",
    "\n",
    "            del single_list, single_label_list, single_meta_list, single_feats_parts\n",
    "            gc.collect()\n",
    "\n",
    "            print(f\"  Single: {X_tr.shape}\")\n",
    "            submit_ensemble(body_parts_tracked_str, 'single', X_tr, single_label, single_meta)\n",
    "\n",
    "            del X_tr, single_label, single_meta\n",
    "            gc.collect()\n",
    "\n",
    "        if len(pair_list) > 0:\n",
    "            pair_feats_parts = []\n",
    "            for data_i, meta_i in zip(pair_list, pair_meta_list):\n",
    "                fps_i = _fps_from_meta(meta_i, _fps_lookup, default_fps=30.0)\n",
    "                Xi = transform_pair(data_i, body_parts_tracked, fps_i).astype(np.float32)\n",
    "                pair_feats_parts.append(Xi)\n",
    "\n",
    "            X_tr = pd.concat(pair_feats_parts, axis=0, ignore_index=True)\n",
    "\n",
    "            \n",
    "            pair_label = pd.concat(pair_label_list, axis=0, ignore_index=True)\n",
    "            pair_meta  = pd.concat(pair_meta_list,  axis=0, ignore_index=True)\n",
    "\n",
    "            del pair_list, pair_label_list, pair_meta_list, pair_feats_parts\n",
    "            gc.collect()\n",
    "\n",
    "            print(f\"  Pair: {X_tr.shape}\")\n",
    "            submit_ensemble(body_parts_tracked_str, 'pair', X_tr, pair_label, pair_meta)\n",
    "\n",
    "            del X_tr, pair_label, pair_meta\n",
    "            gc.collect()\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f'***Exception*** {str(e)[:100]}')\n",
    "\n",
    "    gc.collect()\n",
    "    print()\n",
    "\n",
    "if len(submission_list) > 0:\n",
    "    submission = pd.concat(submission_list, ignore_index=True)\n",
    "else:\n",
    "    submission = pd.DataFrame({\n",
    "        'video_id': [438887472],\n",
    "        'agent_id': ['mouse1'],\n",
    "        'target_id': ['self'],\n",
    "        'action': ['rear'],\n",
    "        'start_frame': [278],\n",
    "        'stop_frame': [500]\n",
    "    })\n",
    "\n",
    "submission_robust = robustify(submission, test, 'test')\n",
    "submission_robust.index.name = 'row_id'\n",
    "submission_robust.to_csv('submission.csv')\n",
    "print(f\"\\nSubmission created: {len(submission_robust)} predictions\")"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "databundleVersionId": 13874099,
     "sourceId": 59156,
     "sourceType": "competition"
    }
   ],
   "dockerImageVersionId": 31193,
   "isGpuEnabled": true,
   "isInternetEnabled": false,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
